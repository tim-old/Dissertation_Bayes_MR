---
title: "2. Introduction and Background"
author: "B233241"
date: "2025-01-07"
output:
  pdf_document:
    latex_engine: xelatex
    dev: cairo_pdf
knit: (function(inputFile, encoding) {
      rmarkdown::render(inputFile,
                        encoding = encoding,
                        knit_root_dir = rprojroot::find_rstudio_root_file(),
                        output_dir = file.path("../Output")
                        )})
fig_caption: yes
link-citations: TRUE
urlcolor: blue
bibliography: Lit_Rev_Refs.bib
csl: vancouver-superscript.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

Word count: `r wordcountaddin::word_count(here::here("MSc_Thesis_Split", "Script", "_2_Intro_Background.Rmd"))`


# Introduction and Background

Epidemiology is the study of determinants and distribution of disease across populations; a common epidemiological study aim is therefore to seek evidence as to whether a given exposure (e.g. cigarette smoking) may cause a given outcome (e.g. lung cancer) [@coggon_chapter_2003]. Logistics limit feasibility of delivering experimental interventions across large groups of people, so insights regarding associations between exposures and outcomes at scale are typically gleaned from observational data of people in the population of interest. Comparing rates of a particular health outcome between individuals with different levels of a particular exposure may highlight potential links, e.g. higher cancer incidence in those who smoke more would be consistent with a potential causal role for cigarettes in carcinogenesis [@coggon_chapter_2003]. 

However, correlation does not by itself prove causation. A key challenge in epidemiology is accounting for so-called "confounding" factors; these are other variables associated with both the exposure and the outcome of interest which represent an alternative causal explanation for any exposure:outcome links observed[@martens_instrumental_2006]. If those who smoke also drink more alcohol than non-smokers, then an observed link between smoking and increased cancer risk could plausibly be caused by increased alcohol exposure, either in part or entirely. Another potential issue with observational data is "reverse causation", where the presumed outcome is in fact a cause of the exposure; this might be the case if a cancer diagnosis drove individuals to drink and smoke more, and data were collected without accounting for relative timings of each of these factors.

Mendelian randomisation (MR) is a methodology intended to support causal inference from observational data. It applies the principles of instrumental variable (IV) analysis to genetic data, in essence performing a type of natural experiment often likened to a randomised-controlled trial (RCT) [@hernan_instruments_2006]. 

In a properly conducted RCT, causality can be inferred due to a randomisation process being used as an "instrument" to allocate different levels of exposures to different experimental groups. If groups are randomly allocated, any confounding variables which might otherwise influence exposure:outcome relationships should be evenly distributed between groups, whether these confounders are known or not. As such, there should be no systematic differences between individuals from different groups is the exposure of interest - that is, there should be no bias [@stel_instrumental_2012]. Statistical methods can quantify the probability that any observed outcome differences could have occurred by chance, and thereafter any outcome differences can be interpreted as caused by exposure differences. As allocation and receipt of exposures is known to precede outcome measurements, reverse causality is impossible.

In MR, naturally occurring genetic variants - “genetic instruments” – are chosen based on their known association to an exposure of interest. In theory, provided that the assumptions of IV analysis are met, random assignment of genetic variants from parents to offspring during meiosis can create a form of natural randomisation analagous to that performed for an RCT – both measured and unmeasured confounders should be distributed evenly between the groups created, allowing valid causal inference after other sources of bias and random variation are accounted for [@davies_reading_2018].

Three key assumptions of IV analysis must be met [@lousdal_introduction_2018]:
1.	Relevance – the genetic variant must be associated with the exposure of interest
2.	Independence – the genetic variant is independent of confounders of the relationship between exposure and outcome
3.	Exclusion restriction – the genetic variant must not be associated with the outcome except via the exposure

If these assumptions are satisfied, the “causal effect estimate” of the exposure on the outcome can be estimated by comparing measures of gene:exposure association with those of gene:outcome association. At its simplest, the relationship between exposure and outcome can be represented as a linear model:




instruments to an outcome of interest, genetic data can be used to investigate causal links between exposures and outcomes [@richmond_mendelian_2022]. by the Wald ratio, i.e. by dividing the co-efficient of gene-outcome association by the co-efficient of gene-exposure, giving a numerical measure of strength of causal exposure-outcome association [@burgess_robust_2020].
 
Figure X. Taken from Burgess et al 2016 (DAG) [@burgess_sensitivity_2016]
```{r DAG, include=FALSE}

```



In practice, only the relevance assumption can be directly tested and proven, as independence and exclusion restriction depend on all possible confounders of the exposure-outcome association, both measured and unmeasured[@ ***REF***]. Threats to the independence assumption will vary depending on the population, exposure and outcome being studied[@ ***REF***]. Exclusion restriction is a particularly universal issue in MR, due to so-called (horizontal) genetic pleiotropy, where a single genetic variant may have multiple “pleiotropic” effects – i.e. it may influence several traits simultaneously. Such pleiotropic effects may be unknown and open unmeasured causal pathways between a genetic instrument and the outcome, separate to the path involving the exposure of interest, thus potentially biasing MR estimates of the association between exposure and outcome [@hemani_evaluating_2018].

Although not possible to prove exclusion restriction for any MR study, several methods attempt to produce exposure-outcome causal effect estimates which are robust to violations of this assumption. A common approach is the Weighted Median Estimator (WME) method, proposed by Bowden et al [@bowden_consistent_2016]. 

In WME analysis, several genetic instruments are used to estimate the exposure-outcome causal effect. Each instrument is known to be associated with the exposure of interest, but an unknown proportion of these instruments may be invalid due to pleiotropic genetic effects. Any instrument linked to an outcome via multiple pleiotropic causal pathways will exhibit a less consistent gene-outcome association than a relationship mediated by a single pathway; this results in larger variance in causal estimates derived from invalid/pleiotropic genetic instruments versus estimates from valid instruments.

WME therefore assigns a weight to each genetic instrument’s estimate of the causal effect according to the inverse of the variance of the estimate; these weighted effect estimates are used to construct a cumulative distribution function for probability of true causal effect size across the range of estimated values. The 50th percentile of this distribution can then be taken as a “weighted median estimate” of the true causal effect, theoretically producing consistent causal estimates even if up to 50% of the included information comes from invalid instruments [@bowden_consistent_2016]. (Fig?)

