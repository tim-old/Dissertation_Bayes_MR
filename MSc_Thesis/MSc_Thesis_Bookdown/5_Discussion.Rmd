# Discussion

```{r setup5, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Performance of Methods 

### Simulation

#### Null Causal Effect
\leavevmode\newline For a null causal effect, MR-Hevo exhibited broadly similar bias away from the null to \acr{WME}, with both methods tending to slightly over-estimate the true value. Considering variance of estimates, the mean \acr{SE} for MR-Hevo was fractionally lower than for \acr{WME}, representing slightly narrower \acr{CI}s. Despite near identical average quantitative effect estimation, MR-Hevo was consistently more accurate in categorical classification as causal/no causal effect, exhibiting a superior false-positive rate in all 24 meta-analyses with null causal effect. As false-positive reports were still a rare occurrence, it is perhaps unsurprising that mean estimates/\acr{SE}s don't clearly reflect this difference in Type 1 error. 

These results do suggest that MR-Hevo deals with pleiotropic effects more conservatively than \acr{WME}, namely by appropriately reducing the reported precision of the estimate to reflect additional uncertainty. Greater consistency of effect estimation by MR-Hevo versus \acr{WME} was particularly marked when moving between different scenarios representing different assumption violations. 

#### Positive Causal Effect
\leavevmode\newline When a positive causal effect was present, MR-Hevo exhibited a slightly higher mean sensitivity than \acr{WME} when all results were pooled, but on per meta-analysis basis it was out-performed in the majority of cases. The accuracy of MR-Hevo versus \acr{WME} was very slightly lower overall, again tending to over-estimate the true causal effect. Precision was similar to the null causal effect case, with a comparable \acr{CI} for both methods, but a much smaller \acr{SE} for MR-Hevo.

Regarding consistency, there are again trends towards both methods reporting wider \acr{CI}s with a greater proportion of invalid instruments and/or greater violations of \acr{IV} assumptions; again, this broadening of \acr{CI}s is more marked for MR-Hevo than for \acr{WME}. There appears to be a correlation whereby \acr{WME} displays greater sensitivity than MR-Hevo in cases where parameter and scenario combinations bias more strongly away from the null; this may suggest MR-Hevo produces estimates more robust to assumption violations than those of \acr{WME}, rather than \acr{WME} truly being a more sensitive method.

An exception to general trends is the combination of 0% invalid instruments with 20,000 participants, where MR-Hevo reports narrower \acr{CI}s - and therefore correctly reports disproportionately more causal effects - than either \acr{WME} using that parameter combination, or MR-Hevo at 0% invalid instruments with 10,000 participants. This parameter combination appears to drive the somewhat discordant summary of sensitivity results. 

It is not clear why this combination is associated with such a high causal report rate for MR-Hevo. If MR-Hevo performed particularly well versus \acr{WME} in the absence of invalid instruments, this would be expected to hold in the 10,000 participants case also. Similarly, if MR-Hevo were particularly sensitive to the difference in sample size versus \acr{WME}, larger discrepancies would be expected between the two methods with other parameter/scenario combinations when transitioning between 10,000 to 20,000 participants. Differences in assumption violations between scenarios do not affect this result, as assumption violations are only relevant to invalid instruments, of which there are none in the 0% invalid case. This unexpected result may be an aberrant feature of the particular datasets generated, which could be investigated by re-running the analysis from a different random seed. Alternatively, it may be that, when using MR-Hevo methods, sample size interacts in a non-linear way for and invalid instrument proportions approaching zero with respect to the method's power. If the causal report rate for this parameter/scenario combination remained high after data simulation with a different seed, this possibility could be next investigated using simulated datasets with invalid instrument proportions between 0-10%.

### Re-Analysis

As discussed in \@ref(lim-cite), the comparison of re-analysis \acr{WME} causal effect estimates to those of MR-Hevo may represent the true performance of MR-Hevo on "real-world" data poorly, given the poor reproducibility of \acr{WME} findings on re-analysis. This inability to reproduce published results using the corresponding published data and methods potentially represents a major issue for the field of \acr{MR} - arguably greater than any difference in outcomes between causal estimation methodologies. A full discussion is outside the scope of this project; however, the following data features were noted which may explain some of this phenomenon. Of the six studies with reproducible \acr{WME} estimates, all presented data rounded to three to five decimal places. By contrast, of the four non-reproducible studies, only one (Ligthart et al[@ligthart_genome_2018]) presented data rounded to three decimal places, with the other three reporting to one to two significant figures. It is possible that such minor data variations are proportionally large enough to influence causal effect estimates, given that most gene-exposure and gene-outcome coefficients are numerically small in absolute terms. The author (B233241) was unable to find any literature pertaining to this, or indeed to reproducibility of \acr{MR} results in general; this would seem to be a lacuna which warrants further investigation.

In studies where \acr{WME} estimates were reproducible, MR-Hevo estimates and \acr{CI}s matched closely. Across all studies, reproducible or not, conclusions regarding causality matched exactly, although estimates and particularly confidence intervals differed substantially between the two methods for some studies. This is a broadly reassuring finding, suggesting that the conclusions of the most highly-cited works in the field are robust to different methodologies. However, with thousands of \acr{MR} studies now reported, as evidenced by the 5,417 articles referencing Bowden et al [@bowden_consistent_2016] alone, this is not to say that MR-Hevo could not change conclusions of many published \acr{MR} studies in the literature if it were used to re-analyse their data.

## Results in Context

A key concern in the \acr{MR} literature of late has been of suspiciously high numbers of studies reporting causal effects, often in cases where causality does not seem biologically plausible[@stender_reclaiming_2024]. It is against this backdrop that the creators of MR-Hevo introduce their approach as a potential solution, and it is worth considering this wider context before assessing the relative merits of each method.

Several factors may be driving high positive report rates observed in published \acr{MR} studies. As with other academic fields, there is likely to be an element of publication bias in favour of studies reporting statistically significant results [@bowden_mendelian_2015; @bowden_modelling_2010]; naturally, no causal effect estimation methods will be able to address this issue. The widespread availability and use of tools such as the `TwoSampleMR` R package[@hemani_mr-base_2018] facilitate production of \acr{MR} studies at scale. Genetic studies without a plausible hypothetical basis are at high baseline risk of false positives due to implicit multiple comparisons, given the number of potential exposures and outcomes which could be examined[@balding_tutorial_2006]. The ability to generate \acr{MR} studies in an automated way renders all such spurious associations more easily accessible for attempted publication; if these are then preferentially published versus the negative findings, this could contribute to the proliferation of positive \acr{MR} studies observed. This was recognised by the creators of MR-Base themselves, prompting them to write a paper which programmatically assessed all possible exposure-outcome associations on the platform, in an attempt to disincentivise this practice[@hemani_automating_2017]:

>"...we said what we're going to do is do the Mendelian randomization of everything against everything and put it online, and then say no one should be able to publish just the two-sample Mendelian randomization study because we've done them all" [@mrc_ieu_at_university_of_bristol_noodles_2023]

A related concern is that such methods are easily accessible to non-experts, such that the large numbers of studies so produced may also be disproportionately of low quality, without implementing safeguards against such issues. Some authors go so far as to state that \acr{MR} needs "reclaiming...from the deluge of papers and misleading findings" [@stender_reclaiming_2024], and recommending evidence "triangulation" - i.e. presenting non-\acr{MR} data to support each claim of causality detected by \acr{MR} methods - should be a necessary adjunct to publication of any causal \acr{MR} finding[@munafo_triangulating_2021].

By contrast, the group behind MR-Hevo assert that valid methods should yield valid results, regardless of the scale on which analyses are performed. Further, they argue that it is not biologically plausible that directional pleiotropy would routinely exist without the \acr{InSIDE} assumption also being violated[@mckeigue_inference_2024]. Regarding this study's simulation results, this pre-supposed coupling of direction and magnitude of pleiotropic effects would imply that Scenario 2 is essentially defunct. The most relevant assumption set regarding bias introduced by invalid instruments with pleiotropic effects would then be Scenario 3, where \acr{WME} exhibited the highest false-positive causal report rates, and where MR-Hevo arguably exhibits both the greatest improvement in consistency but fall in sensitivity versus \acr{WME}. In the above "everything against everthing" pre-print[@hemani_automating_2017], it is significant that evidence of pleiotropy was noted in >90% of comparisons on the MR-Base platform. The prescence of balanced pleiotropy would be expected to add only variance to causal effect estimates, and therefore could not explain a high false-positive causal report rate. Taken together, this would therefore suggest that MR-Hevo is the more suitable of the two methods to address any contributions of pleiotropic effects to the high false-positive causal report rates observed.

<!-- ?Resources e.g. compute -->



\newpage
