# (APPENDIX) Appendix {-} 

\newpage


# Appendix: List of Abbreviations {#appendix-acr}


\printacronyms


\newpage

# Appendix: Bootstrapping {#appendix-boot}

## Bootstrapping - General Method

The typical process for "bootstrap" generating an estimate, \acr{SE} and \acr{CI}s of a population parameter (e.g. population mean $\mu$) from a sample $x$ is as follows[@buscaglia_chapter_2020]:

1. A sample, $x$, of $n$ individuals is selected from a total population, $X$, of $N$ individuals
2. This sample $x$ is then treated as the "bootstrap population"; the empirical distribution of values in the $n$ individuals in the bootstrap population is taken to be broadly representative of the distribution of values in the underlying population $X$ of $N$ individuals
3. A "bootstrap sample", $x^*$,  is then obtained by re-sampling individuals from the bootstrap population with replacement $n$ times per bootstrap sample, i.e. the new bootstrap sample comprises $n$ sampled individuals, $x^*_1, x^*_2,...x^*_n$. As such, individuals from the original bootstrap population $x$ may contribute once, more than once or not at all to each bootstrap sample $x^*$.
4. A total of $k$ bootstrap samples are generated, $x^{*1}, x^{*2},...x^{*k}$, and the statistic of interest (e.g. sample mean $\bar{x}$) is estimated in each individual sample, $\bar{x}^{*i}$, giving the complete set of $\bar{x}^{*1}, \bar{x}^{*2},...\bar{x}^{*i}...\bar{x}^{*k}$.
5. The set of $k$ statistics are combined to form a "bootstrap distribution"; as expected from \acr{CLT}[@ross_chapter_2014], this is typically closer to a normal distribution than the underlying distribution of values in either the bootstrap population $x$ or the total population $X$. (See Figure \@ref(fig:prostate-vol) for an example of this)
6. The final values are derived as follows:

> - the parameter estimate (e.g. estimate of the true population mean, $\hat{\mu}$) is taken as the mean of the bootstrap distribution of $k$ estimates, $(\sum^k_{i = 1} \bar{x}) \div n$
> - the \acr{CI}s are taken as the values at the appropriate centiles at the edges of the sampling distribution, e.g. a 95% \acr{CI} would be generated using values at the 2.5th and 97.5th centiles
> - the \acr{SE} of the estimate is taken as the \acr{SD} of the sampling distribution, given by $\sqrt{\frac{1}{k - 1} \sum^k_{i = 1} (\bar{x_i} - \hat{\mu})^2}$



## Bootstrapping - Example: Prostate Volume

The above process is illustrated in \@ref(fig:prostate-vol). Data on prostate volume in 307 prostate cancer patients demonstrates a right-skewed distribution (A). An empirical distribution from a sample of 100 of these patients mirrors this right skew, and is used as the "bootstrap population" (B) for further re-sampling. As the bootstrap population is re-sampled more and more times, the "bootstrap distribution" of the sample means generated (C and D) gradually tends towards a normal distribution. The 95% \acr{CI} is given by the bounds defining the middle 95% of the bootstrap distribution of estimated means, as shown.

![(\#fig:prostate-vol)Histograms demonstrating distribution of prostate volumes in patients with prostatic cancer, taken from Cata et al 2011[@cata_blood_2011] via the R package `medicaldata`[@medicaldata]. A) Distribution from whole study population of 307 patients with non-missing data, exhibiting right-skew. B) Distribution from random sample of 100 patients, still exhibiting right-skew. C) Bootstrap distribution generated by re-sampling 1,000 bootstrap samples from the original sample of 100 patients, right-skew less apparent. D) Bootstrap distribution generated by re-sampling 100,000 bootstrap samples from the original sample of 100 patients, approaching normality. 95% confidence intervals are demonstrated in plots C and D by marking the 2.5th and 97.5th centiles.](9_Appendices_files/figure-latex/prostate-vol-1.pdf) 

\newpage

## Bootstrapping - Relevance to WME

In current implementations of \acr{WME}, the \acr{WME} estimate of the causal effect ($\hat{\beta}_{WME}$) is calculated as described in Bowden et al[@bowden_consistent_2016], and the 95% \acr{CI} is generated separately using bootstrapping, though notably not using the method described above. 

The bootstrapping process begins similarly, with re-sampling undertaken (a default of $k = 1000$ times) to generate $k$ bootstrap samples $x^{*1}, x^{*2},...x^{*k}$. Each individual bootstrap sample $x^{*i}$ is used to estimate the causal effect using the \acr{WME} method $\hat{\beta}^{*i}_{WME}$, and thus a bootstrap distribution of $k$ values of \acr{WME} is created, $\hat{\beta}^{*1}_{WME},  \hat{\beta}^{*2}_{WME}....\hat{\beta}^{*k}_{WME}$. 

At this stage, however, the bootstrap distribution is then assumed to be approximately normally distributed without verifying this assumption. The 95% \acr{CI} of the bootstrap estimate is then calculated as 1.96 \acr{SD}s of the bootstrap distribution either side of the mean estimate, i.e. $\hat{\beta}_{WME} \pm 1.96  \times SE$. This approach may be problematic for several reasons. 

Although \acr{CLT} leads us to expect that the bootstrap distribution will approach normality as the number of bootstrap iterations $k$ increases, the extent to which this occurs for a given $k$ may depend on the inital distribution of values in the population $X$, and so also on the distribution in the sample/bootstrap population $x$. If the true distribution of values is very non-normal, as may be the case for traits determined by complex genetic and environmental influences, it may take relatively more bootstrap iterations for the bootstrap distribution to become sufficiently normal to assume mean and \acr{SD} accurately describe it. 

Additionally, the bootstrap \acr{SE} is inversely proportional to the number of bootstrap iterations $k$, as opposed to the usual standard error (given by $SE = \frac{SD}{\sqrt{n}}$), which is inversely proportional to the square root of the sample size $n$. It is therefore possible to generate smaller \acr{SE}s by increasing the number of bootstrap samples obtained. This may lead to false confidence in estimates generated despite potential issues with initial sample $x$, e.g. if it too small, or sampled in such a way that it is not representative of the underlying population $X$. Although such issues are inherent to any bootstrapping approaches, the usual method of generating bootstrapped \acr{CI}s detailed above uses more information (i.e. using the entire bootstrap distribution) to generate these values than the parameter-based $estimate \pm 1.96 \times SE$ method (i.e. using approximate summary statistics to represent the distribution). The usual method of bootstrap \acr{CI} generation may therefore be expected to highlight any variation or uncertainty present more readily than the parameter-based approach; this would be represented as wider \acr{CI}s.

\newpage

# Appendix: Simulation Code {#appendix-sim}


## Generating Data and Models {#appendix-sim-gen}

The data generating model used was from Appendix 3 of Bowden et al [@bowden_consistent_2016]; the relevant section describing their model is reproduced below:

>_"..._

>\begin{equation} 
U_i = \sum^J_{j=1} \phi_jG_{ij} + \epsilon_i^U
\end{equation}


>\begin{equation} 
X_i = \sum^J_{j=1} \gamma_jG_{ij} + U_i + \epsilon_i^X
\end{equation}

>\begin{equation} 
Y_i = \sum^J_{j=1} \alpha_jG_{ij} + \beta X_i + U_i + \epsilon_i^Y
\end{equation}

>_for participants indexed by $i = 1, . . . , N$, and genetic instruments indexed by $j = 1, . . . , J$._

>_The error terms $\epsilon_i^U , \epsilon_i^X$ and $\epsilon_i^Y$ were each drawn independently from standard normal distributions. The genetic effects on the exposure γj are drawn from a uniform distribution between 0.03 and 0.1. Pleiotropic effects $\alpha_j$ and $\phi_j$ were set to zero if the genetic instrument was a valid instrumental variable. Otherwise (with probability 0.1, 0.2, or 0.3):_

>_1. In Scenario 1 (balanced pleiotropy, InSIDE satisfied), the $\alpha_j$ parameter was drawn from a uniform distribution between −0.2 and 0.2._

>_2. In Scenario 2 (directional pleiotropy, InSIDE satisfied), the $\alpha_j$ parameter was drawn from a uniform distribution between 0 and 0.2._ 

>_3. In Scenario 3 (directional pleiotropy, InSIDE not satisfied), the $\phi_j$ parameter was drawn from a uniform distribution between −0.2 and 0.2._


>_The causal effect of the exposure on the outcome was either $\beta X = 0$ (null causal effect) or $\beta X = 0.1$ (positive causal effect). A total of 10 000 simulated datasets were generated for sample sizes of N = 10 000 and 20 [sic] participants. Only the summary data, that is genetic associations with the exposure and with the outcome and their standard errors as estimated by univariate regression on the genetic instruments in turn, were used by the analysis methods. In the two-sample setting, data were generated on 2N participants, and genetic associations with the exposure were estimated in the first N participants, and genetic associations with the outcome in the second N participants."_ [@bowden_consistent_2016]

To reproduce this model, code was written in R to generate the relevant participant level data. First, a function (`get_simulated_MR_data`) was written which included parameters specified by Bowden et al, and also to allow testing of data simulation:





This initial simulation function generated data in the following format:




A function (`get_models`) was then written to create linear models from each dataset generated as per Bowden et al:





These models generated estimates of the coefficient of gene-exposure association (`coeff_G_X`), coefficient of gene-outcome association (`coeff_G_Y`), and the relevant standard errors of these estimates. The values of parameters inputted were also returned to aid in further testing of data/model generation, i.e. actual gene-exposure associations (`gamma`), pleiotropic effects of invalid instruments (`alpha`), additional pleiotropic effects when \acr{InSIDE} assumption not satified (`phi`), causal effect of exposure on outcome (`beta`) and the proportion of invalid genetic instruments with pleiotropic effects on the outcome (`prop_invalid`).




\newpage
## Testing Generation of Data and Models {#appendix-sim-test}

A series of test plots were used to verify that data were simulated as intended under the various conditions specified by input parameters. Test plots were not created for the parameters `n_participants`, `n_instruments` or `n_datasets`, as the functioning of these parameters could be readily inferred from the structure of the  datasets outputted, as above.

### Proportion of Invalid Instruments
\leavevmode\newline The `prop_invalid` parameter specifies the proportion of invalid genetic instruments simulated, i.e. the proportion of genetic instruments affecting the outcome via direct/pleiotropic effects, and thus not solely via the exposure of interest. If simulated correctly, increasing the value of `prop_invalid` should increase the number of instruments with pleiotropic effects, i.e. instruments with `alpha` $\ne$ 0. With random error terms set to 0 and no causal effect present (i.e. `rand_error = FALSE` and `causal_effect = FALSE`), the estimated gene-outcome coefficient estimated using any given instrument will equal the pleiotropic effects of that instrument (i.e. `coeff_G_Y = alpha`), and therefore will only be non-zero for invalid instruments with non-zero pleiotropic effects on the outcome . Plotting `coeff_G_Y` against `alpha` for simulated data with no causal effect or random error should therefore yield a graph where

- For valid instruments: gene-outcome coefficient = alpha = 0
- For invalid instruments:  gene-outcome coefficient = alpha $\ne$  0, with values spread uniformly between `alpha_min` and `alpha_max`




\newpage
Similarly, with random error terms set to 0 (`rand_error = FALSE`) and no causal effect present (`causal_effect = FALSE`), gene-exposure coefficients estimated for each instrument should exactly match the actual values simulated, i.e. `coeff_G_X = gamma` for all instruments:



\newpage
### Gene-Exposure Coefficient Versus Gene-Outcome Coefficient Plots
\leavevmode\newline For the next phase of testing, a function (`plot_GY_GX`) was written to plot the coefficients for gene-exposure versus gene-outcome as estimated using the previously created linear models:



\newpage
With random error terms set to 0 (`rand_error = FALSE`) and no causal effect present, a graph of gene-exposure coefficients versus gene-outcome coefficients should be a straight line through the origin with gradient = 0; causal effect of $\beta$ = 0.1  present (`beta_val = 0.1`, `causal_effect = TRUE`), the slope of a graph of gene-exposure coefficients versus gene-outcome coefficients from the same sample should be a straight line through the origin with gradient = 0.1:




\newpage
### Random Errors
\leavevmode\newline Re-plotting the same graphs with non-zero random error terms (`rand_error = TRUE`) should produce similar graphs with Gaussian spread around lines passing through the origin with gradients of 0 and 0.1 for no causal effect and causal effect, respectively:



\newpage
### One versus Two Sample MR
\leavevmode\newline Where gene-exposure coefficients and gene-outcome coefficients are estimated from two separate samples rather than one (i.e. `two_sample = TRUE`, simulating 2 sample MR), even with random error terms set to zero, error will be introduced into causal effect estimation through random sampling of different combinations of effect alleles. However, where a causal effect is not present, the effect estimated will consistently be zero regardless of the combinations of alleles sampled, so random error should not be introduced:





















