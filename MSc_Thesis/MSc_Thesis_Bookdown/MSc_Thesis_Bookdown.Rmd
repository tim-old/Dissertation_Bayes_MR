---
title: "Causal Effect Estimation in Mendelian Randomisation Studies - Evaluating a Modern Bayesian Approach to Genetic Pleiotropy Versus Established Weighted Median Methodology"
author: "B233241"
date: "September 2024 - July 2025"
header-includes:
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \usepackage{lmodern}
- \usepackage{caption}
- \captionsetup[figure]{font=10}
bibliography: 
  - Lit_Rev_Refs.bib
  - grateful-refs.bib
csl: vancouver-superscript.csl
link-citations: TRUE
urlcolor: blue
acronyms:
  loa_title: ""
  include_unused: FALSE
  insert_loa: FALSE
  insert_links: TRUE
  id_prefix: "acronyms_"
  sorting: "alphabetical"
  non_existing: "key"
  style: "long-short"
  fromfile: ./_acronyms.yml
---

\newpage

## Acknowledgements {-}

I would like to thank Dr Athina Spiliopoulou for her expertise, kindness, and infinite patience in supervising this dissertation. I thank Professor Paul McKeigue for his input regarding the background and methodology of the project. Finally, my deepest gratitude goes to my wife, for keeping all our plates spinning while I've been busy shouting at my laptop.


## Statement of Originality & Contributions {-}

I confirm that all work is my own except where indicated, and that all sources are clearly referenced. Parts of this dissertation were informed by my participation in a related project with my supervisor's research group, which included comparison of Mendelian randomisation causal estimation methods using similar methodology, i.e. data simulation and citation searching. I confirm that all simulation code, literature searches and analyses contained within this dissertation are solely my own work, produced under the appropriate guidance of my supervisor.


## Word Count {-}

<!-- Your dissertation should be 10,000 words in length (this includes the tables & figures and footnotes but excludes the abstract, table of contents, bibliography, and appendices). When you submit your dissertation, you must attach a word count using your word processing package. This must be reported on the title page. -->

Word count: 
`r 
wordcountaddin::word_count("2_Intro_Background.Rmd") + 
wordcountaddin::word_count("3_Methods.Rmd") +
wordcountaddin::word_count("4_Results.Rmd") +
wordcountaddin::word_count("5_Discussion.Rmd") +
wordcountaddin::word_count("6_Limitations_Recommendations.Rmd") +
wordcountaddin::word_count("7_Conclusions.Rmd")
`
<!-- wordcountaddin::word_count("index.Rmd") +  -->
<!-- wordcountaddin::word_count("9_Appendices.Rmd")  -->

\newpage

<!--chapter:end:index.Rmd-->

# Abstract

## Background

Mendelian randomisation (MR) uses data from observational genetic studies to support causal inference between exposures and outcomes of interest. Pleiotropy - where genetic variants influence outcomes through multiple pathways - can bias MR causal estimates. Inadequate controls for pleiotropy likely contribute to high false-positive causal report rates across MR literature. MR-Hevo is a recently proposed MR methodology claiming superior handling of pleiotropy and fewer false-positive reports of causality versus the established weighted median estimator (WME) method.

## Aims

To evaluate differences in causal effect estimates between WME versus MR-Hevo methods, and to establish whether these may alter conclusions drawn in real-world studies.

## Methods

Outputs from each method were compared through parallel analysis of simulated data, following the published approach used to validate WME. Simulations represented plausible combinations of population parameters and assumption violations. To investigate differences between methods using real-world data, both were applied to a sample of ten highly-cited MR studies reporting WME causal effect estimates alongside sufficient data to allow replication.

## Results

Using simulated data with null causal effect, MR-Hevo demonstrated lower false-positive report rates versus WME across all 24 combinations of parameters/assumption violations considered (mean false-positive report rate 0.41% versus 5.1%). Using simulated data with true causal effect, MR-Hevo demonstrated higher power to detect this, both on average (mean true-positive report rate 31% versus 28%) and in most cases considered (14 of 24). Cases with higher true- and false-positive report rates for WME versus MR-Hevo correlated with conditions biasing away from the null, suggesting MR-Hevo estimates may be more robust to assumption violations. Re-analysis of highly-cited MR studies found poor reproducibility of published WME estimates in 4 of 10 studies included. Causal effect estimates were similar in magnitude between MR-Hevo and WME; conclusions regarding presence of causality were consistent between both methods across all 10 studies.

## Conclusions

Compared to WME, MR-Hevo exhibited lower false-positive report rates and less perturbation by assumption violations. Across published MR literature reporting a causal effect, re-analysis using MR-Hevo may change conclusions in a minority of cases. Future work should investigate the non-reproducibility of MR results observed.


**Word count:** `r wordcountaddin::word_count(here::here("1_Abstract.Rmd"))`

\newpage

<!--chapter:end:1_Abstract.Rmd-->

# Introduction and Background

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE, 
                      message = FALSE, 
                      error = FALSE,
                      include = FALSE,
                      cache = TRUE, 
                      dev = "png", 
                      dpi = 500)

library(ggdag)
library(here)
library(tidyverse)
library(bookdown)
library(TwoSampleMR)
library(acronymsdown)

# Load University of Edinburgh colour palette
source(here("Script", "edin_uni_colours.R"))

# Load pre-formatted plot template - call to ggplot with UoE colours
source(here("Script", "edin_fig_style.R"))

# Load function scripts
source(here("Script", "simulation_functions.R"))

```


## Introduction to Mendelian Randomisation (MR)

Epidemiology is the study of determinants and distribution of disease across populations; a common epidemiological study aim is therefore to seek evidence as to whether a given exposure (e.g. cigarette smoking) may cause a given outcome (e.g. lung cancer) [@coggon_chapter_2003]. Logistics limit experimental interventions across large groups, so insights into associations between exposures and outcomes are gleaned from observational data of people in the population of interest. Comparing health outcomes between individuals with different levels of a particular exposure may highlight potential links, e.g. higher cancer incidence in those who smoke more is consistent with a causal role for cigarettes in carcinogenesis [@coggon_chapter_2003]. 

However, correlation does not prove causation. A key epidemiological challenge is accounting for so-called "confounding" factors; these are other variables, associated with both the exposure and the outcome of interest, which represent an alternative causal explanation for any exposure-outcome links observed[@martens_instrumental_2006]. If smokers also drink more alcohol than non-smokers, then an observed link between smoking and increased cancer risk could plausibly be caused by increased alcohol exposure, either partially or entirely. Another potential issue with observational data is "reverse causation", where the presumed outcome is in fact a cause of the exposure; this might be the case if a cancer diagnosis drove individuals to drink and smoke more, and data were collected without respect to exposure timings.

\acr{MR} is a methodology intended to support causal inference from observational data. It applies the principles of \acr{IV} analysis to genetic data, performing a type of natural experiment often likened to a \acr{RCT} [@hernan_instruments_2006]. 

In a properly conducted \acr{RCT}, causality can be inferred due to a randomisation process being used as an "instrument" to allocate different levels of exposures to different experimental groups. If groups are randomly allocated, any confounding variables which might otherwise influence exposure-outcome relationships should be evenly distributed between groups, whether these confounders are known or not. As such, there should be no systematic differences between individuals from different groups in the exposure of interest - that is, there should be no bias [@stel_instrumental_2013]. Statistical methods can quantify the probability that any observed outcome differences could have occurred by chance, and thereafter any outcome differences can be interpreted as caused by exposure differences. As allocation and receipt of exposures is known to precede outcome measurements, reverse causality is impossible.

In \acr{MR}, naturally occurring genetic variants - “genetic instruments” – are chosen based on their known association to an exposure of interest. Random assignment of alleles (i.e. variants of a given gene) from parents to offspring during meiosis creates randomisation analagous to that performed for an \acr{RCT} – both measured and unmeasured confounders should be distributed evenly between the groups created. Such genetic randomisation should therefore enable valid causal inference, provided that assumptions of \acr{IV} analysis are met [@davies_reading_2018].

## Causal Effect Estimation in MR

At its simplest, the relationship between two continuous variables - an exposure $X$ and outcome $Y$ - can be represented as a linear model:

\begin{equation} 
Y = \alpha + \beta X + \epsilon
\end{equation}

where $\alpha$ represents all non-$X$ determinants of $Y$, $\beta$ is the causal effect of $X$ on $Y$ and $\epsilon$ is an error term. The $\beta$ term is a numerical measure of strength of causal exposure-outcome association, where:

  - $\beta = 0$ implies no causal link between exposure and outcome
  - $\beta > 0$ implies $X$ causes $Y$
  - $\beta < 0$ implies $X$ prevents $Y$ 
  
To estimate a causal effect using a genetic variant in an \acr{IV} analysis, three key assumptions must be met [@lousdal_introduction_2018]:

1.	Relevance – the genetic variant must be associated with the exposure of interest
2.	Independence – the genetic variant is independent of confounders of the relationship between exposure and outcome
3.	Exclusion restriction – the genetic variant must not be associated with the outcome except via the exposure

These assumptions are represented graphically in Figure \@ref(fig:DAG-assumptions-plot). 

```{r DAG-tib}

# Set up data for base case MR directed acyclic graph
MR_DAG_coords <- list(x = c(G = 0, X = 1, Y = 2, U = 1.5),
                      y = c(G = 0.5, X = 0.5, Y = 0.5, U = 1))


base_dag_tib <- dagify(Y ~ X + U,
                       X ~ G + U,
                       labels = c("G" = "Genetic Variant",
                                  "X" = "Exposure",
                                  "Y" = "Outcome",
                                  "U" = "Confounders"),
                       coords = MR_DAG_coords,
                       exposure = "X",
                       outcome = "Y") %>% 
  tidy_dagitty() 

base_dag_tib


```

```{r DAG-base-plot}

# Plot
base_dag_plot <- base_dag_tib %>% 
  # ggplot(aes(x = x,
  #            y = y,
  #            xend = xend,
  #            yend = yend,
  #            )) +
  ggdag(node = FALSE) +
  geom_dag_edges(edge_width = 1.1) +
  geom_dag_text(col = "black",
                fontface = "italic",
                size = 10
                ) +
  theme_dag() +
  scale_adjusted()

base_dag_plot


```

```{r DAG-assumptions-plot, include=TRUE}
#| fig.id="DAG-assumptions-plot",
#| fig.cap="Causal diagram illustrating the relationships between genetic instrument _G_, exposure _X_, outcome _Y_ and confounders of the exposure-outcome relationship _U_ in Mendelian randomisation studies. Blue text & crosses represent key assumptions to ensure valid inference of causal effect of _X_ on _Y_ using _G_ as an instrumental variable. Red text represents violations of these assumptions that may lead to invalid inference through opening of alternate causal pathways. Greek characters represent the key parameters/association coefficients to be estimated. Adapted from Burgess et al 2016[@burgess_sensitivity_2016]"

# Formatting for assumption labels
assumption_label_col <- edin_muted_blue_hex
assumption_label_size <- 4
assumption_viol_label_col <- edin_burgundy_hex
assumption_viol_label_size <- 4
assumption_viol_cross_size <- 6

# Formatting for parameter labels
parameter_label_col <- edin_spruce_grey_hex
parameter_label_size <- 5

# parameter_vals <- list(size = 4,
#                        fontface = "italic", 
#                        colour = "red")


assumptions_dag_plot <- base_dag_plot +
  # Line - Direct effects/uncorrelated pleiotropy/alpha, IV assumption 3
  geom_dag_edges_arc(aes(x = 0,
                         xend = 2,
                         y = 0.5,
                         yend = 0.5,
                         edge_linetype = "dotted"),
                     curvature = -0.4,
                     arrow = grid::arrow(length = grid::unit(12, "pt"), type = "closed")) +
  # Line - Direct effects on confounder/correlated pleiotropy, IV assumption 2
  geom_dag_edges_arc(aes(x = 0,
                         xend = 1.5,
                         y = 0.5,
                         yend = 1,
                         edge_linetype = "dotted"),
                     curvature = 0.3,
                     arrow = grid::arrow(length = grid::unit(12, "pt"), type = "closed")
                     ) +
  # # Label - alpha
  # geom_dag_text(x = 1, 
  #               y = 0.25, 
  #               label = "\U03B1", 
  #               size = parameter_label_size,
  #               fontface = "italic", 
  #               colour = parameter_label_col) +
  # Label - beta
  geom_dag_text(x = 1.5, 
                y = 0.55, 
                label = expression(beta), #"\U03B2",
                size = parameter_label_size,
                fontface = "italic",
                colour = parameter_label_col
                ) +
  # Label - gamma (Y)
  geom_dag_text(x = 0.5, 
                y = 0.55, 
                label = expression(gamma), #"\U03B3",
                size = parameter_label_size,
                fontface = "italic",
                colour = parameter_label_col
                ) +
  # Label - Gamma (7)
  geom_dag_text(x = 1, 
                y = 0.001, 
                label = expression("|- - - - - - - - - - - - - - - - - - -"~Gamma~ "=" ~ gamma * beta~"- - - - - - - - - - - - - - - - - - -|"), 
                #label = expression("\\~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~"~Gamma~ "=" ~ gamma * beta~"~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~/"), 
                size = parameter_label_size,
                fontface = "italic", 
                colour = parameter_label_col) +
  # Label - IV1
  geom_dag_text(x = 0.5, 
                y = 0.45, 
                label = "Assumption 1: Relevance", 
                size = assumption_label_size, 
                colour = assumption_label_col) +
  # Label - IV2
  geom_dag_text(x = 0.4, 
                y = 1.05, 
                label = "Assumption 2:\nIndependence", 
                size = assumption_label_size, 
                colour = assumption_label_col) +
  # Cross - IV2
  geom_dag_text(x = 0.65, 
                y = 1, 
                label = "X", 
                size = assumption_viol_cross_size,
                fontface = "bold", 
                colour = assumption_label_col) +
  # Label - Correlated Pleiotropy
  geom_dag_text(x = 0.85, 
                y = 0.875, 
                label = "Correlated Pleiotropy\n(InSIDE Assumption Violated)", 
                size = assumption_viol_label_size,
                #fontface = "italic", 
                colour = assumption_viol_label_col) +
  # Label - IV3
  geom_dag_text(x = 1, 
                y = 0.16, 
                label = "Assumption 3: Exclusion\nRestriction", 
                size = assumption_label_size, 
                colour = assumption_label_col) +
  # Cross - IV3
  geom_dag_text(x = 1, 
                y = 0.06, 
                label = "X", 
                size = assumption_viol_cross_size,
                fontface = "bold", 
                colour = assumption_label_col) +
  # Label - Uncorrelated Pleiotropy
  geom_dag_text(x = 1, 
                y = 0.27, 
                label = "Uncorrelated Pleiotropy", 
                size = assumption_viol_label_size,
                #fontface = "italic", 
                colour = assumption_viol_label_col) #+
  #labs(#title = "Key Assumptions in Mendelian Randomisation",
       #subtitle = "", #[@burgess_sensitivity_2016]
       #caption = "\nG: Genetic Instrument, U: Confounders, X: Exposure, Y: Outcome\n" )

assumptions_dag_plot

```


Typically, \acr{MR} studies estimate the causal effect using several genetic instruments; the causal effect estimate derived from the $jth$ instrument is denoted $\hat{\beta}_j$. Let:

\begin{equation} 
X|G_j = \gamma_0 + \gamma_j G_j + \epsilon_{X_j}
\end{equation}

\begin{equation} 
Y|G_j = \Gamma_0 + \Gamma_j G_j + \epsilon_{Y_j}
\end{equation}

be linear models for exposure and outcome, respectively, given a specific genetic instrument $G_j$, where:

  - $\gamma_0$ and $\Gamma_0$ reflect intercept values corresponding to the predicted value for $X$ and $Y$, respectively, when $G_j = 0$ (i.e. these are the predicted values for an individual carrying the non-effect allele of the genetic variant)

  - $\gamma_j$ and $\Gamma_j$ are coefficients of association with the genetic variant, representing the extent to which an effect allele of $G_j$ will perturb the value of $X$ or $Y$ versus the non-effect allele

  - $\epsilon_{X_j}$ and $\epsilon_{Y_j}$ are error terms, representing effects of variables not explicitly included in the model, e.g. confounders of the exposure-outcome relationship ($U$ in the causal diagram), and genetic contributions outside of $G_j$.

It can be shown that a simple causal effect estimate for the exposure on the outcome can be obtained from a single genetic instrument by the Wald method, dividing the coefficient of gene-outcome association by the coefficient of gene-exposure association, i.e.:

\begin{equation} 
\hat{\beta}_j = \frac {\hat{\Gamma}_j} {\hat{\gamma}_j}
\end{equation}

These coefficients of gene-exposure and gene-outcome association ($\hat{\gamma}$ and $\hat{\Gamma}$) can be obtained from a \acr{GWAS}, which quantifies associations between small genetic variations - known as \acr{SNP}s - and various phenotypes. Each genetic instrument selected from a \acr{GWAS} may be valid or invalid, depending on it meeting the above assumptions. The overall causal effect estimate $\hat{\beta}$ from any given \acr{MR} method will typically seek to pool effect estimates from several instruments so as to minimise effects of any invalid instruments included, e.g. by removing/down-weighting contributions of genetic instruments which might be violating one or more assumptions. This is equivalent to plotting all estimated coefficients of gene-outcome association ($\bar{\Gamma}$) versus all estimated coefficients of gene-exposure association ($\bar{\gamma}$) for the set of instruments, then using the gradient of a regression line through the points as the causal effect estimate $\hat{\beta}$; picking an \acr{MR} methodology is analogous to choosing the method to draw the line of best fit (Figure \@ref(fig:Gamma-gamma-plot)). For binary outcomes, the coefficients of gene-outcome association ($\bar{\Gamma}$) are expressed as log odds ratios ($log(OR)$) for estimating the causal effect, and the causal effect estimate can be converted to an \acr{OR} through exponentiation, i.e.:

\begin{equation} 
OR = e^{\hat{\beta}}
\end{equation}

```{r Gamma-gamma-plot, include=TRUE}
#| fig.id="Gamma-gamma-plot",
#| fig.cap="Simulated MR Study on 10,000 individuals using 25 genetic instruments, of which 30% are invalid (red points) and introduce directional pleiotropic effects. The true value of the exposure-outcome causal effect is 0.25 (grey line, causal effect represented by gradient). Regression using an unadjusted least-squares linear model (light blue line) results in a biased estimate in the positive direction due to the influence of the invalid instruments. Using the Weighted Median Estimator method (pink line) attenuates the effects of the invalid instruments, resulting in an estimate closer to the true value. Adapted from Bowden et al 2016[@bowden_consistent_2016]"

true_beta <- 0.25

# Simulate individuals' data
causal_data <- get_simulated_MR_data(n_participants = 10000,
                                     n_instruments = 25,
                                     n_datasets = 1,
                                     prop_invalid = 0.3,
                                     causal_effect = TRUE, 
                                     beta_val = true_beta, 
                                     balanced_pleio = FALSE)

# Get models inc estimates of  Coeff_G_X/Coeff_G_Y
causal_models <- tibble(get_models(causal_data)[[1]])

# Assign values to vectors
coeff_G_X_vect <- causal_models$coeff_G_X
coeff_G_Y_vect <- causal_models$coeff_G_Y
coeff_G_X_SE_vect <- causal_models$coeff_G_X_SE
coeff_G_Y_SE_vect <- causal_models$coeff_G_Y_SE


# Calculate WME estimates
causal_models_WME <- mr_weighted_median(b_exp = coeff_G_X_vect,
                                        b_out = coeff_G_Y_vect,
                                        se_exp = coeff_G_X_SE_vect,
                                        se_out = coeff_G_Y_SE_vect,
                                        parameters = list(nboot = 1000)
                                        )
# Calculate gradients for plotting
lm_gradient <- round(coefficients(lm(causal_models$coeff_G_Y ~ 0 + causal_models$coeff_G_X)[1]), digits = 2)

WME_gradient <- round(causal_models_WME$b, digits = 2)

# Extra tibble for plotting
lines_tib <- tibble(intercept = c(0,0,0),
                    slope = c(true_beta, lm_gradient, WME_gradient),
                    values = c("True", "Linear", "WME")
                    )

# Plot
Gamma_gamma_plot <- causal_models %>%
  mutate(Invalid = (alpha != 0)) %>% 
  plot_template() +
  aes(x = coeff_G_X, 
      y = coeff_G_Y) + 
  # Instruments
  geom_point(aes(fill = Invalid),
             pch = 21,
             #alpha = 0.75,
             size = 3) +
  # Lines
  geom_abline(data = lines_tib,
              aes(colour = values,
                  slope = slope,
                  intercept = intercept),
              size = c(1.5, 0.75, 0.75)
              ) +
  scale_colour_manual(name = "Effect Estimate",
                      values = c("True" = edin_spruce_grey_hex,
                                 "Linear" = edin_bright_blue_hex,
                                 "WME" = edin_bright_pink_hex),
                      labels = c("True" = "True \U03B2", 
                                 "Linear" = "Least Squares",
                                 "WME" = "Weighted Median"),
                      guide = "legend") +
  # Add betas
  ## True
  geom_text(label = paste0("True \U03B2 = ", true_beta), #beta
            x = 0.08, # labels with gradient (causal effect estimate)
            y = 0.01,
            size = 3.5, 
            fontface = "italic",
            colour = edin_spruce_grey_hex, 
            hjust = 0, 
            data = . %>% slice_head() # prevent over-printing
  ) +
  ## Linear
  geom_text(label = expression("Least Squares" ~ hat(beta) ~ "= 0.61"), #beta
            x = 0.075, # labels with gradient (causal effect estimate)
            y = 0.09,
            size = 3.5, 
            #fontface = "bold",
            colour = edin_bright_blue_hex, 
            hjust = 0, 
            data = . %>% slice_head() # prevent over-printing
  ) +
  ## WME
  geom_text(label = expression("WME" ~ hat(beta) ~ "= 0.3"), #beta
            x = 0.088, # labels with gradient (causal effect estimate)
            y = 0.045,
            size = 3.5, 
            #fontface = "bold",
            colour = edin_bright_pink_hex, 
            hjust = 0, 
            data = . %>% slice_head() # prevent over-printing
  ) +
  # Colours for valid/invalid instruments
  scale_fill_manual(values = c(edin_muted_turquoise_hex, edin_burgundy_hex),
                   labels = c("Valid", "Invalid")) +
  #Colours for regression lines
  labs(#title = plot_title,
    #x = "gene-exposure Coefficient ( \U0302\U03B3)",  #U1D67 small gamma
    #y = "gene-outcome Coefficient ( \U0302\U1D26)") + #U0393 big Gamma
    x = expression("Gene-Exposure Coefficient (" ~hat(gamma)~ ")"),  
    y = expression("Gene-Outcome Coefficient (" ~hat(Gamma)~ ")"),
    colour = "Regression Lines",
    fill = "Instruments") +
  #guides(guide)
  xlim(-0.01, 0.125)
  
Gamma_gamma_plot


```

## Violations to Assumptions

In practice, only the relevance assumption can be directly tested and proven. Typically, genetic variants for \acr{MR} studies are selected as instruments based on their observed strength of association with exposures of interest in one or more \acr{GWAS}. Sufficient gene-exposure association can be partly assured by selection using an appropriate genome-wide significance level (e.g. $p < 10 ^{-8}$) during this instrument selection. Statistical testing can also further quantify the gene-exposure relationship; commonly used measures include the $R^2$ statistic, representing the proportion of variance in the exposure explained by the genotype, and the related $F$-statistic, which additionally accounts for the sample size under investigation [@richmond_mendelian_2022]. An $F$-statistic of $\ge$ 10 is generally considered to represent a strong enough gene-exposure association to consider a genetic instrument for use [@martens_instrumental_2006].

The assumptions of independence and exclusion restriction depend on all determinants of the outcome, both known and unknown; as such, these can never be proven absolutely. Various methods have been proposed to quantify and account for violations of these two additional assumptions, including the weighted median estimator, described below [@bowden_consistent_2016].
 
The main methods to avoid violations of the independence assumption relate to appropriate controls for population structure, to avoid confounding due to ancestry or population stratification. For example, in two-sample MR studies, where gene-exposure and gene-outcome coefficients are estimated from two separate \acr{GWAS} studies, spurious exposure-outcome associations can be generated by confounding due to underlying differences in e.g. allele frequency, baseline disease risks etc. between ancestrally different populations; techniques such as principle components analysis can help control for such differences [@richmond_mendelian_2022].

Exclusion restriction is a particularly troublesome issue in MR, due to so-called (horizontal) genetic pleiotropy, which is abundant among genetic variants associated with disease traits[@sivakumaran_abundant_2011]. A genetic variant has “pleiotropic” effects if it influences several traits simultaneously through its involvement in multiple biological pathways; such alternative biological pathways - and the resulting pleiotropic effects - are often unknown. Pleiotropic effects open unmeasured causal pathways between a genetic instrument and the outcome (Figure \@ref(fig:DAG-assumptions-plot)), thus introducing bias in the \acr{MR} estimate of the association between exposure and outcome. As pleiotropy influences outcome separate to the path involving the exposure of interest, the term "direct effects" is also used[@hemani_evaluating_2018]. Where pleiotropic effects are in both positive and negative directions with a mean of zero - "balanced pleiotropy" - then they only add variance to the causal effect estimate, making inference more uncertain [@morrison_mendelian_2020]. By contrast, "directional pleiotropy", where the mean of pleiotropic effects is non-zero, may introduce bias [@bowden_consistent_2016] (Figure \@ref(fig:Gamma-gamma-plot)). Note that, due to sampling error, the distribution of pleiotropic effects in a finite sample of genetic instruments may not reflect the true distribution across all possible genetic instruments for a given trait. For example, even where balanced pleiotropy is present across all genetic variants influencing a trait, bias could still be introduced into \acr{MR} estimates of causal effect if a sample of instruments used happens (by chance) to have a non-zero mean pleiotropic effect on the outcome; the probability of this occuring reduces as the number of instruments used increases. In general, as the number of instruments used tends towards infinity, balanced pleiotropy will tend to introduce more variance than bias into causal effect estimates, and directional pleiotropy will tend to introduce bias more consistently than any additional variance it contributes.

If an additional causal pathway acts between gene $G$ and outcome $Y$ via a confounding factor $U$, then the magnitude of direct - and therefore overall - effects of $G$ on $Y$ will correlate with the effects of $G$ on $X$ (i.e. $\Gamma \propto \gamma$), and "correlated pleiotropy" is present. If an additional causal pathway acts directly between gene $G$ and outcome $Y$ independent of both exposure $X$ and confounders $U$, this results in "uncorrelated pleiotropy" (Figure \@ref(fig:DAG-assumptions-plot)). Both correlated and uncorrelated pleiotropy can introduce bias which distorts the estimate of the true causal effect. In general, correlated pleiotropy is far more challenging to account for - potentially impossible using \acr{MR} methods alone. Any attempt to statistically describe associations between genes, exposures and outcomes in the presence of correlated pleiotropy will struggle to identify a unique model - different parameterisations where different proportions of overall gene-outcome association are subsumed into the confounder-outcome association may be equally plausible given available observational data. For this reason, several MR methods explicitly require an additional assumption of \acr{InSIDE}, i.e no correlated pleiotropy to be present [@grant_bayesian_2024].

## Weighted Median Estimator (WME)

A common approach to produce exposure-outcome causal effect estimates robust to violations of the exclusion restriction assumption is the \acr{WME}  method, proposed by Bowden et al [@bowden_consistent_2016]. 

In \acr{WME} analysis, several genetic instruments are used to estimate the exposure-outcome causal effect $\hat{\beta}$. Each instrument is known to be associated with the exposure of interest, but an unknown proportion of these instruments may be invalid due to pleiotropic genetic effects. The median causal effect will provide a consistent effect estimate despite presence of pleiotropic effects, provided that <50% of included instruments are invalid. However, the simple median is an inefficient estimator - it weights estimates from all included instruments equally, without accounting for differences in precision of estimates obtained from each instrument, or by extension the factors influencing precision (e.g. sample size)[@bowden_consistent_2016].

\acr{WME} therefore assigns a weight to each genetic instrument’s estimate of the causal effect according to the inverse of the variance of the estimate; these weighted effect estimates are used to construct a cumulative distribution function for the value of the causal effect across the range of values estimated based on each of the instruments. The 50th percentile of this distribution can then be taken as a “weighted median estimate” of the true causal effect, theoretically producing consistent causal estimates even if up to 50% of the included information comes from invalid instruments [@bowden_consistent_2016]. An example of \acr{WME} attenuating the effects of invalid instruments is shown in Figure \@ref(fig:Gamma-gamma-plot).

## Issues With WME Confidence Intervals

\acr{WME} calculation methods are available via several prolific \acr{MR} tools: the R packages `MendelianRandomization`[@yavorska_mendelianrandomization_2017] and `TwoSampleMR`, and the MR-Base web platform[@hemani_mr-base_2018]. \acr{WME} is now commonly used either as the primary method or as a sensitivity analysis to account for pleiotropic effects in a large number of \acr{MR} studies. \acr{WME}'s cited "breakdown level" of 50% invalid instruments suggests that, in the vast majority of cases, \acr{WME} causal effect estimates should be robust to the presence of pleiotropic effects[@bowden_consistent_2016]. Despite this, a growing concern in the field of \acr{MR} is high Type 1 error rates (i.e. frequently declaring a causal effect between exposures and outcomes where none is actually present)[@stender_reclaiming_2024]. If \acr{WME} causal estimates are indeed robust to pleiotropy as claimed, another possible explanation for the method allowing null hypotheses to be falsely accepted would be if the \acr{CI} it reports for its causal estimates were inappropriately narrow.

\acr{CI}s are a measure of the precision of an effect estimate, representing the range of values expected to contain the true effect given the observed variance of data around the observed average effect. Two key sources of uncertainty lead to variance in \acr{MR} causal effect estimates:

1. Uncertainty around estimation of the gene-exposure and gene-outcome coefficients ($\hat{\gamma}$ and $\hat{\Gamma}$).

2. Uncertainty around the presence and magnitude of pleiotropic effects of included instruments.

All commonly available tools to calculate \acr{WME} implement the original method for generating the 95% \acr{CI}, using "bootstrapping" methodology to re-sample coefficients and causal estimates derived from each instrument. However, this approach only accounts for uncertainty from Point 1 (estimation of $\hat{\gamma}$ and $\hat{\Gamma}$), and may therefore under-estimate the total variance relevant to causal effect estimation. A fuller explanation of the theoretical issues with this approach, together with an overview of bootstrapping in general, is presented in Appendix \@ref(appendix-boot).

In brief, this method would be expected to lead to \acr{CI}s which are too narrow, giving over-confidence in the causal effect estimates obtained, and therefore inflated Type 1 error rates.  Given the widespread use of \acr{WME} across \acr{MR} literature, this issue with its \acr{CI} generation could potentially have far-reaching consequences.

## MR-Hevo

MR-Hevo is an R package implementing an alternative approach to \acr{MR} causal estimation. It uses Bayesian methodology to estimate MR causal effects and corresponding \acr{CI}s. 

In general, Bayesian methods can estimate parameters in the following way[@clyde_chapter_2022]:

1. A "prior" is specified - this is a probability distribution which represents existing beliefs about likely values of that parameter (e.g. based on data from previous studies), 
2. Further data is collected
3. The prior is updated based on the new data to form a "posterior" probability distribution, i.e. an improved representation of likely values of the parameter is created which incorporates the new information available


In this case, MR-Hevo directly addresses possible pleiotropy through use of a prior probability distribution which models pleiotropic effects of instruments on the outcome. The chosen prior distribution (a regularised hierarchical horseshoe, building on the work of Piironen & Vehtari[@piironen_sparsity_2017]) represents existing knowledge that most genetic instruments will not exert pleiotropic effects on the outcome, but some will, and these pleiotropic effects may be large. The R implementation of MR-Hevo then uses the probabilistic programming language, Stan, to directly sample the posterior probability distribution of pleiotropic effects on the outcome[@mckeigue_inference_2024]. Essentially, this process involves using a computationally intensive, simulation based, "trial-and-error" approach using Markov chain Monte Carlo algorithms to perform inference over all model parameters and the available data[@homan_no-u-turn_2014; @hamra_markov_2013]. 

Once the joint posterior distribution over all model parameters has been sampled, it is possible to obtain the marginal likelihood for the causal effect parameter given the data by dividing the posterior distributions by the prior. This computation marginalises over the pleiotropic effects, i.e. integrates over all possible values for these effects, thus removing their influence on other model parameters. This approach accounts for both main sources of uncertainty in \acr{MR} studies, and also allows classical hypothesis testing for the maximum likelihood estimate of the causal effect, including calculation of a p-value from the marginal likelihood[@mckeigue_inference_2024].


## Aims and Objectives

The main aim of this study was to compare the outputs and resulting conclusions of MR-Hevo versus \acr{WME} causal effect estimation methods in \acr{MR} studies. In particular, this study aims to demonstrate if the \acr{WME} approach gives over-confident causal estimates in the presence of pleiotropy, and whether this issue is more correctly handled by the MR-Hevo approach as its creators suggest. This will be achieved through addressing the research questions and objectives as outlined below:


### Research Questions: {-}

1. How do \acr{MR} causal effect estimates from MR-Hevo differ versus the weighted median estimator?
2. Do conclusions of existing MR studies using weighted median causal effect estimation change if MR-Hevo methods are used?

### Objectives: {-}

1. Quantify the bias of MR-Hevo causal estimates for simulated data under differing sets of common assumptions, with reference to the weighted median estimator
2. Quantify the variance of MR-Hevo causal estimates for simulated data under differing sets of common assumptions, with reference to the weighted median estimator
3. Compare the conclusions drawn from MR-Hevo causal effect estimation versus the weighted median estimator on real-world data



\newpage

<!--chapter:end:2_Intro_Background.Rmd-->

# Methods {#Methods}

```{r setup3, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Simulation Study

To establish differences in \acr{MR} causal estimates of MR-Hevo relative to WME, the bias and variance of estimates from both methods were evaluated using simulated datasets with known parameter values.

### Data Simulation

To aid comparability with existing methods and literature, the simulation methodology of the original WME exposition was reproduced based on published models and parameters in Appendix 3 of its supplementary materials[@bowden_consistent_2016]. Full details of simulation reproduction, including code and validation of outputs, is presented in Appendix \@ref(appendix-sim). 

In brief, simulations were created based on three different scenarios, each representing a common set of assumptions about underlying data used for MR. Each scenario poses an increasing challenge to valid inference using any given MR causal estimation methodology than the previous assumption set. Without loss of generality, all instruments are simulated to have a positive effect on the exposure:

1. Balanced pleiotropy, InSIDE assumption satisfied - A proportion of invalid genetic instruments are present and introduce pleiotropic effects uncorrelated with the instrument strength. These pleiotropic effects were simulated from a uniform distribution centered around zero, and were equally likely to be positive as negative.

2. Directional pleiotropy, InSIDE assumption satisfied - A proportion of invalid genetic instruments are present and introduce pleiotropic effects on the outcome which are in the positive direction only. The magnitude of these pleiotropic effects on the outcome is uncorrelated with the magnitude of instrument effects on the exposure.

3. Directional pleiotropy, InSIDE assumption not satisfied - A proportion of invalid genetic instruments are present and introduce pleiotropic effects on the outcome which are in the positive direction only. The magnitude of these pleiotropic effects on the outcome is correlated with the magnitude of instrument effects on the exposure through action via a confounder.

1,000 simulated datasets of participant-level data were generated for every combination of each scenario and each the following simulation parameters:

  - Proportion of invalid instruments: 0%, 10%, 20% or 30%
  - Number of participants: $n = 10,000$ or $n = 20,000$
  - Causal effect: null ($\beta = 0$) or positive ($\beta = 0.1$)
  
  
The same 25 simulated genetic instruments were used across all datasets, with the status of each as valid/invalid determined by random draw per instrument at the start of each simulation run of 1,000 datasets.

Genotypes were simulated as for a two-sample setting: where number of particpants was $n = 10,000$, then 20,000 genotypes were simulated - 10,000 for the cohort used to estimate gene-exposure association ($\hat{\gamma}$), and a separate cohort of 10,000 used to estimate gene-outcome association ($\hat{\Gamma}$). Parameter values for effect allele frequency were not specified by Bowden et al, though initial testing showed values around 0.5 produced WME causal effect estimates closest to published values when other parameters were matched[@bowden_consistent_2016]. As such, effect allele frequencies were assigned per instrument from a uniform distribution between 0.4 to 0.6. Each effect allele freqency thus generated per instrument was then used as a probability to assign each simulated participant alleles for each instrument via two draws from a binomial distribution, such that each simulated participant had 0, 1 or 2 effect alleles for each instrument. 

### Analysis of Simulated Data

Each dataset generated was analysed using both WME and MR-Hevo methods, via functions from the `TwoSampleMR` and `mrhevo` packages, respectively[@hemani_mr-base_2018; @mckeigue_inference_2024]. Results were aggregated per group of 1,000 simulated datasets corresponding to a particular combination of scenario and parameter values. The mean causal effect estimate, the mean standard errors/\acr{CI}s of the causal effect estimate,  and causality report rate (i.e. percentage of simulated studies reported as a non-null causal effect, with a 95% \acr{CI} for the causal effect estimate not including 0) were reported for both \acr{WME} and MR-Hevo for each combination of scenario/parameter values; these were computed over the 1,000 simulated \acr{MR} studies using the same 25 genetic instruments in the same population.

Results of the above aggregations were tabulated as per Tables 2 [(link)](https://pmc.ncbi.nlm.nih.gov/articles/PMC4849733/table/gepi21965-tbl-0002/) and 3 [(link)](https://pmc.ncbi.nlm.nih.gov/articles/PMC4849733/table/gepi21965-tbl-0003/) of Bowden et al[@bowden_consistent_2016] to allow direct comparisons of the two methods versus each other and versus the published characteristics of other MR causal estimation methods evaluated by Bowden et al[@bowden_consistent_2016].

## Re-Analysis of Published Data

To investigate the potential implications of any differences in performance between WME and MR-Hevo methods, a selection of published studies reporting causal effect estimates using the WME method was re-analysed. A sample size of 10 published studies was pre-selected during study design as a pragmatic compromise between the scope of this project and the need to document frequency of any observed differences. In the original Bowden et al simulation studies, the WME causal estimation method was shown to generate a false-positive report rate of $\ge$ 30% with some parameter/scenario combinations[@bowden_consistent_2016]. Therefore, even this relatively small sample of 10 studies could plausibly demonstrate differences between methods if sufficient instruments with pleiotropic effects are present in included studies, and if the MR-Hevo approach is as appropriately conservative as its creators propose.

In an attempt to characterise the greatest possible impact of using MR-Hevo instead of \acr{WME} (and thus potentially controlling Type 1 error better), studies were chosen for re-analysis based on their number of citations in the wider MR literature. Compared to studies with few or no citations, highly-cited studies would be expected to have a larger impact on their respective fields if their conclusions were to change. In addition, highly-cited works will typically have been submitted to more scrutiny than less-cited works - both during peer review whilst under consideration by journals, and from the wider scientific community following the widespread dissemination evidenced by a high citation count. As such, it would be expected that highly-cited works are likely to be free of significant methodological flaws which may impede interpretation of any re-analysis.

### Citation Search

The Scopus search platform [@noauthor_scopus_nodate] was used on 15/04/2025 to retrieve all articles citing the original weighted median estimator exposition paper [@bowden_consistent_2016]. The articles returned were sorted by the number of times each article itself had been cited, and the resulting list was saved to RIS format in blocks of ten articles for upload into the Covidence evidence synthesis platform[@noauthor_covidence_2025]. Abstracts were screened by a single reviewer (B233241), starting with the most cited article and proceeding in descending order of citation count, against the following inclusion and exclusion criteria:

Inclusion criteria:

- Original two-sample MR study

- Able to determine samples’ ancestry sufficient to establish presence/potential degree of participant overlap between groups

- Reporting $\ge$ 20 human genetic instruments relating to exposure

- Reports details of effect/non-effect alleles

- Regression coefficients and standard errors and/or confidence intervals available for each genetic instrument used
  
- Uses Weighted Median Estimator

Exclusion criteria: 

- Methodology paper, review article, editorial or letter

- English full-text not accessible


Where eligibility could not be determined from abstract screening alone, full texts were retrieved and screened against the same criteria. Screening of abstracts and full texts was undertaken in blocks of ten articles, until the target of ten included studies for reanalysis had been reached. 

Where an article reported multiple exposure-outcome associations, data were only extracted for the association with the highest number of genetic instruments available, or else for the first reported association where several were based on the same number of instruments. Data were extracted from full texts of included studies using a standardised data collection template, which included publication details, citation count, primary study question, degree of potential participant overlap between groups, number/details of genetic instruments used, effect estimates/standard errors calculated, and conclusion regarding causality as determined by the weighted median estimator method. 

## Data Manipulation and Analysis

All simulations, data manipulations and data analyses were performed in `r version$version.string`[@base]. 

For the simulation study, full details of computation are available in Appendix \@ref(appendix-sim).

For citation search data, a standardised data collection form in Microsoft Excel [@microsoft_corporation_microsoft_2018] was used to create .csv files for subsequent analysis in R; Excel's "Get Data" function was also used to extract tables of genetic instruments where these were presented in non-csv format (e.g. pdf). 

Data cleaning for citation search data was primarily undertaken using the Tidyverse suite of R packages [@tidyverse]. A full list of packages used can be found in Appendix \@ref(appendix-pkg). 

Data were manually screened at summary level and relevant features were extracted. Data were checked for completeness, consistency, duplicate values and plausibility. Data were transformed to an appropriate data type, and encoding of genetic variables was standardised into a single format. Instruments missing values for association coefficients and/or \acr{SE}s were excluded from the main analysis, and were imputed as the most extreme values per dataset as a sensitivity analysis. It was noted during early testing that causal effect estimation functions did not operate correctly in the presence of zero-value coefficients of genetic association and/or their standard errors; such zero values were therefore re-coded as an arbitrarily low value of $10^{-100}$.

## Ethical Approval

The protocol for this work has been reviewed and approved by the \acr{UMREG} at the University of Edinburgh, Ethics ID: UM241126. Due to the nature of the project, using simulated and publically available data only, no significant ethical issues were foreseen, and sponsorship was deemed unnecessary by the \acr{UMREG} reviewing panel.



<!--chapter:end:3_Methods.Rmd-->

# Results


```{r setup4, include=TRUE, echo=FALSE}

knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE, 
                      message = FALSE, 
                      error = FALSE,
                      cache = TRUE, 
                      include = FALSE, 
                      dev = "png", 
                      dpi = 500
)

# Load packages
library(tidyverse)
library(magrittr) #bookdown not finding %>%
library(stringr)
library(tidyr)
library(dplyr)
library(bookdown)
library(knitr)
library(TwoSampleMR)
library(rstan)
library(here)
library(cowplot)
library(kableExtra)
library(tables)
library(flextable)
library(ftExtra)
library(officer)
library(gluedown)

# Load University of Edinburgh colour palette
source(here("Script", "edin_uni_colours.R"))

# Load pre-formatted plot template - call to ggplot with UoE colours
source(here("Script", "edin_fig_style.R"))

# Load function scripts
source(here("Script", "simulation_functions.R"))

# Compile model for MR-Hevo
mr.stanmodel <- stan_model(file = here("Script",
                                       "Hevo",
                                       "MRHevo_summarystats.stan"),
                           model_name = "MRHevo.summarystats", 
                           verbose = FALSE)

```

## Simulation Study

### Data Simulation

Data were successfully simulated as intended. A selection of representative visualisations are presented in Figure \@ref(fig:data-sim-validation). Full details of testing used to validate model outputs from parameter inputs are given in Appendix \@ref(appendix-sim-test). The minimum $F$-statistic calculated from simulated instruments across all simulations was >10, indicating that instruments were sufficiently strongly associated with exposure to meet the relevance assumption of \acr{IV} analysis (Tables \@ref(tab:no-causal-sim-summ-display) and \@ref(tab:causal-sim-summ-display)).


```{r data-sim-load}

# --- Load data --- #
## 0% Invalid
no_causal_10k_point0_scen1_models <- readRDS(file = here("Data", "Simulated_Datasets", "no_causal_10k_point0_scen1_models.rds"))
causal_10k_point0_scen1_models <- readRDS(file = here("Data", "Simulated_Datasets", "causal_10k_point0_scen1_models.rds"))

## 10% Invalid
no_causal_10k_point1_scen1_models <- readRDS(file = here("Data", "Simulated_Datasets", "no_causal_10k_point1_scen1_models.rds"))
causal_10k_point1_scen1_models <- readRDS(file = here("Data", "Simulated_Datasets", "causal_10k_point1_scen1_models.rds"))

## 20% Invalid
no_causal_10k_point2_scen2_models <- readRDS(file = here("Data", "Simulated_Datasets", "no_causal_10k_point2_scen2_models.rds"))
causal_10k_point2_scen2_models <- readRDS(file = here("Data", "Simulated_Datasets", "causal_10k_point2_scen2_models.rds"))

## 30% Invalid
no_causal_10k_point3_scen3_models <- readRDS(file = here("Data", "Simulated_Datasets", "no_causal_10k_point3_scen3_models.rds"))
causal_10k_point3_scen3_models <- readRDS(file = here("Data", "Simulated_Datasets", "causal_10k_point3_scen3_models.rds"))


# --- Citation Search --- # 

Citations_Instrument_Data <- read.csv(here("Data", "Citations_Datasets", "Citations_Instrument_Data.csv")) %>% as_tibble() #%>% filter(Instrument !="rs7326482") %>% mutate(N=1)
# Citations_Instrument_Data_2 <- read.csv(here("Data", "Citations_Datasets", "Citations_Instrument_Data.csv")) %>% as.tibble() #%>%filter(Instrument !="rs7326482") %>%  mutate(N=2)

```


```{r data-sim-validation, include=TRUE, fig.height=7}
#| fig.id = "data-sim-validation",
#| fig.cap = "Plots of a representative group of simulated datasets; all simulate genetic instruments from the same index from the same random seed. Left and right columns demonstrate null and positive true causal effects, respectively; the true causal effect is represented by the gradient of the line shown. The scenario and the proportion of invalid (i.e. pleiotropic) genetic instruments changes with each row. a) 0% of instruments invalid, rendering scenario assumptions regarding invalid assumptions irrelevant. b) 10% of instruments invalid, Scenario 1: balanced pleiotropy simulated, though random sampling of these instruments has introduced some directionality; both variance and some bias are introduced to causal effect estimation. c) 20% of instruments invalid, Scenario 2: directional pleiotropy biases in the direction of the invalid instruments. d) 30% of instruments invalid, Scenario 3: directional pleiotropy and InSIDE assumption violation strongly biases towards a positive effect estimate in a manner difficult to statistically distinguish from a true causal effect."

# Get random dataset index
set.seed(1701)
rand_example <- sample(1:1000, 1, replace = FALSE)

# Select random dataset from each scenario
models_list <- list(
  # 0% Invalid
  no_causal_10k_point0_scen1_models[[rand_example]],
  causal_10k_point0_scen1_models[[rand_example]],
  ## 10% Invalid
  no_causal_10k_point1_scen1_models[[rand_example]],
  causal_10k_point1_scen1_models[[rand_example]],
  ## 20% Invalid
  no_causal_10k_point2_scen2_models[[rand_example]],
  causal_10k_point2_scen2_models[[rand_example]],
  ## 30% Invalid
  no_causal_10k_point3_scen3_models[[rand_example]],
  causal_10k_point3_scen3_models[[rand_example]]
)

# Create blank list to receive plots
Gamma_gamma_plots <- as.list(rep(NA, length(models_list)))

# Create plot subtitles
subtitles <- c(
  "0% Invalid",
  "",
  "10% Invalid, Scenario 1",
  "",
  "20% Invalid, Scenario 2",
  "",
  "30% Invalid, Scenario 3",
  ""
)


# Create plots
for(model in 1:length(models_list)){
  
  # Set beta for graph slope
  true_beta <- if_else(model%%2 == 1,
                       true = 0,
                       false = 0.1) 
  
  # Label only left/bottom axes
  y_lab <- if_else(model%%2 == 1,
                   true = "Gene-Outcome\nCoefficient (\U1D26)",
                   false = "") 
  
  x_lab <- case_when(model == length(models_list) - 1 | model == length(models_list) ~ "Gene-Exposure Coefficient (\U03B3)",
                     .default = "") 
  
  # Title Causal/Non-Causal
  causal_title <- case_when(model ==  1 ~ "No Causal Effect",
                            model == 2 ~ "Causal Effect",
                            .default = "") 
  
  # Tag index
  tag_index <- if_else(model%%2 == 1,
                       true = (model+1)/2,
                       false = FALSE) 
  
  # Tag text
  tag_text <- if_else(model%%2 == 1,
                       true = paste0(letters[tag_index], ")"),
                       false = "") 
  
  
  # Plot outline
  Gamma_gamma_plots[[model]] <- models_list[[model]] %>%
    tibble() %>% 
    mutate(Invalid = (alpha != 0)) %>%
    plot_template() +
    aes(x = coeff_G_X,
        y = coeff_G_Y) +
    # Instruments
    geom_point(aes(fill = Invalid),
               pch = 21,
               alpha = 0.75,
               size = 3) +
    # Lines
    geom_abline(colour = edin_uni_blue_hex,
                slope = true_beta,
                intercept = 0,
                size = 1) +
    
    # Add betas
    ## True
    geom_text(label = paste0("True \U03B2 = ", true_beta), #beta
              x = 0.1, # labels with gradient (causal effect estimate)
              y = -0.1,
              size = 3,
              fontface = "italic",
              colour = edin_uni_blue_hex,
              hjust = 0,
              data = . %>% slice_head() # prevent over-printing
    ) +
    # Colours for valid/invalid instruments
    scale_fill_manual(values = c(edin_muted_turquoise_hex, edin_burgundy_hex),
                      labels = c("Valid", "Invalid"),
                      guide = "legend",
                      name = "Instruments") +
    # Labels
    labs(#title = causal_title,
         subtitle = subtitles[model],
         tag = tag_text,
         x = x_lab,
         y = y_lab) +
    theme(legend.position = "none",
          plot.margin = unit(c(0.1,0.1,0.1,0.1), "cm"),
          axis.text = element_text(size = 6), 
          axis.title = element_text(size = 7), 
          subtitle = element_text(size = 6)
          ) +
    xlim(-0.06, 0.2125) +
    ylim(-0.11, 0.25) 
  
}

#Legend
legend <- get_legend(Gamma_gamma_plots[[length(models_list)]] +
                       theme(legend.position = "right")
                     )

plot_two_cols <- plot_grid(plotlist = Gamma_gamma_plots, 
                           rel_widths = c(0.55, 0.45),
                           ncol = 2)


# Plot all
plot_grid(plot_two_cols,
          legend,
          ncol = 2,
          rel_widths = c(1, 0.2))

```

### Analysis of Simulated Data

Due to a coding issue with outputs from MR-Hevo functions, the \acr{SE}s for MR-Hevo causal estimates were not successfully retrieved; all 95% \acr{CI}s were retrieved as intended. To aid comprehension and comparison of below results with regards to variance of causal effect estimates, it was decided to display an estimated \acr{SE} for MR-Hevo. Estimated \acr{SE} was calculated as $(Upper~~CI - Lower~~CI) \div (2 \times 1.96)$, i.e. approximating the bootstrap distribution as normally distributed per the expectation from \acr{CLT} (see Appendix \@ref(appendix-boot)). As such, whilst reported MR-Hevo \acr{CI}s are accurate, MR-Hevo \acr{SE}s are approximate only.

```{r sim-summ-load}

# --- Load results --- #
# No Causal:
no_causal_10k_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "no_causal_10k_scen1_sim_summ_tib.rds"))
no_causal_20k_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "no_causal_20k_scen1_sim_summ_tib.rds"))

no_causal_10k_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "no_causal_10k_scen2_sim_summ_tib.rds"))
no_causal_20k_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "no_causal_20k_scen2_sim_summ_tib.rds"))

no_causal_10k_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "no_causal_10k_scen3_sim_summ_tib.rds"))
no_causal_20k_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "no_causal_20k_scen3_sim_summ_tib.rds"))


# Causal:
causal_10k_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "causal_10k_scen1_sim_summ_tib.rds"))
causal_20k_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "causal_20k_scen1_sim_summ_tib.rds"))

causal_10k_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "causal_10k_scen2_sim_summ_tib.rds"))
causal_20k_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "causal_20k_scen2_sim_summ_tib.rds"))

causal_10k_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "causal_10k_scen3_sim_summ_tib.rds"))
causal_20k_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "causal_20k_scen3_sim_summ_tib.rds"))
```

```{r sim-summ-tibs}

# --- No Causal --- #
# Scenario 1
no_causal_scen1_sim_summ_tib <- bind_rows(no_causal_10k_scen1_sim_summ_tib,
                                          no_causal_20k_scen1_sim_summ_tib
) %>%
  mutate(Scenario = "Scenario 1: Balanced pleiotropy, InSIDE assumption satisfied")

# Scenario 2
no_causal_scen2_sim_summ_tib <- bind_rows(no_causal_10k_scen2_sim_summ_tib,
no_causal_20k_scen2_sim_summ_tib
                                          ) %>%
  mutate(Scenario = "Scenario 2: Directional pleiotropy, InSIDE assumption satisfied")

# Scenario 3
no_causal_scen3_sim_summ_tib <- bind_rows(no_causal_10k_scen3_sim_summ_tib,
                                          no_causal_20k_scen3_sim_summ_tib
) %>%
  mutate(Scenario = "Scenario 3: Directional pleiotropy, InSIDE assumption not satisfied")


# Summary
no_causal_sim_summ_tib <- bind_rows(no_causal_scen1_sim_summ_tib,
                                    no_causal_scen2_sim_summ_tib,
                                    no_causal_scen3_sim_summ_tib
)%>% 
  mutate(WME_Lower_CI = WME_Av - 1.96 * WME_SE,
         WME_Upper_CI = WME_Av + 1.96 * WME_SE,
         Hevo_SE_Calc = round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3),
         Pos_Rate_Diff = Hevo_Pos_Rate - WME_Pos_Rate,
         Hevo_Better = Pos_Rate_Diff < 0)


# --- Causal --- #
# Scenario 1
causal_scen1_sim_summ_tib <- bind_rows(causal_10k_scen1_sim_summ_tib,
                                       causal_20k_scen1_sim_summ_tib
) %>% 
  mutate(Scenario = "Scenario 1: Balanced pleiotropy, InSIDE assumption satisfied")

# Scenario 2
causal_scen2_sim_summ_tib <- bind_rows(causal_10k_scen2_sim_summ_tib,
                                       causal_20k_scen2_sim_summ_tib
) %>% 
  mutate(Scenario = "Scenario 2: Directional pleiotropy, InSIDE assumption satisfied")

# Scenario 3
causal_scen3_sim_summ_tib <- bind_rows(causal_10k_scen3_sim_summ_tib,
                                       causal_20k_scen3_sim_summ_tib
) %>% 
  mutate(Scenario = "Scenario 3: Directional pleiotropy, InSIDE assumption not satisfied")


# Summary
causal_sim_summ_tib <- bind_rows(causal_scen1_sim_summ_tib,
                                 causal_scen2_sim_summ_tib,
                                 causal_scen3_sim_summ_tib) %>% 
  mutate(WME_Lower_CI = WME_Av - 1.96 * WME_SE,
         WME_Upper_CI = WME_Av + 1.96 * WME_SE,
         Hevo_SE_Calc = round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3),
         Pos_Rate_Diff = Hevo_Pos_Rate - WME_Pos_Rate,
         Hevo_Better = Pos_Rate_Diff > 0)
  
#no_causal_sim_summ_tib
```

```{r inline-vals-no-causal}

# --- No Causal --- #
# Mean positive report rates
no_causal_Hevo_mean_pos_rate <- mean(no_causal_sim_summ_tib$Hevo_Pos_Rate * 100) %>% signif(2)
no_causal_WME_mean_pos_rate <- mean(no_causal_sim_summ_tib$WME_Pos_Rate * 100) %>% signif(2)

# Proportion of combinations of scenarios/parameters
no_causal_comb_n <- no_causal_sim_summ_tib$Hevo_Better %>% length()
no_causal_Hevo_better_n <- no_causal_sim_summ_tib$Hevo_Better %>% sum(na.rm = TRUE)
no_causal_Hevo_better_pc <- (no_causal_Hevo_better_n/no_causal_comb_n * 100) %>% signif(2)

# Mean/CIs
no_causal_Hevo_mean_est <- no_causal_sim_summ_tib$Hevo_Av %>% mean() %>% signif(2)
no_causal_Hevo_mean_lower <- no_causal_sim_summ_tib$Hevo_Lower_CI %>% mean() %>% signif(2)
no_causal_Hevo_mean_upper <- no_causal_sim_summ_tib$Hevo_Upper_CI %>% mean() %>% signif(2)

no_causal_Hevo_mean_est_S1 <- no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 1", x = Scenario)) %>% pull(Hevo_Av) %>% mean() %>% signif(2)
no_causal_Hevo_mean_est_S2 <- no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 2", x = Scenario)) %>% pull(Hevo_Av) %>% mean() %>% signif(2)
no_causal_Hevo_mean_est_S3 <- no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 3", x = Scenario)) %>% pull(Hevo_Av) %>% mean() %>% signif(2)


no_causal_WME_mean_est <- no_causal_sim_summ_tib$WME_Av %>% mean() %>% signif(2)
no_causal_WME_mean_lower <- no_causal_sim_summ_tib$WME_Lower_CI %>% mean() %>% signif(2)
no_causal_WME_mean_upper <- no_causal_sim_summ_tib$WME_Upper_CI %>% mean() %>% signif(2)

no_causal_WME_mean_est_S1 <- no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 1", x = Scenario)) %>% pull(WME_Av) %>% mean() %>% signif(2)
no_causal_WME_mean_est_S2 <- no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 2", x = Scenario)) %>% pull(WME_Av) %>% mean() %>% signif(2)
no_causal_WME_mean_est_S3 <- no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 3", x = Scenario)) %>% pull(WME_Av) %>% mean() %>% signif(2)

# SEs
no_causal_Hevo_mean_SE <- no_causal_sim_summ_tib$Hevo_SE %>% mean() %>% signif(2)
no_causal_Hevo_min_SE <- no_causal_sim_summ_tib$Hevo_SE %>% min() %>% signif(2)
no_causal_Hevo_max_SE <- no_causal_sim_summ_tib$Hevo_SE %>% max() %>% signif(2)

no_causal_Hevo_mean_SE_S1 <-  no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 1", x = Scenario)) %>% pull(Hevo_SE_Calc) %>% mean() %>% signif(2)
no_causal_Hevo_mean_SE_S2 <-  no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 2", x = Scenario)) %>% pull(Hevo_SE_Calc) %>% mean() %>% signif(2)
no_causal_Hevo_mean_SE_S3 <-  no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 3", x = Scenario)) %>% pull(Hevo_SE_Calc) %>% mean() %>% signif(2)


no_causal_WME_mean_SE <- no_causal_sim_summ_tib$WME_SE %>% mean() %>% signif(2)
no_causal_WME_min_SE <- no_causal_sim_summ_tib$WME_SE %>% min() %>% signif(2)
no_causal_WME_max_SE <- no_causal_sim_summ_tib$WME_SE %>% max() %>% signif(2)

no_causal_WME_mean_SE_S1 <-  no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 1", x = Scenario)) %>% pull(WME_SE) %>% mean() %>% signif(2)
no_causal_WME_mean_SE_S2 <-  no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 2", x = Scenario)) %>% pull(WME_SE) %>% mean() %>% signif(2)
no_causal_WME_mean_SE_S3 <-  no_causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 3", x = Scenario)) %>% pull(WME_SE) %>% mean() %>% signif(2)
```

#### No Causal Effect {#results-sim-no-causal}
\leavevmode\newline Across all cases where no causal effect was present (Table \@ref(tab:no-causal-sim-summ-display)), the mean rate of reporting a causal effect (i.e. false-positive rate) for MR-Hevo was `r no_causal_Hevo_mean_pos_rate`% versus `r no_causal_WME_mean_pos_rate`% for \acr{WME}. Of the `r no_causal_comb_n` combinations of scenarios and parameters, MR-Hevo exhibited a favourable false-positive rate versus \acr{WME} in `r no_causal_Hevo_better_n` (`r no_causal_Hevo_better_pc`%). 

Under Scenario 1 assumptions, the mean causal estimate (mean \acr{SE}) across all parameter combinations was `r paste0(no_causal_Hevo_mean_est_S1, " (", no_causal_Hevo_mean_SE_S1, ")")` for MR-Hevo and `r paste0(no_causal_WME_mean_est_S1, " (", no_causal_WME_mean_SE_S1, ")")` for \acr{WME}.

Under Scenario 2 assumptions, the mean causal estimate (mean \acr{SE}) across all parameter combinations was `r paste0(no_causal_Hevo_mean_est_S2, " (", no_causal_Hevo_mean_SE_S2, ")")` for MR-Hevo and `r paste0(no_causal_WME_mean_est_S2, " (", no_causal_WME_mean_SE_S2, ")")` for \acr{WME}.

Under Scenario 3 assumptions, the mean causal estimate (mean \acr{SE}) across all parameter combinations was `r paste0(no_causal_Hevo_mean_est_S3, " (", no_causal_Hevo_mean_SE_S3, ")")` for MR-Hevo and `r paste0(no_causal_WME_mean_est_S3, " (", no_causal_WME_mean_SE_S3, ")")` for \acr{WME}.

Overall, compared to \acr{WME}, MR-Hevo estimates displayed slightly more bias away from the null in Scenarios 1 and 2, and slightly less in Scenario 3. MR-Hevo estimates exhibited fractionally more variance across all cases. For both methods, increasing proportion of invalid instruments tended to bias estimates away from the null and increase estimate variance, although the 30% invalid instrument cases in Scenarios 1 and 3 did not follow this pattern. Increasing sample size tended to decrease both bias and variance of estimates, as expected.



```{r inline-vals-causal}

# --- No Causal --- #
# Mean positive report rates
causal_Hevo_mean_pos_rate <- mean(causal_sim_summ_tib$Hevo_Pos_Rate * 100) %>% signif(2)
causal_WME_mean_pos_rate <- mean(causal_sim_summ_tib$WME_Pos_Rate * 100) %>% signif(2)

# Proportion of combinations of scenarios/parameters
causal_comb_n <- causal_sim_summ_tib$Hevo_Better %>% length()
causal_Hevo_better_n <- causal_sim_summ_tib$Hevo_Better %>% sum(na.rm = TRUE)
causal_Hevo_better_pc <- (causal_Hevo_better_n/causal_comb_n * 100) %>% signif(2)

# Mean/CIs
causal_Hevo_mean_est <- causal_sim_summ_tib$Hevo_Av %>% mean() %>% signif(2)
causal_Hevo_mean_lower <- causal_sim_summ_tib$Hevo_Lower_CI %>% mean() %>% signif(2)
causal_Hevo_mean_upper <- causal_sim_summ_tib$Hevo_Upper_CI %>% mean() %>% signif(2)

causal_Hevo_mean_est_S1 <- causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 1", x = Scenario)) %>% pull(Hevo_Av) %>% mean() %>% signif(2)
causal_Hevo_mean_est_S2 <- causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 2", x = Scenario)) %>% pull(Hevo_Av) %>% mean() %>% signif(2)
causal_Hevo_mean_est_S3 <- causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 3", x = Scenario)) %>% pull(Hevo_Av) %>% mean() %>% signif(2)


causal_WME_mean_est <- causal_sim_summ_tib$WME_Av %>% mean() %>% signif(2)
causal_WME_mean_lower <- causal_sim_summ_tib$WME_Lower_CI %>% mean() %>% signif(2)
causal_WME_mean_upper <- causal_sim_summ_tib$WME_Upper_CI %>% mean() %>% signif(2)

causal_WME_mean_est_S1 <- causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 1", x = Scenario)) %>% pull(WME_Av) %>% mean() %>% signif(2)
causal_WME_mean_est_S2 <- causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 2", x = Scenario)) %>% pull(WME_Av) %>% mean() %>% signif(2)
causal_WME_mean_est_S3 <- causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 3", x = Scenario)) %>% pull(WME_Av) %>% mean() %>% signif(2)

# SEs
causal_Hevo_mean_SE <- causal_sim_summ_tib$Hevo_SE %>% mean() %>% signif(2)
causal_Hevo_min_SE <- causal_sim_summ_tib$Hevo_SE %>% min() %>% signif(2)
causal_Hevo_max_SE <- causal_sim_summ_tib$Hevo_SE %>% max() %>% signif(2)

causal_Hevo_mean_SE_S1 <-  causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 1", x = Scenario)) %>% pull(Hevo_SE_Calc) %>% mean() %>% signif(2)
causal_Hevo_mean_SE_S2 <-  causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 2", x = Scenario)) %>% pull(Hevo_SE_Calc) %>% mean() %>% signif(2)
causal_Hevo_mean_SE_S3 <-  causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 3", x = Scenario)) %>% pull(Hevo_SE_Calc) %>% mean() %>% signif(2)


causal_WME_mean_SE <- causal_sim_summ_tib$WME_SE %>% mean() %>% signif(2)
causal_WME_min_SE <- causal_sim_summ_tib$WME_SE %>% min() %>% signif(2)
causal_WME_max_SE <- causal_sim_summ_tib$WME_SE %>% max() %>% signif(2)

causal_WME_mean_SE_S1 <-  causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 1", x = Scenario)) %>% pull(WME_SE) %>% mean() %>% signif(2)
causal_WME_mean_SE_S2 <-  causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 2", x = Scenario)) %>% pull(WME_SE) %>% mean() %>% signif(2)
causal_WME_mean_SE_S3 <-  causal_sim_summ_tib %>% filter(grepl(pattern = "Scenario 3", x = Scenario)) %>% pull(WME_SE) %>% mean() %>% signif(2)
```

#### Positive Causal Effect {#results-sim-causal}
\leavevmode\newline Across all cases where a positive causal effect was present (Table \@ref(tab:no-causal-sim-summ-display)), the mean rate of reporting a causal effect (i.e. true-positive rate) for MR-Hevo was `r causal_Hevo_mean_pos_rate`% versus `r causal_WME_mean_pos_rate`% for \acr{WME}. Of the `r causal_comb_n` combinations of scenarios and parameters, MR-Hevo exhibited a favourable true-positive rate versus \acr{WME} in `r causal_Hevo_better_n` (`r causal_Hevo_better_pc`%). 

Under Scenario 1 assumptions, the mean causal estimate (mean \acr{SE}) across all parameter combinations was `r paste0(causal_Hevo_mean_est_S1, " (", causal_Hevo_mean_SE_S1, ")")` for MR-Hevo and `r paste0(causal_WME_mean_est_S1, " (", causal_WME_mean_SE_S1, ")")` for \acr{WME}.

Under Scenario 2 assumptions, the mean causal estimate (mean \acr{SE}) across all parameter combinations was `r paste0(causal_Hevo_mean_est_S2, " (", causal_Hevo_mean_SE_S2, ")")` for MR-Hevo and `r paste0(causal_WME_mean_est_S2, " (", causal_WME_mean_SE_S2, ")")` for \acr{WME}.

Under Scenario 3 assumptions, the mean causal estimate (mean \acr{SE}) across all parameter combinations was `r paste0(causal_Hevo_mean_est_S3, " (", causal_Hevo_mean_SE_S3, ")")` for MR-Hevo and `r paste0(causal_WME_mean_est_S3, " (", causal_WME_mean_SE_S3, ")")` for \acr{WME}.

Overall, MR-Hevo estimates displayed slight bias away from the null across all three scenarios, whereas \acr{WME} estimates were more mixed. MR-Hevo estimates again demonstrated fractionally more variance on average than \acr{WME}. For both methods, increasing proportion of invalid instruments tended to increase both size and variance of effect estimates, though again the 30% invalid instrument cases in Scenarios 1 and 3 did not follow this pattern. Increasing sample size tended to decrease both bias and variance of estimates, as expected.

\newpage


```{r no-causal-sim-summ-display, echo=FALSE, warning=FALSE, include=TRUE, tab.id="no-causal-sim-summ-display", tab.cap="Summary of 1,000 simulated Mendelian randomisation studies per combination of scenario and parameters, all with null causal effect", results='asis'}
#| ft.arraystretch = 1.3


library(ftExtra)

# Display
no_causal_sim_summ_tib_display <- no_causal_sim_summ_tib %>%
  # Change names for cleaner plotting
  mutate(Invalid = paste0((Prop_Invalid * 100), "%"),
         F = round(F_stat, 1),
         R2 = paste0(R2_stat *100, "%"),
         Weighted_Median_Mean_Estimate = WME_Av,
         Weighted_Median_Mean_SE = paste0("(", WME_SE, ")"),
         Weighted_Median_Lower_CI = round(WME_Av - 1.96 * WME_SE, 2),
         Weighted_Median_Upper_CI = round(WME_Av + 1.96 * WME_SE, 2),
         Weighted_Median_95_CI = paste0(Weighted_Median_Lower_CI, " to ", Weighted_Median_Upper_CI),
         Weighted_Median_Causal_Report_Rate = paste0((WME_Pos_Rate * 100), "%"),
         MR_Hevo_Mean_Estimate = Hevo_Av,
         #MR_Hevo_Mean_SE = paste0("(", round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3), ")"),
         MR_Hevo_Mean_SE = paste0("(", Hevo_SE_Calc, ")"),
         MR_Hevo_Lower_CI = round(Hevo_Lower_CI, 2),
         MR_Hevo_Upper_CI = round(Hevo_Upper_CI, 2),
         MR_Hevo_95_CI = paste0(round(Hevo_Lower_CI, 2), " to ", round(Hevo_Upper_CI, 2)),
         MR_Hevo_Causal_Report_Rate = paste0((Hevo_Pos_Rate * 100), "%")) %>%
  # Drop old names
  select(N,
         Invalid,
         F,
         R2,
         Weighted_Median_Mean_Estimate,
         Weighted_Median_Mean_SE,
         Weighted_Median_95_CI,
         Weighted_Median_Causal_Report_Rate,
         MR_Hevo_Mean_Estimate,
         MR_Hevo_Mean_SE,
         MR_Hevo_95_CI,
         MR_Hevo_Causal_Report_Rate,
         Scenario) %>%
  as_grouped_data(groups = c("Scenario")) %>%
  as_flextable(hide_grouplabel = TRUE, col_keys = c("N",
                                                    "Invalid",
                                                    "F",
                                                    "R2",
                                                    "Weighted_Median_Mean_Estimate",
                                                    "Weighted_Median_Mean_SE",
                                                    "Weighted_Median_95_CI", 
                                                    "Weighted_Median_Causal_Report_Rate",
                                                    "blank_col",
                                                    "MR_Hevo_Mean_Estimate",
                                                    "MR_Hevo_Mean_SE",
                                                    "MR_Hevo_95_CI", 
                                                    "MR_Hevo_Causal_Report_Rate",
                                                    "Scenario")) |>
  # To separate WME/MR-Hevo
  width(j = "blank_col", width = 0.2) |>
  empty_blanks() |>
  span_header() |>
  align(part = "all", align = "center") |>
  align(part = "body", j =c(5, 10),  align = "right") |>
  align(part = "body", j =c(6, 11),  align = "left") |>
  # Italicise N and F
  italic(part = "header", i = 1, j = c(1,3) ) |>
  # Fix name of invalid IVs
  flextable::compose(part = "header", i = 1:4, j = 2, value = as_paragraph("Invalid IVs")) |>
  # Fix name of 95% CIs
  flextable::compose(part = "header", i = 3, j = c(7, 12), value = as_paragraph("Mean")) |>
  flextable::compose(part = "header", i = 4, j = c(7, 12), value = as_paragraph("95% CI")) |>
  # Fix split headers
  flextable::compose(part = "header", i = 3, j = c(5,10), value = as_paragraph("Mean Estimate")) |>
  flextable::compose(part = "header", i = 4, j = c(5:6), value = as_paragraph("(Mean SE)")) |>
  flextable::compose(part = "header", i = 4, j = c(10:11), value = as_paragraph("(Mean SE*)")) |>
  #flextable::compose(part = "header", i = 4, j = c(5:6,10:11), value = as_paragraph("(Mean SE)")) |>
  merge_h(part = "header", i = 4) |>
  # Italicise/superscript R^2
  flextable::compose(part = "header", i = 1, j = 4, value = as_paragraph(as_i("R"), as_sup(as_i(as.character(2))))) |>
  
  hline(part = "header", i = 2, j = c(5:8, 10:13), border = officer::fp_border(color = "black", width = 1)) |>
  #footnote(i = c(1,4), j = c(2, 5), part = "header", value = as_paragraph(c("IV: Instrumental Variable", "SE: Standard Error")))
  # Fix dimensions
  autofit() |>
  #line_spacing(space = 0, part = "header") |>
  line_spacing(space = 1, part = "body") |>
  fit_to_width(max_width = 6.5) |>
  #height_all(height = 40, unit = "mm",part = "all") |>

  # Add footer
  add_footer_lines("CI: Confidence Interval, InSIDE: Instrument Strength Independent of Direct Effect, IV: Instumental Variable, SE: Standard Error, SE*: Estimated Standard Error. F and R\U00B2 statistics presented are the minimum values across all simulated datasets. \nNull Causal Effect (\U03B2 = 0)") |>
  fontsize(9, i = c(1:5), j = c(1:13), part = "header") |>
  fontsize(8, i = c(1:27), j = c(1:13), part = "body") |>
  fontsize(8, i = 1, j = 1, part = "footer")
# set_caption(caption = "Summary of 1000 Simulated Mendelian Randomisation Studies With Null Causal Effect (\U03B2 = 0)",
#             style = "Table Caption",
#             autonum = run_autonum(seq_id = "tab",
#                                   bkm = "no-causal-sim-summ-tib"))

no_causal_sim_summ_tib_display


```


\newpage
```{r causal-sim-summ-display, echo=FALSE, warning=FALSE, include=TRUE, tab.id="causal-sim-summ-display", tab.cap="Summary of 1,000 simulated Mendelian randomisation studies per combination of scenario and parameters, all with positive causal effect", results='asis'}
#| ft.arraystretch = 1.3

# Display
causal_sim_summ_tib_display <- causal_sim_summ_tib %>%
# Change names for cleaner plotting
    mutate(Invalid = paste0((Prop_Invalid * 100), "%"),
         F = round(F_stat, 1),
         R2 = paste0(R2_stat *100, "%"),
         Weighted_Median_Mean_Estimate = WME_Av,
         Weighted_Median_Mean_SE = paste0("(", WME_SE, ")"),
         Weighted_Median_Lower_CI = round(WME_Av - 1.96 * WME_SE, 2),
         Weighted_Median_Upper_CI = round(WME_Av + 1.96 * WME_SE, 2),
         Weighted_Median_95_CI = paste0(Weighted_Median_Lower_CI, " to ", Weighted_Median_Upper_CI),
         Weighted_Median_Causal_Report_Rate = paste0((WME_Pos_Rate * 100), "%"),
         MR_Hevo_Mean_Estimate = Hevo_Av,
         #MR_Hevo_Mean_SE = paste0("(", round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3), ")"),
         MR_Hevo_Mean_SE = paste0("(", Hevo_SE_Calc, ")"),
         MR_Hevo_Lower_CI = round(Hevo_Lower_CI, 2),
         MR_Hevo_Upper_CI = round(Hevo_Upper_CI, 2),
         MR_Hevo_95_CI = paste0(round(Hevo_Lower_CI, 2), " to ", round(Hevo_Upper_CI, 2)),
         MR_Hevo_Causal_Report_Rate = paste0((Hevo_Pos_Rate * 100), "%")) %>%
  # Drop old names
  select(N,
         Invalid,
         F,
         R2,
         Weighted_Median_Mean_Estimate,
         Weighted_Median_Mean_SE,
         Weighted_Median_95_CI,
         Weighted_Median_Causal_Report_Rate,
         MR_Hevo_Mean_Estimate,
         MR_Hevo_Mean_SE,
         MR_Hevo_95_CI,
         MR_Hevo_Causal_Report_Rate,
         Scenario) %>%
  as_grouped_data(groups = c("Scenario")) %>%
  as_flextable(hide_grouplabel = TRUE, col_keys = c("N",
                                                    "Invalid",
                                                    "F",
                                                    "R2",
                                                    "Weighted_Median_Mean_Estimate",
                                                    "Weighted_Median_Mean_SE",
                                                    "Weighted_Median_95_CI", 
                                                    "Weighted_Median_Causal_Report_Rate",
                                                    "blank_col",
                                                    "MR_Hevo_Mean_Estimate",
                                                    "MR_Hevo_Mean_SE",
                                                    "MR_Hevo_95_CI", 
                                                    "MR_Hevo_Causal_Report_Rate",
                                                    "Scenario")) |>
  # To separate WME/MR-Hevo
  width(j = "blank_col", width = 0.2) |>
  empty_blanks() |>
  span_header() |>
  align(part = "all", align = "center") |>
  align(part = "body", j =c(5, 10),  align = "right") |>
  align(part = "body", j =c(6, 11),  align = "left") |>
  # Italicise N and F
  italic(part = "header", i = 1, j = c(1,3) ) |>
  # Fix name of invalid IVs
  flextable::compose(part = "header", i = 1:4, j = 2, value = as_paragraph("Invalid IVs")) |>
  # Fix name of 95% CIs
  flextable::compose(part = "header", i = 3, j = c(7, 12), value = as_paragraph("Mean")) |>
  flextable::compose(part = "header", i = 4, j = c(7, 12), value = as_paragraph("95% CI")) |>
  # Fix split headers
  flextable::compose(part = "header", i = 3, j = c(5,10), value = as_paragraph("Mean Estimate")) |>
  flextable::compose(part = "header", i = 4, j = c(5:6), value = as_paragraph("(Mean SE)")) |>
  flextable::compose(part = "header", i = 4, j = c(10:11), value = as_paragraph("(Mean SE*)")) |>
  #flextable::compose(part = "header", i = 4, j = c(5:6,10:11), value = as_paragraph("(Mean SE)")) |>
  merge_h(part = "header", i = 4) |>
  # Italicise/superscript R^2
  flextable::compose(part = "header", i = 1, j = 4, value = as_paragraph(as_i("R"), as_sup(as_i(as.character(2))))) |>
  
  hline(part = "header", i = 2, j = c(5:8, 10:13), border = officer::fp_border(color = "black", width = 1)) |>
  #footnote(i = c(1,4), j = c(2, 5), part = "header", value = as_paragraph(c("IV: Instrumental Variable", "SE: Standard Error")))
  # Fix dimensions
  autofit() |>
  #line_spacing(space = 0, part = "header") |>
  line_spacing(space = 1, part = "body") |>
  fit_to_width(max_width = 6.5) |>
  #height_all(height = 40, unit = "mm",part = "all") |>
  # Add footer
  add_footer_lines("CI: Confidence Interval, InSIDE: Instrument Strength Independent of Direct Effect, IV: Instumental Variable, SE: Standard Error. F and R\U00B2 statistics presented are the minimum values across all simulated datasets. \nPositive Causal Effect (\U03B2 = 0.1)") |>
  fontsize(9, i = c(1:5), j = c(1:13), part = "header") |>
  fontsize(8, i = c(1:27), j = c(1:13), part = "body") |>
  fontsize(8, i = 1, j = 1, part = "footer")
# set_caption(caption = "Summary of 1000 Simulated Mendelian Randomisation Studies With Null Causal Effect (\U03B2 = 0)",
#             style = "Table Caption",
#             autonum = run_autonum(seq_id = "tab",
#                                   bkm = "no-causal-sim-summ-tib"))

causal_sim_summ_tib_display
#causal_sim_summ_tib


```

\newpage


## Re-Analysis of Published Data

### Citation Search Results

```{r citations-reanalysis-summ-fn, include=FALSE, eval=FALSE}

get_reanalysis_tib <- function(models_in){
  
  output_tib_row <- tibble(N = as.integer(),
                           WME_Av = as.double(),
                           WME_SE = as.double(),
                           Hevo_Av = as.double(),
                           Hevo_SE = as.double()
  )
  
  # Create blank tibble to receive results of Weighted
  # Median Estimator function from MR-Base
  
  results_tib <-  tibble(
                         Study_Author = as.character(),
                         Study_Ref = as.character(),
                         Study_DOI = as.character(),
                         Study_Exposure = as.character(),
                         Study_Outcome = as.character(),
                         Study_Reported_Measure = as.character(),
                         N = as.integer(),
                         WME_est = as.double(),
                         WME_se = as.double(),
                         WME_pval = as.double(),
                         WME_nsnp = as.integer(),
                         Hevo_est = as.double(),
                         Hevo_se = as.double(),
                         Hevo_sd = as.double(),
                         Hevo_est_lower_CI = as.double(),
                         Hevo_est_upper_CI = as.double()
  )
  
  # Convert full tibble to list of 1 tibble per dataset
  model_list <- models_in %>% 
    group_by(Study_DOI) %>%
    group_split()
  
  
  # Should = 10
  n_datasets <- length(model_list)
  
  #Run WME and MR-Hevo for each dataset
  for(dataset in 1:n_datasets){
    
    # Extract study details
    results_tib[dataset, ]$Study_Author <- model_list[[dataset]]$Author[[1]]
    results_tib[dataset, ]$Study_Ref <- model_list[[dataset]]$Study_Ref[[1]]
    results_tib[dataset, ]$Study_DOI <- model_list[[dataset]]$Study_DOI[[1]]
    results_tib[dataset, ]$Study_Exposure <- model_list[[dataset]]$Exposure[[1]]
    results_tib[dataset, ]$Study_Outcome <- model_list[[dataset]]$Outcome[[1]]
    results_tib[dataset, ]$Study_Reported_Measure <- model_list[[dataset]]$Reported_Measure[[1]]

    # Stored as individual vectors for MR-Hevo/RStan - not
    # Tidyverse compatible
    coeff_G_X_vect <- model_list[[dataset]]$Coeff_G_X
    coeff_G_Y_vect <- model_list[[dataset]]$Coeff_G_Y
    coeff_G_X_SE_vect <- model_list[[dataset]]$Coeff_G_X_SE
    coeff_G_Y_SE_vect <- model_list[[dataset]]$Coeff_G_Y_SE


    # N.B. MR-Hevo terminology vs WME paper/other code:
    # alpha = effects of instruments on exposure, i.e. coeff_G_X
    # beta = pleiotropic effects of instruments on outcome, i.e. alpha in WME
    # gamma = effects of instruments on outcome, i.e. coeff_G_Y
    # theta = causal effect X on Y, i.e. b

    # Results from weighted median estimator method
    WME_results <- mr_weighted_median(b_exp = coeff_G_X_vect,
                                      b_out = coeff_G_Y_vect,
                                      se_exp = coeff_G_X_SE_vect,
                                      se_out = coeff_G_Y_SE_vect,
                                      parameters = list(nboot = 1000))

    # Results from MR-Hevo method
    Hevo_results <- run_mrhevo.sstats(alpha_hat = coeff_G_X_vect,
                                      se.alpha_hat = coeff_G_X_SE_vect,
                                      gamma_hat = coeff_G_Y_vect,
                                      se.gamma_hat = coeff_G_Y_SE_vect
    ) %>%
      summary()


    # Extract WME Results
    results_tib[dataset, ]$WME_est <- WME_results$b
    results_tib[dataset, ]$WME_se <- WME_results$se
    results_tib[dataset, ]$WME_pval <- WME_results$pval
    results_tib[dataset, ]$WME_nsnp <- WME_results$nsnp

    # Extract MR-Hevo Results
    results_tib[dataset, ]$Hevo_est <- Hevo_results$summary["theta","mean"]
    results_tib[dataset, ]$Hevo_se <- Hevo_results$summary["theta","se_mean"]
    results_tib[dataset, ]$Hevo_sd <- Hevo_results$summary["theta","sd"]
    results_tib[dataset, ]$Hevo_est_lower_CI <- Hevo_results$summary["theta","2.5%"]
    results_tib[dataset, ]$Hevo_est_upper_CI <- Hevo_results$summary["theta","97.5%"]

    results_tib[dataset, ]$N <- dataset


  }

  results_tib <- results_tib %>%
    mutate(WME_OR = exp(WME_est),
           WME_est_lower_CI = (WME_est - (1.96 * WME_se)),
           WME_est_upper_CI = (WME_est + (1.96 * WME_se)),
           WME_OR_lower_CI = exp(WME_est_lower_CI),
           WME_OR_upper_CI = exp(WME_est_upper_CI),
           WME_est_causal_detected = WME_pval < 0.05,
           #WME_est_causal_detected = (WME_est_lower_CI > 0  | WME_est_upper_CI < 0),
           #WME_OR_causal_detected = (WME_OR_lower_CI > 1  | WME_OR_upper_CI < 1),
           Hevo_OR = exp(Hevo_est),
           Hevo_OR_lower_CI = exp(Hevo_est_lower_CI),
           Hevo_OR_upper_CI = exp(Hevo_est_upper_CI),
           Hevo_OR_causal_detected = (Hevo_OR_lower_CI > 1  | Hevo_OR_upper_CI < 1),
           Hevo_est_causal_detected = (Hevo_est_lower_CI > 0  | Hevo_est_upper_CI < 0)
    )

  return(results_tib)
  
}


```

```{r citations-reanalysis-summ-tib, eval=FALSE}

citations_reanalysis_summ_tib <-
  Citations_Instrument_Data %>%
  #slice()
  #slice(1452:1521) %>% # Mokry
  #slice(2282:2730) %>% # Xie
  #slice(2731:3108) %>% # Clift
  mutate(
      # replace all unicode dash variations with minus - to stop conversion to char
      # https://stackoverflow.com/questions/48923599/searching-for-all-variations-of-hyphens-and-dashes-in-regex
      across(starts_with("Coeff_"),
             ~str_replace_all(.,
                              pattern = "[\u002D\u058A\u05BE\u1400\u1806\u2010-\u2015\u2E17\u2E1A\u2E3A\u2E3B\u2E40\u301C\u3030\u30A0\uFE31\uFE32\uFE58\uFE63\uFF0D]",
                              # https://www.kaggle.com/discussions/questions-and-answers/54715
                              replacement = "\U002D")),
      # encode missing as NA
      across(starts_with("Coeff_"), ~str_replace_all(., pattern = "[Aa:Zz]", replacement = NA_character_)),
      across(starts_with("Coeff_"), ~as.double(.)),
      #across(where(is.numeric), ~replace_na(., mean(., na.rm = TRUE)) ), #imputes missing as mean
      # replace zeros for MR-Hevo
      across(starts_with("Coeff_"), ~replace(., . == 0, 10^-100)),
      # remove square brackets from ref tags
      across(Study_Ref, ~str_replace_all(., "\\[|\\]", ""))
    ) %>%
  drop_na(starts_with("Coeff")) %>% 
  #filter(if_any(starts_with("Coeff_"), is.na)) #%>%
  #print()
  get_reanalysis_tib() %>%
  mutate(Discordant = (WME_est_causal_detected != Hevo_est_causal_detected))


# citations_reanalysis_summ_tib <- Citations_Instrument_Data %>%
#   #slice()
#   #slice(1452:1521) %>% # Mokry
#   #slice(2282:2730) %>% # Xie
#   #slice(2731:3108) %>% # Clift
#   mutate(across(Coeff_G_X:Coeff_G_Y_SE, ~replace(., . == 0, 10^-100)),
#          across(starts_with("Coeff_"), ~as.double(.))) %>% 
#   get_reanalysis_tib() %>% 
#   mutate(Discordant = (WME_est_causal_detected != Hevo_est_causal_detected))

  
saveRDS(citations_reanalysis_summ_tib, file = here("Data", "Summary_Tables", "citations_reanalysis_summ_tib.rds"))
# 
# #citations_reanalysis_summ_tib$Discordant
# citations_reanalysis_summ_tib <- citations_reanalysis_summ_tib %>% 
#   mutate(Reanalysis_Discordant = Discordant) %>% 
#   select(-Discordant)
# 
# citations_reanalysis_summ_tib
```


```{r citation-data, cache=FALSE}

citations_search_sample <- read_csv(here("Data", "Citations_Search", "Citations_Methods_Comparison.csv"),na = "#N/A") %>% 
  mutate(
    # fill blanks
    Reported_WME_Lower_CI = if_else(is.na(Reported_WME_Lower_CI), 
                                    (Reported_WME_Causal_Effect - (1.96 * Reported_WME_SE)),
                                    Reported_WME_Lower_CI),
    Reported_WME_Upper_CI = if_else(is.na(Reported_WME_Upper_CI),
                                    (Reported_WME_Causal_Effect + (1.96 * Reported_WME_SE)),
                                    Reported_WME_Upper_CI))

citations_search_sample_refs <- citations_search_sample %>% pull(Study_Ref) %>%  paste(collapse = ";") 

#[@choi_assessment_2019; @pasman_gwas_2018; @ligthart_genome_2018; @carter_understanding_2019; @mokry_obesity_2016; @carreras-torres_role_2017; @xu_causal_2022; @budu-aggrey_evidence_2019; @xie_associations_2023; @clift_smoking_2022]

```

A total of 103 abstracts and 54 full texts were screened to identify the 10 studies included [`r  gluedown::md_text(citations_search_sample_refs)`]; these studies are summarised in Table \@ref(tab:citation-search-sample-display). The flow diagram of study screening and selection is presented in Figure \@ref(fig:screening-flow).

```{r screening-flow, include=TRUE}
#| out.width = "100%",
#| out.height = "70%",
#| fig.id = "screening-flow",
#| fig.cap = "Flow diagram illustrating selection of a sample of ten highly-cited two-sample Mendelian randomisation articles reporting a weighted median estimate of causal effect"

include_graphics(path = here("Data", "Citations_Search", "WME_citation_search_flow_diagram_crop.png"),
                 error = FALSE)

```

\blandscape

```{r citation-search-sample-display, include=TRUE, cache=FALSE, out.height=6}
#| tab.id = "citation-search-sample-display",
#| tab.cap = "Summary of ten highly-cited two-sample Mendelian randomisation articles reporting a weighted median estimate of causal effect",
#| ft.arraystretch = 1.3

library(magrittr) #bookdown forgets these packages, unclear why
library(flextable)
library(ftExtra)
library(tidyverse)

citations_search_sample %>% 
  mutate(
    # fill blanks
    # Reported_WME_Lower_CI = if_else(is.na(Reported_WME_Lower_CI), 
    #                                 (Reported_WME_Causal_Effect - (1.96 * Reported_WME_SE)),
    #                                 Reported_WME_Lower_CI),
    # Reported_WME_Upper_CI = if_else(is.na(Reported_WME_Upper_CI),
    #                                 (Reported_WME_Causal_Effect + (1.96 * Reported_WME_SE)),
    #                                 Reported_WME_Upper_CI),
    # Overlap_Max_Est_Decimal = replace_na(Overlap_Max_Est_Decimal, 0),
    p_value = replace_na(p_value, "-"),
    # round
    across(where(is.numeric), ~round(., 3)),
    # combine effect estimate + CIs
    Effect_Estimate = paste0(Reported_WME_Causal_Effect, " (", Reported_WME_Lower_CI, " to ", Reported_WME_Upper_CI, ")"),
    # combine author/year
    Author = paste0(Author, 
                    ", ",
                    Year),
    # convert TRUE/FALSE to Yes/No
    Causality_Reported = if_else(Causality_Reported, "Yes", "No"),
    # convert to %
    Participants_Maximum_Estimated_Overlap = if_else(is.na(Overlap_Max_Est_Decimal),
                                                     "0%",
                                                     paste0((Overlap_Max_Est_Decimal * 100), "%")),
    # change naming for flextable
    Participants_N_Exposure = Exposure_N_Participants,
    Participants_N_Outcome = Outcome_N_Participants,
    Causal_Effect_Measure = Reported_WME_Measure,
    Causal_Effect_Estimate = Effect_Estimate
    
  ) %>% 
  #sort by citation count
  arrange(Author) %>% 
  select(Author,
         #DOI,
         Citations,
         Association,
         n_Instruments,
         Participants_N_Exposure,
         Participants_N_Outcome,
         Participants_Maximum_Estimated_Overlap,
         Causal_Effect_Measure,
         Causal_Effect_Estimate,
         Causality_Reported,
         p_value
         ) %>% 
  as_flextable() %>% 
  span_header() %>% 
  align(part = "all", align = "center") %>% 
  # Fix column titles
  ## N Instruments
  flextable::compose(part = "header", j = 4, value = as_paragraph(as_i("N"), " \nInstruments")) %>% 
  merge_v(part = "header", j = 4) %>% 
  ## Participants
  flextable::compose(part = "header", i = 2, j = 5, value = as_paragraph(as_i("N"))) %>%
  ## Causality
  flextable::compose(part = "header", j = 10, value = as_paragraph("Causality Reported")) %>% 
  merge_v(part = "header", j = 10) %>% 
  ## p-value 
  flextable::compose(part = "header", j = 11, value = as_paragraph(as_i("p"), "-value")) %>% 
  merge_v(part = "header", j = 11) %>% 
  # Add beta symbol
  flextable::compose(part = "body", i = 8, j = 8, value = as_paragraph(as_i("\U03B2"))) %>% 
  # add lines
  hline(part = "header", i = 1, j = c(5:7), border = officer::fp_border(color = "black", width = 1)) %>% 
  hline(part = "header", i = 2, j = c(8:9), border = officer::fp_border(color = "black", width = 1)) %>% 
  hline(part = "body", i = c(1:10), j = c(1:11), border = officer::fp_border(color = "black", width = 0.2)) %>% 
  # Add footer
  add_footer_lines("\U03B2 and OR presented as: estimate (95% CI).\n\U03B2: causal effect estimate, CI: Confidence Interval, OR: Odds Ratio, SE: Standard Error.\nBMI: body mass index, CRP: C-reactive protein, NAFLD: non-alcoholic fatty liver disease, T2DM: type 2 diabetes mellitus") %>% 
  # Formatting
  #width(j = 2, width = 0.5,unit = "cm") #%>% 
  fontsize(9, i = c(1:4), j = c(1:11), part = "header") %>% 
  fontsize(8, i = c(1:10), j = c(1:11), part = "body") %>% 
  fontsize(8, i = 1, j = 1, part = "footer") %>% 
  #set_table_properties(width = 0.8, layout = "autofit") %>% 
  width(j = 3, width = 25, unit = "mm") #%>%
  #dim()
  #autofit() %>% 
  #height_all(height = 0.6) %>% 
  #hrule(rule = "exact", part = "all") %>% 
  #fit_to_width(max_width = 9)
  #add_footer_lines(".") %>%
  # format citations
  #flextable::compose(part = "body", i = c(1:2), j = 1, value = as_paragraph_md(Author))
  #colformat_md(part = "all", j = 1, pandoc_args = c('--csl', 'harvard-cite-them-right.csl'))
  
  
```

\elandscape

```{r cite-data-load, eval=FALSE}

# --- Citation Search --- # 

data_budu_aggrey_evidence_2019 <- read.csv(here("Data", "Citations_Datasets", "budu-aggrey_evidence_2019.csv")) %>% as_tibble()
data_carreras_torres_role_2017 <- read.csv(here("Data", "Citations_Datasets", "carreras-torres_role_2017.csv")) %>% as_tibble()
data_carter_understanding_2019 <- read.csv(here("Data", "Citations_Datasets", "carter_understanding_2019.csv")) %>% as_tibble()
data_choi_assessment_2019 <- read.csv(here("Data", "Citations_Datasets", "choi_assessment_2019.csv")) %>% as_tibble()
data_clift_smoking_2022 <- read.csv(here("Data", "Citations_Datasets", "clift_smoking_2022.csv")) %>% 
  # drop outlier #impute outlier as mean
  as_tibble() %>% 
  mutate(across(starts_with("Coeff_G_Y"), \(x) if_else(Coeff_G_Y == min(Coeff_G_Y),
                                                       NA_real_,
                                                       #mean(x),
                                                       x)))
  #filter(Coeff_G_Y!= min(Coeff_G_Y))
data_ligthart_genome_2018 <- read.csv(here("Data", "Citations_Datasets", "ligthart_genome_2018.csv")) %>% as_tibble()
data_mokry_obesity_2016 <- read.csv(here("Data", "Citations_Datasets", "mokry_obesity_2016.csv")) %>% as_tibble()
data_pasman_gwas_2018 <- read.csv(here("Data", "Citations_Datasets", "pasman_gwas_2018.csv")) %>% as_tibble()
data_xie_associations_2023 <- read.csv(here("Data", "Citations_Datasets", "xie_associations_2023.csv")) %>% as_tibble()
data_xu_causal_2022 <- read.csv(here("Data", "Citations_Datasets", "xu_causal_2022.csv")) %>% as_tibble()

# Clean
citation_datasets_list <- list(data_budu_aggrey_evidence_2019,
                               data_carreras_torres_role_2017,
                               data_carter_understanding_2019,
                               data_choi_assessment_2019,
                               data_clift_smoking_2022,
                               data_ligthart_genome_2018,
                               data_mokry_obesity_2016,
                               data_pasman_gwas_2018,
                               data_xie_associations_2023,
                               data_xu_causal_2022)

for(dataset in 1:length(citation_datasets_list)){
  
  citation_datasets_list[[dataset]] <- citation_datasets_list[[dataset]] %>% 
    tibble() %>% 
    mutate(
      # replace all unicode dash variations with minus - to stop conversion to char
      # https://stackoverflow.com/questions/48923599/searching-for-all-variations-of-hyphens-and-dashes-in-regex
      across(starts_with("Coeff_"), 
             ~str_replace_all(.,
                              pattern = "[\u002D\u058A\u05BE\u1400\u1806\u2010-\u2015\u2E17\u2E1A\u2E3A\u2E3B\u2E40\u301C\u3030\u30A0\uFE31\uFE32\uFE58\uFE63\uFF0D]", 
                              # https://www.kaggle.com/discussions/questions-and-answers/54715
                              replacement = "\U002D")),
      # encode missing as NA 
      across(starts_with("Coeff_"), ~str_replace_all(., pattern = "[Aa:Zz]", replacement = NA_character_)),
      across(starts_with("Coeff_"), ~as.double(.)),
      #across(where(is.numeric), ~replace_na(., mean(., na.rm = TRUE)) ), #imputes missing as mean
      # replace zeros for MR-Hevo
      across(starts_with("Coeff_"), ~replace(., . == 0, 10^-100)), 
      # remove square brackets from ref tags
      across(Study_Ref, ~str_replace_all(., "\\[|\\]", ""))
    )
    
}


# Combine
Citations_Instrument_Data <- bind_rows(citation_datasets_list)

# Write to .csv
write.csv(Citations_Instrument_Data, here("Data", "Citations_Datasets", "Citations_Instrument_Data.csv"),append = FALSE)

# # Check
# Citations_Instrument_Data %>%
#   head()
#   
# Citations_Instrument_Data %>% 
#   group_by(Author) %>% 
#   summarise(across(everything(), \(x) sum(is.na(x)))) %>% 
#   print()
# Citations_Instrument_Data %>%
#   group_by(Author) %>% 
#   summarise(
#     Mean_G_X = mean(Coeff_G_X),
#     Min_G_X = min(Coeff_G_X),
#     Max_G_X = max(Coeff_G_X),
#     Mean_G_X_SE = mean(Coeff_G_X_SE),
#     Min_G_X_SE = min(Coeff_G_X_SE),
#     Max_G_X_SE = max(Coeff_G_X_SE),
#     Mean_G_Y = mean(Coeff_G_Y),
#     Min_G_Y = min(Coeff_G_Y),
#     Max_G_Y = max(Coeff_G_Y),
#     Mean_G_Y_SE = mean(Coeff_G_Y_SE),
#     Min_G_Y_SE = min(Coeff_G_Y_SE),
#     Max_G_Y_SE = max(Coeff_G_Y_SE)) %>% 
#   mutate(across(where(is.numeric), \(x) round(x, 2))) %>%
#   print()
# 
# citation_datasets_list[[9]] %>% 
#   filter(if_any(everything(), is.na)) %>% 
#   print()

#Citations_Instrument_Data

```


### Re-Analysis Results

```{r inline-vals-reanalysis-tibs}

citations_reanalysis_summ_tib <- readRDS(here("Data", "Summary_Tables", "citations_reanalysis_summ_tib.rds")) %>% 
  tibble() %>% 
  mutate(across(Study_Ref, ~str_replace_all(., "\\[|\\]", ""))) #%>% 
  #rename(Hevo_WME_Causal_Discordant = Discordant)

# Join both citation tables for comparisons
citations_combined_summ_tib <- left_join(x = citations_reanalysis_summ_tib, y =citations_search_sample)

citations_combined_summ_tib <- citations_combined_summ_tib %>% 
  mutate(
    #--- Re-analysed WME values vs original reports ---#
    ## Estimates
    Diff_WME_Causal_Est = if_else(Reported_WME_Measure == "OR",
                                  Reported_WME_Causal_Effect - WME_OR,
                                  Reported_WME_Causal_Effect - WME_est),
    Diff_WME_Est_Over_Point1 = (abs(Diff_WME_Causal_Est) > 0.1),
    Auth_Cite_Diff_WME_Est_Over_Point1 = if_else(Diff_WME_Est_Over_Point1,
                                             paste0(Study_Author, "[", Study_Ref, "]"),
                                             NA),
    ## CIs
    Diff_WME_Causal_Low = if_else(Reported_WME_Measure == "OR",
                                  Reported_WME_Lower_CI - WME_OR_lower_CI,
                                  Reported_WME_Lower_CI - WME_est_lower_CI),
    Diff_WME_Causal_Upp = if_else(Reported_WME_Measure == "OR",
                                  Reported_WME_Upper_CI - WME_OR_upper_CI,
                                  Reported_WME_Upper_CI - WME_est_upper_CI),
    Diff_WME_CIs_Over_Point1 = (abs(Diff_WME_Causal_Low > 0.1) | abs(Diff_WME_Causal_Upp) >0.1),
    Auth_Cite_Diff_WME_CIs_Over_Point1 = if_else(Diff_WME_CIs_Over_Point1,
                                             paste0(Study_Author, "[", Study_Ref, "]"),
                                             NA),
    ## SE
    Diff_WME_SE = if_else(is.na(Reported_WME_SE),
                          (Reported_WME_Upper_CI - Reported_WME_Causal_Effect) / 1.96,
                          Reported_WME_SE),
    Diff_WME_SE_Over_Point1 = (abs(Diff_WME_SE) > 0.1),
    Auth_Cite_Diff_WME_SE_Over_Point1 = if_else(Diff_WME_SE_Over_Point1,
                                                paste0(Study_Author, "[", Study_Ref, "]"),
                                                NA),
    across(where(is.numeric), \(x) round(x, 2)),
    ## Comparables
    Comp_WME_Est_CI = (!Diff_WME_Est_Over_Point1 & !Diff_WME_CIs_Over_Point1),
    Auth_Cite_Comp_WME_Est_CI = if_else(Comp_WME_Est_CI,
                                        paste0(Study_Author, "[", Study_Ref, "]"),
                                        NA),
    ## Causal Reports
    Diff_WME_Causal_Report = (Causality_Reported != WME_est_causal_detected),
    Diff_WME_Causal_To_No_Causal = (Causality_Reported == TRUE & WME_est_causal_detected == FALSE),
    Auth_Cite_WME_Causal_To_No_Causal = if_else(Diff_WME_Causal_To_No_Causal,
                                                paste0(Study_Author, "[", Study_Ref, "]"),
                                                NA),
    Diff_WME_No_Causal_To_Causal = (Causality_Reported == FALSE & WME_est_causal_detected == TRUE),
    Auth_Cite_WME_No_Causal_To_Causal = if_else(Diff_WME_No_Causal_To_Causal,
                                                paste0(Study_Author, "[", Study_Ref, "]"),
                                                NA),
    #--- MR-Hevo vs re-analysed WME ---# 
    ## Estimates
    Diff_Hevo_WME_Causal_Est = if_else(Reported_WME_Measure == "OR",
                                       Hevo_OR - WME_OR,
                                       Hevo_est - WME_est),
    Diff_Hevo_WME_Est_Over_Point1 = (abs(Diff_Hevo_WME_Causal_Est) > 0.1),
    Auth_Cite_Diff_Hevo_WME_Est_Over_Point1 = if_else(Diff_Hevo_WME_Est_Over_Point1,
                                                      paste0(Study_Author, "[", Study_Ref, "]"),
                                                      NA),
    ## CIs
    Diff_Hevo_WME_Causal_Low = if_else(Reported_WME_Measure == "OR",
                                       Hevo_OR_lower_CI - WME_OR_lower_CI,
                                       Hevo_est_lower_CI - WME_est_lower_CI),
    Diff_Hevo_WME_Causal_Upp = if_else(Reported_WME_Measure == "OR",
                                       Hevo_OR_upper_CI - WME_OR_upper_CI,
                                       Hevo_est_upper_CI - WME_est_upper_CI),
    Diff_Hevo_WME_CIs_Over_Point1 = (abs(Diff_Hevo_WME_Causal_Low > 0.1) | abs(Diff_Hevo_WME_Causal_Upp) >0.1),
    Auth_Cite_Diff_Hevo_WME_CIs_Over_Point1 = if_else(Diff_Hevo_WME_CIs_Over_Point1,
                                                      paste0(Study_Author, "[", Study_Ref, "]"),
                                                      NA),
    ## SE
    Diff_Hevo_WME_SE = Hevo_se - WME_se,
    Diff_Hevo_WME_SE_Over_Point1 = (abs(Diff_Hevo_WME_SE) > 0.1),
    Auth_Cite_Diff_Hevo_WME_SE_Over_Point1 = if_else(Diff_Hevo_WME_SE_Over_Point1,
                                                     paste0(Study_Author, "[", Study_Ref, "]"),
                                                     NA),
    across(where(is.numeric), \(x) round(x, 2)),
    ## Comparables
    Comp_Hevo_WME_Est_CI = (!Diff_Hevo_WME_Est_Over_Point1 & !Diff_Hevo_WME_CIs_Over_Point1),
    Auth_Cite_Comp_Hevo_WME_Est_CI = if_else(Comp_Hevo_WME_Est_CI,
                                             paste0(Study_Author, "[", Study_Ref, "]"),
                                             NA),
    ## Causal Reports
    Diff_Hevo_WME_Causal_Report = (Hevo_est_causal_detected != WME_est_causal_detected),
    Diff_Hevo_Causal_WME_No_Causal = (Hevo_est_causal_detected == TRUE & WME_est_causal_detected == FALSE),
    Auth_Cite_Hevo_Causal_WME_No_Causal = if_else(Diff_Hevo_Causal_WME_No_Causal,
                                                  paste0(Study_Author, "[", Study_Ref, "]"),
                                                  NA),
    Diff_Hevo_No_Causal_WME_Causal = (Hevo_est_causal_detected == FALSE & WME_est_causal_detected == TRUE),
    Auth_Cite_Hevo_No_Causal_WME_Causal = if_else(Diff_Hevo_No_Causal_WME_Causal,
                                                  paste0(Study_Author, "[", Study_Ref, "]"),
                                                  NA)
  )

## Mean diffs

WME_diff_mean_OR <- citations_combined_summ_tib %>% 
  filter(Reported_WME_Measure == "OR") %>%
  summarise(
    est_diff = mean(Diff_WME_Causal_Est),
    se_diff = mean(Diff_WME_SE),
    lower_diff = mean(Diff_WME_Causal_Low),
    upper_diff = mean(Diff_WME_Causal_Upp),
    N = nrow(.)
  ) %>% 
  mutate(across(where(is.numeric), \(x) round(x, 2)))







# citations_reanalysis_summ_tib
# citations_search_sample
# citations_combined_summ_tib

```

```{r inline-vals-WME-reanalysis-short}

# Comparing re-analysis WME values and original reports

## Different Estimates
diff_WME_est_over_point1_N <- sum(citations_combined_summ_tib$Diff_WME_Est_Over_Point1)
diff_WME_est_over_point1_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_Diff_WME_Est_Over_Point1)) %>% 
  pull(Auth_Cite_Diff_WME_Est_Over_Point1) %>% 
  paste(collapse = ", ")

## Different SEs
diff_WME_se_over_point1_N <- sum(citations_combined_summ_tib$Diff_WME_SE_Over_Point1)
diff_WME_se_over_point1_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_Diff_WME_SE_Over_Point1)) %>% 
  pull(Auth_Cite_Diff_WME_SE_Over_Point1) %>% 
  paste(collapse = ", ")

## Different CIs
diff_WME_CIs_over_point1_N <- sum(citations_combined_summ_tib$Diff_WME_CIs_Over_Point1)
diff_WME_CIs_over_point1_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_Diff_WME_CIs_Over_Point1)) %>% 
  pull(Auth_Cite_Diff_WME_CIs_Over_Point1) %>% 
  paste(collapse = ", ")

## Comparable estimates + CIs
comp_WME_est_CI_N <- sum(citations_combined_summ_tib$Comp_WME_Est_CI)
comp_WME_est_CI_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_Comp_WME_Est_CI)) %>% 
  pull(Auth_Cite_Comp_WME_Est_CI) %>% 
  paste(collapse = ", ")

## Causal Reports
diff_WME_causal_N <- sum(citations_combined_summ_tib$Diff_WME_Causal_Report)
diff_WME_c_nc_N <- sum(citations_combined_summ_tib$Diff_WME_Causal_To_No_Causal)
diff_WME_c_nc_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_WME_Causal_To_No_Causal)) %>% 
  pull(Auth_Cite_WME_Causal_To_No_Causal) %>% 
  paste()
diff_WME_nc_c_N <- sum(citations_combined_summ_tib$Diff_WME_No_Causal_To_Causal)
diff_WME_nc_c_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_WME_No_Causal_To_Causal)) %>% 
  pull(Auth_Cite_WME_No_Causal_To_Causal) %>% 
  paste()

```


#### Data Validation and Re-Analysis
\leavevmode\newline There were missing gene-outcome coefficients for 3 instruments from Xie et al[@xie_associations_2023], and 1 instrument in Clift et al[@clift_smoking_2022] was reported as having an implausibly large gene-outcome coefficient and standard error (-1243.03 and 19161.64, respectively); these instruments were excluded from the main analyses, and included/imputed as the most extreme values per study as a worst-case sensitivity analysis, which did not change conclusions (Appendix \@ref(appendix-sens-reanalysis)). Data were otherwise complete as expected per the descriptions in each study manuscript. A summary of the re-analysis results is presented in Table \@ref(tab:citations-reanalysis-summ-display); estimates are presented both as $\beta$ regression coefficients and \acr{OR}s for discrete variables to aid comparison across studies.

#### Re-Analysed vs Reported WME Causal Estimates
\leavevmode\newline `r diff_WME_est_over_point1_N` of the \acr{WME} estimates generated through re-analysis matched the originally reported estimates poorly (`r diff_WME_est_over_point1_cites`), with a >0.1 difference in re-analysis estimates of \acr{OR} versus the values originally reported. Re-analysed \acr{OR} upper or lower \acr{CI}s were >0.1 different to reported values for `r diff_WME_CIs_over_point1_N` studies (`r diff_WME_CIs_over_point1_cites %>% gluedown::md_text()`). Details of instruments used in re-analysis were re-checked against the relevant manuscripts to confirm accuracy of data used, with no discrepancies found.

Overall, estimates and \acr{CI}s from re-analysis of the other `r comp_WME_est_CI_N` studies (`r comp_WME_est_CI_cites`) appeared comparable to reported values, after accounting for rounding errors from published summary data, and random variation inherent in bootstrap generation of \acr{CI}s.

Compared with reported values of \acr{OR}s across the `r WME_diff_mean_OR$N` studies using them, the mean difference for effect estimates (\acr{SE} of estimate) from the re-analysis estimate was `r paste0(WME_diff_mean_OR$est_diff, " (", WME_diff_mean_OR$se_diff, ")")`. For 95% \acr{CI}s, the mean differences between reported and re-analysed values were `r WME_diff_mean_OR$lower_diff` for the lower bounds and `r WME_diff_mean_OR$upper_diff` for upper bounds, i.e. reported \acr{CI}s were narrower on average than re-analysed \acr{WME} \acr{CI}s.

Conclusions regarding presence of a causal effect were mostly consistent: reported  \acr{WME} and re-analysed \acr{WME} estimates were discordant in detecting a causal exposure-outcome effect for `r diff_WME_causal_N` studies:  `r diff_WME_c_nc_N` where a previously reported causal effect was not found (`r diff_WME_c_nc_cites %>% gluedown::md_text()`), and `r diff_WME_nc_c_N` where a causal effect was found that had not been reported previously (`r diff_WME_nc_c_cites %>% gluedown::md_text()`).


<!-- three re-analysed studies detected a causal effect by \acr{WME} not reported previously (Choi et al [@choi_assessment_2019], Mokry et al [@mokry_obesity_2016] and Xu et al[@xu_causal_2022]); one study detected no causal effect in re-analysis despite one being reported in the original publication (Ligthart et al [@ligthart_genome_2018]). -->



<!-- [@choi_assessment_2019; @pasman_gwas_2018; @ligthart_genome_2018; @carter_understanding_2019; @mokry_obesity_2016; @carreras-torres_role_2017; @xu_causal_2022; @budu-aggrey_evidence_2019; @xie_associations_2023; @clift_smoking_2022] -->


```{r inline-vals-reanalysis-Hevo-WME-short}
# Comparing within re-analysis only WME vs MR-Hevo

## Different Estimates
diff_Hevo_WME_est_over_point1_N <- sum(citations_combined_summ_tib$Diff_Hevo_WME_Est_Over_Point1)
diff_Hevo_WME_est_over_point1_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_Diff_Hevo_WME_Est_Over_Point1)) %>% 
  pull(Auth_Cite_Diff_Hevo_WME_Est_Over_Point1) %>% 
  paste(collapse = ", ")

## Different SEs
diff_Hevo_WME_se_over_point1_N <- sum(citations_combined_summ_tib$Diff_Hevo_WME_SE_Over_Point1)
diff_Hevo_WME_se_over_point1_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_Diff_Hevo_WME_SE_Over_Point1)) %>% 
  pull(Auth_Cite_Diff_Hevo_WME_SE_Over_Point1) %>% 
  paste(collapse = ", ")

## Different CIs
diff_Hevo_WME_CIs_over_point1_N <- sum(citations_combined_summ_tib$Diff_Hevo_WME_CIs_Over_Point1)
diff_Hevo_WME_CIs_over_point1_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_Diff_Hevo_WME_CIs_Over_Point1)) %>% 
  pull(Auth_Cite_Diff_Hevo_WME_CIs_Over_Point1) %>% 
  paste(collapse = ", ")

## Comparables
comp_Hevo_WME_est_CI_N <- sum(citations_combined_summ_tib$Comp_Hevo_WME_Est_CI)
comp_Hevo_WME_est_CI_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_Comp_Hevo_WME_Est_CI)) %>% 
  pull(Auth_Cite_Comp_Hevo_WME_Est_CI) %>% 
  paste(collapse = ", ")

## Mean diffs

Hevo_WME_diff_mean_OR <- citations_combined_summ_tib %>% 
  filter(Reported_WME_Measure == "OR") %>% 
  #select(Diff_Hevo_WME_Causal_Est, Diff_WME_Causal_Est)
  summarise(
    est_diff = mean(Diff_Hevo_WME_Causal_Est),
    se_diff = mean(Diff_Hevo_WME_SE),
    lower_diff = mean(Diff_Hevo_WME_Causal_Low),
    upper_diff = mean(Diff_Hevo_WME_Causal_Upp),
    N = nrow(.)
  ) %>% 
  mutate(across(where(is.numeric), \(x) round(x, 3)))


## Causal Reports
diff_Hevo_WME_causal_N <- sum(citations_combined_summ_tib$Diff_Hevo_WME_Causal_Report)
diff_Hevo_c_WME_nc_N <- sum(citations_combined_summ_tib$Diff_Hevo_Causal_WME_No_Causal)
diff_Hevo_c_WME_nc_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_Hevo_Causal_WME_No_Causal)) %>% 
  pull(Auth_Cite_Hevo_Causal_WME_No_Causal) %>% 
  paste()
diff_Hevo_nc_WME_c_N <- sum(citations_combined_summ_tib$Diff_Hevo_No_Causal_WME_Causal)
diff_Hevo_nc_WME_c_cites <- citations_combined_summ_tib %>% 
  filter(!is.na(Auth_Cite_Hevo_No_Causal_WME_Causal)) %>% 
  pull(Auth_Cite_Hevo_No_Causal_WME_Causal) %>% 
  paste()


## Proportion reporting causal
reanalysis_Hevo_causal <- citations_reanalysis_summ_tib$Hevo_est_causal_detected %>% sum(na.rm = TRUE)
re_analysis_Hevo_causal_cites <- citations_combined_summ_tib %>% 
  filter(Hevo_est_causal_detected) %>% 
  mutate(Auth_Cite_Hevo_Causal = paste0(Study_Author, "[", Study_Ref, "]")) %>% 
  pull(Auth_Cite_Hevo_Causal) %>% 
  paste(collapse = ", ")

reanalysis_WME_causal <- citations_reanalysis_summ_tib$WME_est_causal_detected %>% sum(na.rm = TRUE)
reanalysis_causal_discordant <- citations_reanalysis_summ_tib$Discordant %>% sum(na.rm = TRUE)
```

#### Re-Analysed WME vs MR-Hevo Causal Estimates
\leavevmode\newline Causal effect estimates generated by MR-Hevo were >0.1 different from re-analysed \acr{WME} estimates for `r diff_Hevo_WME_est_over_point1_N` studies (`r diff_Hevo_WME_est_over_point1_cites`). Compared with \acr{WME} values of \acr{OR}s across the `r Hevo_WME_diff_mean_OR$N` studies using them, the mean difference for effect estimates (\acr{SE} of estimate) from the re-analysis estimate was `r paste0(Hevo_WME_diff_mean_OR$est_diff, " (", Hevo_WME_diff_mean_OR$se_diff, ")")`. For 95% \acr{CI}s, the mean differences between MR-Hevo and \acr{WME} values were `r Hevo_WME_diff_mean_OR$lower_diff` for the lower bounds and `r Hevo_WME_diff_mean_OR$upper_diff` for upper bounds, i.e. MR-Hevo \acr{CI}s were wider and slightly shifted in the negative direction on average than \acr{WME} values. MR-Hevo \acr{OR} upper or lower \acr{CI}s were >0.1 different to \acr{WME} values for `r diff_Hevo_WME_CIs_over_point1_N` studies (`r diff_Hevo_WME_CIs_over_point1_cites %>% gluedown::md_text()`).

Overall, estimates and \acr{CI}s from MR-Hevo analysis of the other `r comp_Hevo_WME_est_CI_N` studies (`r comp_Hevo_WME_est_CI_cites`) appeared comparable to re-analysed \acr{WME} values.

Conclusions regarding presence of a causal effect were consistent: re-analysed \acr{WME} estimates were discordant in detecting a causal exposure-outcome effect in `r diff_Hevo_WME_causal_N` studies versus MR-Hevo, with both reporting a causal effect in the same `r citations_reanalysis_summ_tib$Hevo_est_causal_detected %>% sum(na.rm = TRUE)` studies (`r re_analysis_Hevo_causal_cites %>% gluedown::md_text()`).


\blandscape

```{r citations-reanalysis-summ-display, include=TRUE, cache=FALSE}
#| tab.id = "citations-reanalysis-summ-display",
#| tab.cap = "Re-analysis of ten highly-cited two-sample Mendelian randomisation articles reporting a weighted median estimate of causal effect, comparing results of both WME and MR-Hevo causal effect estimation methods",
#| ft.arraystretch = 1.5


citations_reanalysis_summ_display <- citations_reanalysis_summ_tib %>%
  # Change names for cleaner plotting
  mutate(across(where(is.numeric), \(x) round(x, 3)), 
         Study_SNPs = WME_nsnp,
         Blank = NA,
         Weighted_Median_Beta = paste0(round(WME_est, 2), " (", round(WME_est_lower_CI, 2), "-", round(WME_est_upper_CI, 2), ")"),
         Weighted_Median_SE = WME_se,
         Weighted_Median_OR = paste0(round(WME_OR, 2), " (", round(WME_OR_lower_CI, 2), "-", round(WME_OR_upper_CI, 2), ")"),
         Weighted_Median_Causality = if_else(WME_est_causal_detected, "Yes", "No"),
         Blank_2 = NA,
         MR_Hevo_Beta = paste0(round(Hevo_est, 2), " (", round(Hevo_est_lower_CI, 2), "-", round(Hevo_est_upper_CI, 2), ")"),
         MR_Hevo_SE = round((Hevo_est_upper_CI - Hevo_est_lower_CI)/3.92, 3),
         MR_Hevo_OR = paste0(round(Hevo_OR, 2), " (", round(Hevo_OR_lower_CI, 2), "-", round(Hevo_OR_upper_CI, 2), ")"),
         MR_Hevo_Causality = if_else(Hevo_est_causal_detected, "Yes", "No")
         ) %>% 
  # Sort
  arrange(Study_Author) %>% 
  # Drop old names
  select(Study_Author,
         #Study_Ref,
         #Study_DOI,
         Study_Exposure,
         Study_Outcome,
         Study_SNPs, 
         Blank,
         Weighted_Median_Beta,
         Weighted_Median_SE,
         Weighted_Median_OR,
         Weighted_Median_Causality,
         Blank_2,
         MR_Hevo_Beta,
         MR_Hevo_SE,
         MR_Hevo_OR,
         MR_Hevo_Causality) %>% 
    mutate(across(where(is.double), round, 3)) %>% 
  #as_grouped_data(groups = "Study_Author", expand_single = FALSE,) %>%
  flextable(#hide_grouplabel = TRUE, 
    col_keys = c("Study_Author", #"Study_Ref", #"Study_DOI",
                 "Study_Exposure",
                 "Study_Outcome",
                 "Study_SNPs", 
                 "Blank", #5
                 "Weighted_Median_Beta", 
                 "Weighted_Median_SE",
                 "Weighted_Median_OR",
                 "Weighted_Median_Causality",
                 "Blank_2", #10
                 "MR_Hevo_Beta", 
                 "MR_Hevo_SE",
                 "MR_Hevo_OR",
                 "MR_Hevo_Causality")) |>
  # To separate Study Details/WME/MR-Hevo
  width(j = c(5, 10), width = 0.2) |>
  span_header() |>
  align(part = "all", align = "center") |>
  # Fix names 
  ## Blank cols - unsure why not working as above
  flextable::compose(part = "header", i = 1:3, j = c(5, 10), value = as_paragraph("")) |>
  ## Blank study top row
  flextable::compose(part = "header", i = 1, j = c(1), value = as_paragraph("")) |>
  empty_blanks() |>
  ## WME
  flextable::compose(part = "header", i = c(1:2), j = c(6:9), value = as_paragraph("Weighted Median")) %>% 
  merge_v(part = "header", j = c(6:9)) %>% 
  ## MR-Hevo
  flextable::compose(part = "header", i = c(1:2), j = c(11:14), value = as_paragraph("MR-Hevo")) %>% 
  merge_v(part = "header", j = c(11:14)) %>% 
  ## Causality
  width(j = c(6, 8, 11, 13), width = 20) |>
  flextable::compose(part = "header", i = 3, j = c(9, 14), value = as_paragraph("Causality\nReported")) |>
  ## SE*
  flextable::compose(part = "header", i = 3, j = c(12), value = as_paragraph("SE*")) |>
  ## Blanks
  empty_blanks() |>
  ## Beta
  flextable::compose(part = "header", i = 3, j = c(6, 11), value = as_paragraph("\U03B2")) |> #\U0302
  # Remove ORs for continuous 
  flextable::compose(part = "body", i = 8, j = c(8, 13), value = as_paragraph("-")) |> #\U0302
  # Separating lines
  hline(part = "header", i = 2, j = c(6:9, 11:14), border = officer::fp_border(color = "black", width = 1)) |>
  hline(part = "body", i = c(1:10), j = c(1:14), border = officer::fp_border(color = "black", width = 0.2)) |>
  # Fix dimensions
  autofit() |>
  line_spacing(space = 1, part = "header") |>
  line_spacing(space = 1, part = "body") |>
  fit_to_width(max_width = 9) |>
  height_all(height = 0.6) |>
  #height_all(height = 40, unit = "mm",part = "all") |>
  # Add footer
  add_footer_lines("\U03B2 and OR presented as: estimate (95% CI).\n\U03B2: causal effect estimate, CI: Confidence Interval, OR: Odds Ratio, SE: Standard Error, SE*: Estimated Standard Error.\nBMI: body mass index, CRP: C-reactive protein, NAFLD: non-alcoholic fatty liver disease, T2DM: type 2 diabetes mellitus") |>
  #footnote(i = c(1,4), j = c(2, 5), part = "header", value = as_paragraph(c("IV: Instrumental Variable", "SE: Standard Error")))
  fontsize(9, i = c(1:3), j = c(1:14), part = "header") |>
  fontsize(8, i = c(1:3), j = c(1:14), part = "header") |>
  fontsize(8, i = c(1:10), j = c(1:14), part = "body") |>
  fontsize(8, i = 1, j = 1, part = "footer")
  # reframe(N = N,
  #         WME_Av = mean(WME_est),
  #         WME_SE = mean(WME_se),
  #         Hevo_Av = mean(Hevo_est),
  #         Hevo_SE = mean(Hevo_se),
  #         Hevo_Est_Causal = Hevo_est_causal_detected
  # ) %>%

citations_reanalysis_summ_display

```

\elandscape




<!--chapter:end:4_Results.Rmd-->

# Discussion

```{r setup5, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Performance of Methods 

### Simulation

#### Null Causal Effect
\leavevmode\newline For a null causal effect, MR-Hevo exhibited broadly similar bias away from the null to \acr{WME} on average, with both methods tending to slightly over-estimate the true value. Considering variance of estimates, the mean estimated \acr{SE} for MR-Hevo was fractionally higher than for \acr{WME}. For MR-Hevo, both bias and variance of estimates generally appeared to increase relatively more than those of \acr{WME} with increasing proportion of invalid instruments under the assumptions of Scenarios 1 and 2, and relatively less under Scenario 3 assumptions.

Despite comparable average effect estimation from a quantitative perspective, MR-Hevo was consistently more accurate in categorical classification as causal/no causal effect, exhibiting a superior false-positive rate in all 24 parameter/scenario combinations with null causal effect. False-positive reports from \acr{WME} in particular appeared to correlate with parameter/scenario combinations promoting greater pleiotropy and therefore bias away from the null, potentially suggesting that MR-Hevo estimates are relatively more robust to assumption violations than \acr{WME}. As false-positive reports were still an infrequent occurrence for both methods, it is perhaps unsurprising that mean estimates/\acr{SE}s don't clearly reflect this difference in Type 1 error. 

These results do suggest that, despite MR-Hevo point estimates being marginally more biased away from the null on average than those of \acr{WME}, MR-Hevo appears to more effectively deal with pleiotropic effects regarding reporting of causality. This primarily appears to be by appropriately reducing the reported precision of the estimate to reflect additional uncertainty, consistently reducing Type 1 error for MR-Hevo versus \acr{WME}. 

#### Positive Causal Effect
\leavevmode\newline When a positive causal effect was present, MR-Hevo exhibited a slightly higher mean true-positive rate than \acr{WME} both when all results were pooled, and also in the majority of parameter/scenario combinations. MR-Hevo estimates were generally more biased in the positive direction than \acr{WME}; this bias was generally stable across scenarios for MR-Hevo. For \acr{WME} estimates, reported causal effect magnitude appeared to correlate with assumption violations promoting bias away from the null, again potentially suggesting that this method's estimates are more susceptible to peturbation by pleiotropic effects. In this light, higher true-positive rates for \acr{WME} versus MR-Hevo seen in Scenario 3 with $\ge$ 20% invalid instruments may seem a less convincing endorsement for its use. 

Variance of estimates was similar to the null causal effect case, with broadly comparable average \acr{SE}s/\acr{CI}s across both methods, though disproportionately higher variance for MR-Hevo versus \acr{WME} estimates with parameter/scenario combinations promoting bias due to pleiotropy.

Again, these findings would be in keeping with MR-Hevo reporting causality in a way more robust to assumption violations than \acr{WME}, rather than \acr{WME} truly being a more powerful method for detecting causal effects.

An exception to general trends is the combination of 0% invalid instruments with 20,000 participants, where MR-Hevo reports narrower \acr{CI}s - and therefore correctly reports disproportionately more causal effects - than either \acr{WME} using that parameter combination, or MR-Hevo at 0% invalid instruments with 10,000 participants.

It is not clear why this combination is associated with such a high causal report rate for MR-Hevo. If MR-Hevo performed particularly well versus \acr{WME} in the absence of invalid instruments, this would be expected to hold in the 10,000 participants case also. Similarly, if MR-Hevo were particularly sensitive to the difference in sample size versus \acr{WME}, larger discrepancies would be expected between the two methods with other parameter/scenario combinations when transitioning between 10,000 to 20,000 participants. Differences in assumption violations between scenarios do not affect this result, as assumption violations are only relevant to invalid instruments, of which there are none in the 0% invalid case. This unexpected result may be an aberrant feature of the particular datasets generated, which could be investigated by re-running the analysis from a different random seed. Alternatively, it may be that, with respect to the power of MR-Hevo methods to detect a true causal effect, sample size interacts in a non-linear way with invalid instrument proportions approaching zero. If the causal report rate for this parameter/scenario combination remained high after data simulation with a different seed, this possibility could be next investigated using simulated datasets with invalid instrument proportions between 0-10%.

### Re-Analysis

As discussed in \@ref(lim-cite), the comparison of re-analysis \acr{WME} causal effect estimates to those of MR-Hevo may represent the true performance of MR-Hevo on "real-world" data poorly, given the poor reproducibility of \acr{WME} findings on re-analysis. This inability to reproduce published results using the corresponding published data and methods potentially represents a major issue for the field of \acr{MR} - arguably greater than any difference in outcomes between causal estimation methodologies. A full discussion is outside the scope of this project; however, the following data features were noted which may explain some of this phenomenon. Of the six studies with reproducible \acr{WME} estimates, all presented data rounded to three to five decimal places. By contrast, of the four non-reproducible studies, only one (Ligthart et al[@ligthart_genome_2018]) presented data rounded to three decimal places, with the other three reporting to one to two significant figures. It is possible that such minor data variations are proportionally large enough to influence causal effect estimates, given that most gene-exposure and gene-outcome coefficients are numerically small in absolute terms. The author (B233241) was unable to find any literature pertaining to this, or indeed to reproducibility of \acr{MR} results in general; this would seem to be a lacuna which warrants further investigation.

In studies where \acr{WME} estimates were reproducible, MR-Hevo estimates and \acr{CI}s matched these closely. Across all studies, reproducible or not, conclusions regarding causality matched exactly, although estimates and particularly confidence intervals differed substantially between the two methods for some studies. This is a broadly reassuring finding, suggesting that the conclusions of the most highly-cited works in the field are robust to differences in methodology. However, with thousands of \acr{MR} studies now reported, as evidenced by the citation search returning 5,417 articles referencing Bowden et al [@bowden_consistent_2016] alone, this is not to say that MR-Hevo could not change conclusions of many published \acr{MR} studies in the literature if it were used to re-analyse their data.

## Results in Context

A key concern in the \acr{MR} literature of late has been of suspiciously high numbers of studies reporting causal effects, often in cases where causality does not seem biologically plausible[@stender_reclaiming_2024]. It is against this backdrop that the creators of MR-Hevo introduce their approach as a potential solution, and it is worth considering this wider context before assessing the relative merits of each method.

Several factors may be driving high positive report rates observed in published \acr{MR} studies. As with other academic fields, there is likely to be an element of publication bias in favour of studies reporting statistically significant results [@bowden_mendelian_2015; @bowden_modelling_2010]; naturally, no causal effect estimation methods will be able to address this issue. The widespread availability and use of tools such as the `TwoSampleMR` R package[@hemani_mr-base_2018] facilitate production of \acr{MR} studies at scale. Genetic studies without a plausible hypothetical basis are at high baseline risk of false positives due to implicit multiple comparisons, given the number of potential exposures and outcomes which could be examined[@balding_tutorial_2006]. The ability to generate \acr{MR} studies in an automated way renders all such spurious associations more easily accessible for attempted publication; if these are then preferentially published versus the negative findings, this could contribute to the proliferation of positive \acr{MR} studies observed. This was recognised by the creators of MR-Base themselves, prompting them to write a paper which programmatically assessed all possible exposure-outcome associations on the platform, in an attempt to disincentivise this practice[@hemani_automating_2017]:

>"...we said what we're going to do is do the Mendelian randomization of everything against everything and put it online, and then say no one should be able to publish just the two-sample Mendelian randomization study because we've done them all" [@mrc_ieu_at_university_of_bristol_noodles_2023]

A related concern is that such methods are easily accessible to non-experts, such that the large numbers of studies so produced may also be disproportionately of low quality, without implementing safeguards against such issues. Some authors go so far as to state that \acr{MR} needs "reclaiming...from the deluge of papers and misleading findings" [@stender_reclaiming_2024], and recommending evidence "triangulation" - i.e. presenting non-\acr{MR} data to support each claim of causality detected by \acr{MR} methods - should be a necessary adjunct to publication of any causal \acr{MR} finding[@munafo_triangulating_2021].

By contrast, the group behind MR-Hevo assert that valid methods should yield valid results, regardless of the scale on which analyses are performed. Further, they argue that it is not biologically plausible that directional pleiotropy would routinely exist without the \acr{InSIDE} assumption also being violated[@mckeigue_inference_2024]. Regarding this study's simulation results, this pre-supposed coupling of direction and magnitude of pleiotropic effects would imply that Scenario 2 is essentially defunct. The most relevant assumption set regarding bias introduced by invalid instruments with pleiotropic effects would then be Scenario 3, where \acr{WME} exhibited the highest false-positive causal report rates, and where MR-Hevo arguably exhibits both the greatest robustness to assumption violations, but also the largest fall in true-positive rate versus \acr{WME}. In the above "everything against everthing" pre-print[@hemani_automating_2017], it is significant that evidence of pleiotropy was noted in >90% of comparisons on the MR-Base platform. The presence of truly balanced pleiotropy would be expected to add only variance to causal effect estimates, and therefore could not explain a high false-positive causal report rate. Taken together, this would therefore suggest that MR-Hevo is the more suitable of the two methods to address any contributions of pleiotropic effects to the high false-positive causal report rates observed.

<!-- ?Resources e.g. compute -->



\newpage

<!--chapter:end:5_Discussion.Rmd-->

# Limitations and Recommendations

```{r setup6, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(biostats101)

```


## Limitations 

### Simulation Study {#lim-sim}

Key objectives of this study were to evaluate the bias and variance of \acr{WME} and MR-Hevo causal estimates under differing sets of assumptions, including differing proportions of invalid genetic instruments. The random seed used happened to assign similar numbers (6 vs 7) of invalid instruments to both the 20% and 30% invalid instrument cases; relevant code was checked to ensure this was not an error in specification of model parameters. As this was noted after analysis had begun, it was decided not to re-run simulations to avoid implicit multiple comparisons in analysis. However, the resulting datasets generated arguably do not represent the true differences expected between cohorts with a 10% change in valid instrument proportion. In particular, Scenario 3 simulations may have been disproportionately affected by this phenomenon. \acr{InSIDE} assumption violation means each invalid instrument may introduce different proportions of variance and bias to the causal effect estimates generated. If the average variance introduced per instrument is greater than the average bias introduced per instrument, then adding a single extra invalid instrument may act to bias towards the null if its predominant effect is to reduce estimate precision. The addition of several extra instruments may be required for variance terms to average each other out and so for bias terms to predominate; this may explain why several trends in causal estimates, confidence intervals and causal report rates abruptly plateau around 20% under assumptions for Scenarios 1 and 2, and reverse under Scenario 3. Conclusions drawn from trends tracking the progression from 0% to 20% invalid instruments should be unaffected, but extrapolating trends with $\ge$ 30% invalid instruments from these data alone would seem inadvisable. If desired, simulations could be extended to progressively larger proportions of invalid instruments to investigate this possibility further.

This study had intended to exactly duplicate the simulation methodology of Bowden et al[@bowden_consistent_2016] to maximise comparability of results; however several barriers prevented this. As outlined in [Methods], the process of genotype generation, including frequencies of effect/non-effect alleles of simulated genetic instruments, was not reported by Bowden et al[@bowden_consistent_2016]. In addition, Bowden et al used 10,000 simulations per meta-analysis of each combination of Scenario assumptions and simulation parameters; this was rendered impractical due to the computationally intensive nature of MR-Hevo's resampling approach. On a mid-range home desktop computer (specification found in Appendix \@ref(Session-Information)), each combination of scenario/parameters took in the order of 8 hours to process $n = 1,000$ datasets; testing indicated that the vast majority of processing time was used by MR-Hevo, rather than \acr{WME}. Assuming linear $O(n)$ growth in processing time, this implies reproducing both tables would take `r ((8*2*24)/24/7) %>% round(., digits = 2)` weeks of processing time, which was not practical with the time available. This was also realised too late in the project timeline to arrange for alternative computing capability, such as through the University of Edinburgh's compute cluster "Eddie"[@noauthor_eddie_nodate]. Although exact replication would have been desirable, using 1,000 simulated datasets per analysis appears to have been sufficient to generate comparable mean values of the parameter estimates to those reported by Bowden et al[@bowden_consistent_2016]. The main effect of increasing number of datasets per meta-analysis would be to improve precision of the mean estimates of each parameter (i.e. precision of mean causal effect estimates, mean \acr{SE}s and mean \acr{CI}s). As the spread of these parameter estimates is not reported in Tables \@ref(tab:no-causal-sim-summ-display) and \@ref(tab:causal-sim-summ-display), this change is not likely to have affected conclusions from this study.

Finally, it was noted that parameters used during simulation were not representative of values observed in the ten highly-cited studies used for the re-analysis section of this project. Both number of genetic instruments and number of participants were at least an order of magnitude lower in simulations versus re-analysed studies. Additionally, due to the nature of two-sample \acr{MR} studies, numbers of participants in exposure versus outcome cohorts varied substantially in several real-world studies, whereas the simulation code only considered equally sized cohorts. As mentioned in [Methods], effect allele frequency was simulated around 50% in line with Bowden et al[@bowden_consistent_2016]; where re-analysed studies reported effect allele frequencies, these typically varied from around 10-90% across the range of genetic instruments included. The effects of varying any of these parameters, either alone or in combination, could plausibly affect the true- and false-positive report rates of any \acr{MR} causal effect estimation method. Post-hoc sensitivity analyses of simulations using larger numbers of instruments and participants (chosen as the most discrepant parameters versus observed values) are presented in Appendix \@ref(appendix-sens-post-hoc); these analyses indicate substantial changes in study conclusions could result from such alterations to simulation parameters, with \acr{WME} false-positive rates up to 100% in some cases. It may be that the original simulation parameter values reflect the majority of \acr{MR} literature better than these highly-cited studies, which by their nature would be expected to include more data than is typical for the field. However, given that these parameter values are taken from the original \acr{WME} exposition[@bowden_consistent_2016], it is also possible that they were originally chosen as a "best case scenario", intended to represent \acr{WME} performance in the most favourable possible light. If this were the case, then \acr{WME} could paradoxically struggle more with the increasingly comprehensive datasets now commonly used for \acr{MR} studies. Extending this project using simulation parameter values more representative of real-world data would therefore seem warranted before drawing definitive conclusions regarding relative performance of both methods.



### Re-Analysis of Published Data {#lim-cite}
```{r lim-cite-inline-vals}

max_FPRR_row <- no_causal_sim_summ_tib %>% 
  mutate(Pos_Rate_Diff_Abs = abs(Pos_Rate_Diff)) %>% 
  filter(Pos_Rate_Diff_Abs == max(Pos_Rate_Diff_Abs))

#max_FPRR_row

samp_size_mean_diff <- power.paired.prop(p1 = 0.0041, p2 = 0.051, conf.level = 0.95,power = 0.8,alternative = "two.sided")
samp_size_max_diff <- power.paired.prop(p1 = max_FPRR_row$Hevo_Pos_Rate, p2 = max_FPRR_row$WME_Pos_Rate, conf.level = 0.95,power = 0.8,alternative = "two.sided")

```

As noted in [Results], reproducibility of published findings from each re-analysed study was sub-optimal, despite using the same set of genetic instruments as reported in each study. The degree of divergence between published and re-analysed values was not anticipated, and therefore not accounted for in study design. It had been expected that \acr{WME} re-analysis would confirm published findings more closely, allowing comparison of MR-Hevo vs re-analysed \acr{WME} estimates to be a valid proxy for comparison of MR-Hevo vs published \acr{WME} results; this was only the case in six re-analysed studies. In this project, results of re-analysis were included irrespective of consistency of results with published data; however, any similar future work could employ exclusion criteria for studies whose estimates are not replicable within a specified error margin.

Even if all ten studies had given consistent estimates on re-analysis, this study would have been substantially under-powered to detect a true difference between methods. Using the mean difference in false-positive report rate observed across all scenario/parameter combinations in the simulation study (MR-Hevo = `r no_causal_Hevo_mean_pos_rate`% vs \acr{WME} = `r no_causal_WME_mean_pos_rate`%, Section \@ref(results-sim-no-causal)), to detect a difference of this size with $\alpha = 0.05$ and $1 - \beta = 0.8$ would require a sample size of around `r samp_size_mean_diff$sample_size` studies to be re-analysed by both methods. If only 40% of studies were adequately reproducible for inclusion, the required sample size for re-analysis would increase to `r (samp_size_mean_diff$sample_size/4*10) %>% round(., 0)`. Even with the most extreme difference in false positive report rates observed (MR-Hevo = `r max_FPRR_row$Hevo_Pos_Rate * 100`% vs \acr{WME} = `r max_FPRR_row$WME_Pos_Rate * 100`%;  $N =$ `r max_FPRR_row$N %>% format(scientific = FALSE)`, `r max_FPRR_row$Prop_Invalid * 100`% invalid instruments, Scenario 3; Table \@ref(tab:no-causal-sim-summ-display)), the required sample size would be `r samp_size_max_diff$sample_size`, or `r (samp_size_max_diff$sample_size/4*10) %>% round(., 0)` if only 40% of studies were adequately reproducible for inclusion. As such, it is not possible to conclude that MR-Hevo methods would not change conclusions in a substantial number of studies; as stated in [Methods], the intent of this project was to assess the potential impact of MR-Hevo by initially re-analysing high-impact studies, where impact was proxied by citation count.

## Recommendations

The results of this project do not suggest the need to disregard every \acr{MR}-derived causal association identified using \acr{WME} methodology. However, the results would be compatible with a substantial absolute number of studies in the literature which may falsely report a causal effect due to use of \acr{WME}. Furthermore, causal reports from \acr{MR} studies may separately be untrustworthy by virtue of not being reproducible from data and methodology reported; the extent to which this affects the \acr{MR} evidence base is not known. If MR-Hevo were used in place of \acr{WME} to identify potential causality in future \acr{MR} studies, this would be expected to lower the false-positive report rate by up to ~25% - though with a potential loss of statistical power of ~10-20% in situations where significant bias from pleiotropic effects is present. Given the field-wide concerns regarding high false-positive rates, this may be a reasonable compromise.

Following this project, the recommendations below are offered:

- Further research is required to estimate the proportion of \acr{MR} literature whose results and conclusions are not reproducible from the data and methods presented. Such work would ideally investigate potential causes of such discrepancies (e.g. the contribution of rounding errors in summary results) so that guidance can be developed to prevent further non-reproducible studies being created. A less pressing research suggestion would be to evaluate the effect of varying simulation parameter values (e.g. number of participants, number of genetic instruments and effect allele frequency) on rates of true- and false-positive/true- and false-negative reports of causality from \acr{MR} causal estimation methods.

- Before taking any significant action on the results of any \acr{MR} study reporting causality using any methodology, attempts should be made to reproduce key findings from reported data and methods. Where this is not possible (e.g. due to data availability restrictions), consideration should be given as to whether said significant actions would still be taken if effect estimates and/or their \acr{CI}s were to alter by a plausible margin of around $\beta = \pm 0.1$

- For interpretation of existing \acr{MR} studies relying on \acr{WME} causal effect estimation, re-analysing using MR-Hevo methods is unlikely to substantially alter the magnitude or direction of estimated causal effect. Where a \acr{WME} \acr{MR} study reports no evidence of causality, MR-Hevo re-analysis is unlikely to overturn this conclusion. MR-Hevo is, however, more conservative than \acr{WME} when generating \acr{CI}s; it is therefore likely to change overall interpretation in a significant minority of cases reported as supporting a truly causal exposure-outcome association. Re-analysis of \acr{WME} \acr{MR} studies may therefore be warranted as a sensitivity analysis of \acr{WME} \acr{MR} studies reporting causality, either where significant action is planned on the strength of the results, or where the validity of the result is questioned.

- For future \acr{MR} studies looking to establish potential causal links between exposures and outcomes, use of MR-Hevo causal estimation is expected to produce a lower false-positive causal report rate than \acr{WME} methods. The main disadvantages are a) a corresponding loss in power in cases with substantial pleiotropy; and b) the extra compute required, though for most applications this difference will be trivial.

\newpage

<!--chapter:end:6_Limitations_Recommendations.Rmd-->

# Conclusions

This project principally aimed to establish whether the \acr{WME} causal effect estimation method for \acr{MR} studies produces over-confident effect estimates versus the MR-Hevo method, and whether this might affect the validity of conclusions drawn in real-world studies. 

Using simulated data with known parameters, \acr{WME} and MR-Hevo produced similar effect estimates and 95% \acr{CI}s when averaged over all cases.  However, MR-Hevo reported wider \acr{CI}s than \acr{WME} specifically in cases where key assumptions of \acr{IV} analysis were relatively more violated; this resulted in an overall false-positive report rate an order of magnitude lower for MR-Hevo versus \acr{WME} (`r no_causal_Hevo_mean_pos_rate`% versus `r no_causal_WME_mean_pos_rate`%) across simulations with no causal effect present. In cases where a causal effect truly was present, the overall sensitivity was slightly higher for MR-Hevo versus \acr{WME} (`r causal_Hevo_mean_pos_rate`% versus `r causal_WME_mean_pos_rate`%). In a minority of cases (42%), MR-Hevo's greatly improved specificity came at the expense of a moderate drop in sensitivity, typically in the order of 5-10%, though up to 23% in the most extreme case. Higher sensitivities with \acr{WME} versus MR-Hevo analysis appeared to correlate with increasing effect of parameters and assumption violations biasing away from the null; this result may therefore represent MR-Hevo estimates being more robust to assumption violations than those of \acr{WME}.

Re-analysis of data from highly cited \acr{MR} studies was attempted. \acr{WME} causal effect estimates were found to be poorly reproducible from available data; this finding alone is concerning for the validity of conclusions for the whole field of \acr{MR}, though further investigation of this phenomenon was outside the scope of this project. MR-Hevo produced 95% \acr{CI}s that were wider on average than those generated by \acr{WME}, and in 6 of 10 cases this difference was large enough that it could plausibly have changed conclusions for a small causal effect size. In the sample of 10 re-analysed studies, the final conclusion regarding presence of a true causal effect was not changed in any case by use of MR-Hevo versus \acr{WME} methods. Characteristics of included studies were noted to diverge significantly from simulation parameters used in the original validation of \acr{WME} and reproduced in this project, particularly in terms of number of participants and number of genetic instruments used.

These results suggest that MR-Hevo may be a more suitable method than \acr{WME} for avoiding false-positive reports of causality between exposures and outcomes, which has been a key challenge for the field of \acr{MR} of late. Within the limitations of the small sample of relatively high-quality \acr{MR} studies re-analysed, it does not appear necessary to disregard all conclusions drawn from existing \acr{WME} \acr{MR} analyses. Given the tendency of \acr{WME} to produce false-positive results, it may be warranted to re-analyse selected \acr{MR} studies which report causality from \acr{WME} estimates, e.g. where results are borderline suggestive of causality, where \acr{IV} analysis assumptions are likely to be substantially violated, or where significant further action is planned on the basis of \acr{MR} results. The main drawbacks of MR-Hevo versus \acr{WME} are the more computationally intensive implementation, and a reduction in sensitivity in cases with substantial pleiotropic effects present. Suggested directions for future work include quantifying and further characterising the non-reproducibility of \acr{MR} results observed here, and evaluating \acr{MR} causal estimation methods using simulation parameters representative of observed values from existing real-world studies.

\newpage

<!--chapter:end:7_Conclusions.Rmd-->

# References

<div id="refs"></div>

<!-- export Zotero as Western encoding -->

\newpage

<!--chapter:end:8_References.Rmd-->

# (APPENDIX) Appendix {-} 

\newpage

```{r setup9, include=FALSE}

knitr::opts_chunk$set(echo = TRUE,
                      include = TRUE,
                      warning=FALSE, 
                      message=FALSE, 
                      error=FALSE,
                      cache = TRUE,
                      dev = "png", 
                      dpi = 500
)

# Load packages
library(tidyverse)
library(dplyr) #bookdown not finding if_else
library(magrittr) #bookdown not finding %>%
library(bookdown)
library(here)
library(cowplot)
library(kableExtra)
library(acronymsdown)
library(grateful)

# Load University of Edinburgh colour palette
source(here::here("Script", "edin_uni_colours.R"))

# Load pre-formatted plot template - call to ggplot with UoE colours
source(here::here("Script", "edin_fig_style.R"))


```
# Appendix: List of Abbreviations {#appendix-acr}


\printacronyms


\newpage

# Appendix: Bootstrapping {#appendix-boot}

## General Method

The typical process for "bootstrap" generating an estimate, \acr{SE} and \acr{CI}s of a population parameter (e.g. population mean $\mu$) from a sample $x$ is as follows[@buscaglia_chapter_2020]:

1. A sample, $x$, of $n$ individuals is selected from a total population, $X$, of $N$ individuals
2. This sample $x$ is then treated as the "bootstrap population"; the empirical distribution of values in the $n$ individuals in the bootstrap population is taken to be broadly representative of the distribution of values in the underlying population $X$ of $N$ individuals
3. A "bootstrap sample", $x^*$,  is then obtained by re-sampling individuals from the bootstrap population with replacement $n$ times per bootstrap sample, i.e. the new bootstrap sample also comprises $n$ sampled individuals, $x^*_1, x^*_2,...x^*_n$. As such, individuals from the original bootstrap population $x$ may contribute once, more than once or not at all to each bootstrap sample $x^*$.
4. A total of $k$ bootstrap samples are generated, $x^{*1}, x^{*2},...x^{*k}$, and the statistic of interest (e.g. sample mean $\bar{x}$) is estimated in each individual sample, $\bar{x}^{*i}$, giving the complete set of $\bar{x}^{*1}, \bar{x}^{*2},...\bar{x}^{*i}...\bar{x}^{*k}$.
5. The set of $k$ statistics are combined to form a "bootstrap distribution"; as expected from \acr{CLT}[@ross_chapter_2014], this is typically closer to a normal distribution than the underlying distribution of values in either the bootstrap population $x$ or the total population $X$. (See Figure \@ref(fig:prostate-vol) for an example of this)
6. The final values are derived as follows:

> - the parameter estimate (e.g. estimate of the true population mean, $\hat{\mu}$) is taken as the mean of the bootstrap distribution of $k$ estimates, $\hat{\mu} = (\sum^k_{i = 1} \bar{x}) \div k$
> - the \acr{CI}s are taken as the values at the appropriate centiles at the edges of the sampling distribution, e.g. a 95% \acr{CI} would be generated using values at the 2.5th and 97.5th centiles
> - the \acr{SE} of the estimate is taken as the \acr{SD} of the sampling distribution, given by $\sqrt{\frac{1}{k - 1} \sum^k_{i = 1} (\bar{x_i} - \hat{\mu})^2}$



## Example: Prostate Volume

The above process is illustrated in Figure \@ref(fig:prostate-vol). Data on prostate volume in 307 prostate cancer patients demonstrates a right-skewed distribution (A). An empirical distribution from a sample of 100 of these patients mirrors this right skew, and is used as the "bootstrap population" (B) for further re-sampling. As the bootstrap population is re-sampled more and more times, the "bootstrap distribution" of the sample means generated (C and D) gradually tends towards a normal distribution. The 95% \acr{CI} is given by the bounds defining the middle 95% of the bootstrap distribution of estimated means, as shown (red-shaded areas).

```{r prostate-vol, echo=FALSE, include=TRUE, fig.dim = c(6, 7.5)}
#| fig.id = 'prostate-vol',
#| fig.cap = "Histograms demonstrating distribution of prostate volumes in patients with prostatic cancer, taken from Cata et al 2011[@cata_blood_2011] via the R package `medicaldata`[@medicaldata]. A) Distribution from whole study population of 307 patients with non-missing data, exhibiting right-skew. B) Distribution from random sample of 100 patients, still exhibiting right-skew. C) Bootstrap distribution generated by re-sampling 1,000 bootstrap samples from the original sample of 100 patients, right-skew less apparent. D) Bootstrap distribution generated by re-sampling 100,000 bootstrap samples from the original sample of 100 patients, approaching normality. 95% confidence intervals are demonstrated in plots C and D by marking the 2.5th and 97.5th centiles (red-shaded areas)."


library(medicaldata)
library(infer)
library(gghighlight)

prostate_vol_pop <- blood_storage %>% 
  plot_template() +
  geom_histogram(aes(x = PVol), 
                 binwidth = 2,
                 #y = stat(density)),
                 fill = edin_blue_hex) +
  labs(subtitle = "A) True distribution, N = 307",
       x = NULL) +
  xlim(10, 275) +
  theme(axis.text.y = element_text(angle = 90, vjust = 0.5, hjust=0.5))

set.seed(1701)
prostate_vol_samp <- blood_storage %>% 
  slice_sample(n = 100) %>% 
  plot_template() +
  geom_histogram(aes(x = PVol), 
                 binwidth = 2,
                 #y=stat(density)),
                 fill = edin_blue_hex) +
  labs(subtitle = "B) Empirical distribution, n = 100",
       x = NULL) +
  xlim(10, 275) +
  theme(axis.text.y = element_text(angle = 90, vjust = 0.5, hjust=0.5))

set.seed(1701)
prostate_vol_boot_1k <- blood_storage %>% 
  slice_sample(n = 100) %>% 
  specify(response = PVol) %>% 
  generate(reps = 1000, 
           type = "bootstrap") %>% 
  calculate(stat = "mean") %>% 
  # Calc CIs
  mutate(lower = quantile(stat, 0.025),
         upper = quantile(stat, 0.975)) %>% 
  plot_template() +
  geom_histogram(aes(x = stat),
                 binwidth = 2,
                 #y=stat(density)),
                 fill = edin_blue_hex) +
  # Plot CIs
  gghighlight(stat > lower & stat < upper,
              unhighlighted_params = list(fill = edin_burgundy_hex)) +
  labs(subtitle = "C) Bootstrap distribution, k = 1,000",
       x = NULL) +
  xlim(10, 275) +
  theme(axis.text.y = element_text(angle = 90, vjust = 0.5, hjust=0.5))

set.seed(1701)
prostate_vol_boot_100k <- blood_storage %>% 
  slice_sample(n = 100) %>% 
  specify(response = PVol) %>% 
  generate(reps = 100000, 
           type = "bootstrap") %>% 
  calculate(stat = "mean") %>% 
  # Calc CIs
  mutate(lower = quantile(stat, 0.025),
         upper = quantile(stat, 0.975)) %>% 
  plot_template() +
  geom_histogram(aes(x = stat),
                 stat = "bin", 
                 binwidth = 2,
                 #y=stat(density)),
                 fill = edin_blue_hex) +
  # Plot CIs
  gghighlight(stat > lower & stat < upper,
              unhighlighted_params = list(fill = edin_burgundy_hex)) +
  labs(subtitle = "D) Bootstrap distribution, k = 100,000",
       x = "Prostate volume/mL") +
  xlim(10,275) +
  theme(axis.text.y = element_text(angle = 90, vjust = 0.5, hjust=0.5))


cowplot::plot_grid(prostate_vol_pop, 
                   prostate_vol_samp,
                   prostate_vol_boot_1k,
                   prostate_vol_boot_100k,
                   ncol = 1,
                   rel_heights = c(1,1,1,1.3)
)

```

\newpage

## Relevance to WME

In current implementations of \acr{WME}, the \acr{WME} estimate of the causal effect ($\hat{\beta}_{WME}$) is calculated as described in Bowden et al[@bowden_consistent_2016], and the 95% \acr{CI} is generated separately using what is described as a bootstrapping approach. However, the implementation of this deviates from the standard bootstrapping methodology described above.

\acr{CI}s for \acr{WME} are generated in the following way (see [Web Appendix 2](https://research-information.bris.ac.uk/ws/portalfiles/portal/101612595/Bowden_et_al_2016_Genetic_Epidemiology.sup_1.pdf) from the original paper[@bowden_consistent_2016] for full code):

1. Summary data (estimates of gene-exposure coefficient $\hat{\gamma}$, gene-outcome coefficient $\hat{\Gamma}$, and their respective standard errors) are obtained for a sample $x$ of $n$ genetic instruments, $G_1, G_2...G_j...G_n$.
2. For each instrument $G_j$ in $x$, a normal distribution is created centered on the input gene-exposure coefficient estimate $\hat{\gamma_j}$, with the \acr{SD} of this distribution set equal to the \acr{SE} of the estimate, $SE({\hat{\gamma_j}})$.
3. Each of these normal distributions, $\mathcal{N}(\space \hat{\gamma_j}, \space SE({\hat{\gamma_j}})\space)$, is treated as a bootstrap population for estimating the gene-exposure coefficient and standard error for its respective instrument. Each instrument is re-sampled a default of $k = 1000$ times from its bootstrap population, forming a bootstrap distribution of $k$ estimates of the gene-exposure coefficient for each instrument, $\hat{\gamma}_j^{*1}, \hat{\gamma}_j^{*2}...\hat{\gamma}_j^{*k}$
4. Steps $2.$ and $3.$ are repeated using gene-outcome coefficients and their \acr{SE}s
5. For each instrument, a Wald estimate of causal effect, $\hat{\beta_j} = \frac{\hat{\Gamma}_j}{\hat{\gamma}_j}$, is obtained from each of the $k$ pairs of gene-exposure and gene-outcome coefficients, $\hat{\beta_j}^{*1}, \hat{\beta_j}^{*2}...\hat{\beta_j}^{*k}$
6. A weighted median causal estimate is calculated from each of the $k$ sets of Wald estimates, $\hat{\beta}_{WME}^{*1}, \hat{\beta}_{WME}^{*2}...\hat{\beta}_{WME}^{*k}$, or $(\hat{\beta}_{WME}^{*i})_{i=1}^k$
7. The standard deviation of the $k$ bootstrapped values of $(\hat{\beta}_{WME}^{*i})_{i=1}^k$ is taken as the bootstrapped standard error, $SE^*$, of the empiric/observed \acr{WME} causal estimate, $\hat{\beta}_{WME}$. The 95% \acr{CI} is then calculated as $\hat{\beta}_{WME} \pm 1.96  \times SE^*$

This approach differs from typical bootstrapping methodology in several regards. Of particular note, the instruments themselves are not re-sampled; rather, gene-exposure and gene-outcome coefficients are re-sampled from normal distributions constructed for the given set of instruments. This approach may adequately account for some random error in the estimation of these coefficients, but it does not account for the presence, distribution or magnitude of pleiotropic effects across the instruments. A re-sampling approach could account for pleiotropy-related uncertainty, but this would require re-sampling of the instruments, which is difficult to implement in practice. 

Given that this method of \acr{CI} generation does not account for an important source of uncertainty, it would be expected to be over-confident and produce \acr{CI}s which are too narrow. Narrow \acr{CI}s are less likely to include the null value, and therefore this may lead to higher rates of causality being reported when using this method, even when no true causal effect exists. As such, incorrect \acr{CI} generation may therefore contribute to a higher Type 1 error rate when using \acr{WME} than might otherwise be expected. 

\newpage

# Appendix: Simulation Code {#appendix-sim}


## Generating Data and Models {#appendix-sim-gen}

The data generating model used was from Appendix 3 of Bowden et al [@bowden_consistent_2016]; the relevant section describing their model is reproduced below:

>_"..._

>\begin{equation} 
U_i = \sum^J_{j=1} \phi_jG_{ij} + \epsilon_i^U
\end{equation}


>\begin{equation} 
X_i = \sum^J_{j=1} \gamma_jG_{ij} + U_i + \epsilon_i^X
\end{equation}

>\begin{equation} 
Y_i = \sum^J_{j=1} \alpha_jG_{ij} + \beta X_i + U_i + \epsilon_i^Y
\end{equation}

>_for participants indexed by $i = 1, . . . , N$, and genetic instruments indexed by $j = 1, . . . , J$._

>_The error terms $\epsilon_i^U , \epsilon_i^X$ and $\epsilon_i^Y$ were each drawn independently from standard normal distributions. The genetic effects on the exposure γj are drawn from a uniform distribution between 0.03 and 0.1. Pleiotropic effects $\alpha_j$ and $\phi_j$ were set to zero if the genetic instrument was a valid instrumental variable. Otherwise (with probability 0.1, 0.2, or 0.3):_

>_1. In Scenario 1 (balanced pleiotropy, InSIDE satisfied), the $\alpha_j$ parameter was drawn from a uniform distribution between −0.2 and 0.2._

>_2. In Scenario 2 (directional pleiotropy, InSIDE satisfied), the $\alpha_j$ parameter was drawn from a uniform distribution between 0 and 0.2._ 

>_3. In Scenario 3 (directional pleiotropy, InSIDE not satisfied), the $\phi_j$ parameter was drawn from a uniform distribution between −0.2 and 0.2._


>_The causal effect of the exposure on the outcome was either $\beta X = 0$ (null causal effect) or $\beta X = 0.1$ (positive causal effect). A total of 10 000 simulated datasets were generated for sample sizes of N = 10 000 and 20 [sic] participants. Only the summary data, that is genetic associations with the exposure and with the outcome and their standard errors as estimated by univariate regression on the genetic instruments in turn, were used by the analysis methods. In the two-sample setting, data were generated on 2N participants, and genetic associations with the exposure were estimated in the first N participants, and genetic associations with the outcome in the second N participants."_ [@bowden_consistent_2016]

To reproduce this model, code was written in R to generate the relevant participant level data. First, a function (`get_simulated_MR_data`) was written which included parameters specified by Bowden et al, plus a toggle for random error terms to allow testing of data simulation (i.e. `rand_error = FALSE` sets random error/noise terms equal to zero):



```{r wme-model-fn, echo=TRUE}

# Define function to create data generating model
# Arguments/default values based on Bowden et al
get_simulated_MR_data <- function(n_participants = as.integer(), 
                                  n_instruments = as.integer(),
                                  n_datasets = as.integer(),
                                  prop_invalid = 0.1,
                                  causal_effect = TRUE,
                                  balanced_pleio = TRUE,
                                  InSIDE_satisfied = TRUE,
                                  rand_error = TRUE,      # remove random errors, for testing
                                  two_sample = TRUE,      # 1- or 2-sample MR toggle, for testing
                                  beta_val = 0.1,         # size of causal effect
                                  allele_freq_min = 0.4,  # frequency of effect allele 0.01/0.99
                                  allele_freq_max = 0.6,  #?0.4/0.6
                                  gamma_min = 0.03,       # size of genetic effects on exposure
                                  gamma_max = 0.1,
                                  alpha_min = -0.2,       # size of pleiotropic effects on outcome
                                  alpha_max = 0.2,
                                  phi_min = -0.2,         # size of additional pleiotropic effects
                                  phi_max = 0.2,          # when InSIDE not satisfied
                                  seed = 14101583){       # Set seed for reproducibility
  
  # Set seed to ensure comparability across scenarios
  set.seed(seed)
  
  # Initialise blank lists to receive datasets for
  # each of:
  #     U (vector: unmeasured confounding exposures per participant), 
  #     X (vector: exposure:outcome associations estimated per participant) 
  #     Y (vector: gene:outcome association estimated per participant), 
  #     G (Matrices: Genotype data)
  #
  #     gamma (vector: pleiotropic effects of each instrument on exposure)
  #     alpha (vector: pleiotropic effects of each instrument on outcome)
  #     phi (vector: additional pleiotropic effects of each instrument when InSIDE 
  #     assumption not satisfied)
  U_list <- list()
  X_list <- list()
  Y_list <- list()
  G_X_list <- list()
  G_Y_list <- list()
  
  gamma_list <- list()
  alpha_list <- list()
  phi_list <- list()
  
  
  n_participants_list <- list()
  n_instruments_list <- list()
  prop_invalid_list <- list()
  beta_val_list <- list()
  
  
  
  # --- Assign features common to all datasets --- #
  
  # size of causal effect
  beta <- if_else(causal_effect == TRUE, 
                  beta_val,
                  0)
  
  # create vector of participant indices for 1st n participants
  # i.e. participants used for estimating gene:exposure coefficient
  sample_1_ref <- 1:n_participants        
  
  
  # Default is to estimate gene:outcome coefficient from different sample
  # to gene:exposure coefficient (i.e. simulating 2-sample MR)
  # two_sample == FALSE toggles to single sample for testing simulation
  ifelse(two_sample == FALSE,
         sample_2_ref <- sample_1_ref, # 1 sample MR
         sample_2_ref <- (n_participants+1):(2*n_participants)) # 2 sample MR
  
  # --- Set characteristics for each genetic instrument --- # 
  
  # Set genetic effects of each instrument on the exposure,
  # drawn from uniform distribution, min/max as per Bowden 
  # et al
  gamma_vect <- runif(n = n_instruments,
                      min = gamma_min,
                      max = gamma_max)
  
  
  
  # Set which instruments invalid, 0 = valid, 1 = invalid
  invalid_instrument_vect <- rbinom(n = n_instruments,
                                    size = 1, 
                                    prob = prop_invalid)
  
  
  # Probability of effect allele set per dataset  
  # for each instrument, default value set at  
  # random between 0.4-0.6 (i.e. both effect +
  # reference are common alleles)
  allele_freq_vect <- runif(n = n_instruments,
                            min = allele_freq_min,
                            max = allele_freq_max)
  
  # Set pleiotropic effects on outcome, Scenarios and 
  # min/max from Bowden et al
  alpha_vect <- double() # Pleiotropic effects of instruments on outcome
  phi_vect <- double() # Pleiotropic effects of confounders on outcome
  
  
  for(j in 1:n_instruments){
    ifelse(invalid_instrument_vect[j] == 0, # alpha = 0 if valid
           alpha_vect[j] <- 0,
           ifelse(balanced_pleio == TRUE,
                  alpha_vect[j] <- runif(n = 1, # balanced
                                         min = alpha_min,
                                         max = alpha_max),
                  alpha_vect[j] <- runif(n = 1, # directional
                                         min = 0,
                                         max = alpha_max)
           )
    )
    
    
    # Assign default phi = 0 unless directional pleiotropy & 
    # InSIDE assumption not satisfied & genetic instrument invalid
    if(balanced_pleio == FALSE & InSIDE_satisfied == FALSE){
      ifelse(invalid_instrument_vect[j] == 0,
             phi_vect[j] <- 0,
             phi_vect[j] <- runif(n = 1,
                                  min = phi_min,
                                  max = phi_max)
      )
      
    }
    else{
      phi_vect[j] <- 0
    }
  }
  
  # Re-set seed to ensure consistency across datasets
  # N.B. above two if/ifelse statements cause de-sync 
  # of number of randomised functions between valid/invalid
  set.seed(seed)
  
  # --- Create separate datasets --- #
  
  # Create N datasets by simulating genotype matrices with
  # 1 row per participant, 1 column per genetic instrument
  # Use these to estimate U, X + Y
  
  for(n in 1:n_datasets){
    
    # --- Create matrix of genotypes --- #
    
    # Assign genotypes by sampling from binomial distribution
    # twice (as two alleles) per participant with probability
    # equal to frequency of effect allele
    # Create twice as many genotypes as participants in sample
    # to simulate 2 sample MR, i.e. first half used to estimate
    # Gene:Exposure, second half used to estimate Gene:Outcome
    
    # Matrix where columns are instruments, rows are participants
    # Values 0, 1 or 2
    # 0 = reference, i.e. zero effect alleles, 
    # 1 = 1 effect allele, 2 = 2 effect alleles 
    
    G_mat <- matrix(rbinom(n = 2 * n_participants * n_instruments,
                           size = 2,
                           prob = rep(allele_freq_vect, 2 * n_participants)),
                    nrow = 2 * n_participants,
                    ncol = n_instruments,
                    byrow = TRUE)
    
    
    # Create error terms for U, X + Y per participant,
    # each drawn from standard normal distribution
    # unless random error turned off (for testing)
    
    ifelse(rand_error == TRUE,
           U_epsilon_vect <- rnorm(n = 2 * n_participants),
           U_epsilon_vect <- rep(0, 2 * n_participants))
    
    ifelse(rand_error == TRUE,
           X_epsilon_vect <- rnorm(n = n_participants),
           X_epsilon_vect <- rep(0, n_participants))
    
    ifelse(rand_error == TRUE,
           Y_epsilon_vect <- rnorm(n = n_participants),
           Y_epsilon_vect <- rep(0, n_participants))
    
    
    # --- Combine Gene matrix/parameters to recreate model --- #
    
    # Create vectors of estimates for U, X and Y per individual,
    # i.e. Ui, Xi and Yi. Uses matrix inner product operator " %*%" 
    # https://stackoverflow.com/questions/22060515/the-r-operator 
    # http://matrixmultiplication.xyz/
    
    #     U (vector: unmeasured confounding exposures per participant), 
    #     X (vector: exposure:outcome associations estimated per participant) 
    #     Y (vector: gene:outcome association estimated per participant) 
    
    Ui_vect <-  G_mat %*% phi_vect + U_epsilon_vect
    
    Xi_vect <-  G_mat[sample_1_ref, ] %*% gamma_vect + 
      Ui_vect[sample_1_ref, ] + 
      X_epsilon_vect
    
    Yi_vect <-  G_mat[sample_2_ref, ] %*% alpha_vect + 
      beta * Xi_vect + 
      Ui_vect[sample_2_ref, ] + 
      Y_epsilon_vect
    
    
    # Add vectors of estimates from this dataset to lists of 
    # estimates from all datasets
    U_list[[n]] <- Ui_vect
    
    X_list[[n]] <- Xi_vect
    
    Y_list[[n]] <- Yi_vect
    
    G_X_list[[n]] <- G_mat[sample_1_ref, ]
    
    G_Y_list[[n]] <- G_mat[sample_2_ref, ]
    
    
    # Include actual parameter values generated for simulation 
    alpha_list[[n]] <- alpha_vect
    
    gamma_list[[n]] <- gamma_vect
    
    phi_list[[n]] <- phi_vect
    
    # Include inputs for reference/testing 
    n_participants_list[[n]] <- n_participants
    n_instruments_list[[n]] <- n_instruments
    prop_invalid_list[[n]] <- prop_invalid
    beta_val_list[[n]] <- beta_val
    
    
  }
  
  
  
  # --- Combine all outputs to return --- #
  
  combined_list <- list(U = U_list,         # Estimates 
                        X = X_list, 
                        Y = Y_list,
                        
                        G_X = G_X_list,     # Genotypes of 1st sample
                        G_Y = G_Y_list,     # Genotypes of 2nd sample
                        
                        alpha = alpha_list, # Actual values for validating simulation
                        gamma = gamma_list,
                        phi = phi_list,
                        
                        n_participants = n_participants_list, # Inputs
                        n_instruments = n_instruments_list,
                        prop_invalid = prop_invalid_list,
                        beta_val = beta_val_list
  )
  
  return(combined_list)
}

```

This initial simulation function generated data in the following format:

```{r test-data-sim, echo = TRUE, include = TRUE}

# Check data produced in expected format
#set.seed(1701)
test_data_sim <- get_simulated_MR_data(n_participants = 1000,
                                       n_instruments = 25,
                                       n_datasets = 2,
                                       prop_invalid = 0.3,
                                       rand_error = FALSE,
                                       causal_effect = TRUE,
                                       balanced_pleio = TRUE,
                                       InSIDE_satisfied = TRUE)

str(test_data_sim)

```


A function (`get_models`) was then written to create linear models from each dataset generated as per Bowden et al:


```{r get-models-fn, echo=TRUE}


# Create plotting tibble with Mean/SD X + Y grouped by
# Dataset + instrument
get_models <- function(sim){
  
  output_list <- list()
  
  # Create linear models per dataset to get coefficients
  # for gene:exposure association (coeff_G_X) and gene:outcome
  # association (coeff_G_Y)
  for(dataset in 1:length(sim$X)){
    
    X <- sim$X[[dataset]]
    Y <- sim$Y[[dataset]]
    Instruments_X <- sim$G_X[[dataset]]
    Instruments_Y <- sim$G_Y[[dataset]]
    
    alpha <- sim$alpha[[dataset]]
    gamma <- sim$gamma[[dataset]]
    phi <- sim$phi[[dataset]]
    beta <- sim$beta_val[[dataset]]
    prop_invalid <- sim$prop_invalid[[dataset]]
    n_instruments <- sim$n_instruments[[dataset]]
    n_participants<- sim$n_participants[[dataset]]
    
    
    # Model for gene:exposure
    X_lm <- lm(X ~ 0 + Instruments_X)
    coeff_G_X_vect <- coef(summary(X_lm))[1:(ncol(Instruments_X)), 1]
    SE_coeff_G_X_vect <- coef(summary(X_lm))[1:(ncol(Instruments_X)), 2]
    
    R2_stat <- summary(lm(X ~ Instruments_X))$r.squared
    F_stat <- summary(lm(X ~ Instruments_X))$fstatistic[[1]]
    
    
    # Model for gene:outcome
    Y_lm <- lm(Y ~ 0 + Instruments_Y)
    coeff_G_Y_vect <- coef(summary(Y_lm))[1:(ncol(Instruments_Y)), 1] 
    SE_coeff_G_Y_vect <- coef(summary(Y_lm))[1:(ncol(Instruments_Y)), 2]
    
    output_list[[dataset]] <- as_tibble(list(dataset = dataset,
                                             Instrument = c(1:ncol(Instruments_X)),
                                             coeff_G_X = coeff_G_X_vect,
                                             coeff_G_X_SE = SE_coeff_G_X_vect,
                                             gamma = gamma,
                                             F_stat = F_stat,
                                             R2_stat = R2_stat,
                                             coeff_G_Y = coeff_G_Y_vect,
                                             coeff_G_Y_SE = SE_coeff_G_Y_vect,
                                             alpha = alpha,
                                             phi = phi,
                                             beta = beta,
                                             prop_invalid = prop_invalid,
                                             n_instruments = n_instruments,
                                             n_participants = n_participants),
                                        .name_repair = "unique")
  }
  
  return(output_list)
  
}  


```


These models generated estimates of the coefficient of gene-exposure association (`coeff_G_X`), coefficient of gene-outcome association (`coeff_G_Y`), and the relevant standard errors of these estimates. The values of parameters inputted were also returned to aid in further testing of data/model generation, i.e. actual gene-exposure associations (`gamma`), pleiotropic effects of invalid instruments (`alpha`), additional pleiotropic effects when \acr{InSIDE} assumption not satified (`phi`), causal effect of exposure on outcome (`beta`) and the proportion of invalid genetic instruments with pleiotropic effects on the outcome (`prop_invalid`).

```{r test-get-model, echo = TRUE, include = TRUE}

test_extract_model <- get_models(test_data_sim)

summary(test_extract_model[[1]])

```


\newpage
## Testing Generation of Data and Models {#appendix-sim-test}

A series of test plots were used to verify that data were simulated as intended under the various conditions specified by input parameters. Test plots were not created for the parameters `n_participants`, `n_instruments` or `n_datasets`, as the functioning of these parameters could be readily inferred from the structure of the  datasets outputted, as above.

### Proportion of Invalid Instruments
\leavevmode\newline The `prop_invalid` parameter specifies the proportion of invalid genetic instruments simulated, i.e. the proportion of genetic instruments affecting the outcome via direct/pleiotropic effects, and thus not solely via the exposure of interest. If simulated correctly, increasing the value of `prop_invalid` should increase the number of instruments with pleiotropic effects, i.e. instruments with `alpha` $\ne$ 0. With random error terms set to 0 and no causal effect present (i.e. `rand_error = FALSE` and `causal_effect = FALSE`), the estimated gene-outcome coefficient estimated using any given instrument will equal the pleiotropic effects of that instrument (i.e. `coeff_G_Y = alpha`), and therefore will only be non-zero for invalid instruments with non-zero pleiotropic effects on the outcome . Plotting `coeff_G_Y` against `alpha` for simulated data with no causal effect or random error should therefore yield a graph where

- For valid instruments: gene-outcome coefficient = alpha = 0
- For invalid instruments:  gene-outcome coefficient = alpha $\ne$  0, with values spread uniformly between `alpha_min` and `alpha_max`


```{r test-plot-prop-invalid, echo=FALSE, include = TRUE}

# Check altering proportion of invalid instruments alters 
# proportion of instruments displaying pleiotropic effects
# N.B. cluster around alpha = 0 represents valid instruments with
# no pleiotropic effects

# 10% of instruments invalid
#set.seed(1701)
sim_test_data_inval_0.1 <- get_simulated_MR_data(n_participants = 1000,
                                                 n_instruments = 25,
                                                 n_datasets = 1,
                                                 prop_invalid = 0.1, 
                                                 rand_error = FALSE,
                                                 causal_effect = FALSE,
                                                 alpha_min = -0.2,
                                                 alpha_max = 0.2)

# 30% of instruments invalid
#set.seed(1701)
sim_test_data_inval_0.3 <- get_simulated_MR_data(n_participants = 1000,
                                                 n_instruments = 25,
                                                 n_datasets = 1,
                                                 prop_invalid = 0.3, 
                                                 rand_error = FALSE,
                                                 causal_effect = FALSE,
                                                 alpha_max = 0.2)

# 50% of instruments invalid
#set.seed(1701)
sim_test_data_inval_0.5 <- get_simulated_MR_data(n_participants = 1000,
                                                 n_instruments = 25,
                                                 n_datasets = 1,
                                                 prop_invalid = 0.5,
                                                 rand_error = FALSE,
                                                 causal_effect = FALSE,
                                                 alpha_min = -0.2,
                                                 alpha_max = 0.2)


test_plot_tib_inval_0.1 <- get_models(sim_test_data_inval_0.1)[[1]]
test_plot_tib_inval_0.3 <- get_models(sim_test_data_inval_0.3)[[1]]
test_plot_tib_inval_0.5 <- get_models(sim_test_data_inval_0.5)[[1]]

test_plot_inval_0.1 <- test_plot_tib_inval_0.1 %>% 
  select(alpha, coeff_G_Y) %>% 
  plot_template() +
  geom_point(colour = edin_bright_red_hex, alpha = 0.3) +
  aes(x = alpha, y = coeff_G_Y ) +
  scale_y_continuous(limits = c(-0.2, 0.2)) +
  scale_x_continuous(limits = c(-0.2, 0.2)) +
  labs(y = "Observed Gene-Outcome Coefficient",
       title = "10% of 25 \nInstruments Invalid",
       caption = ""
  ) 

test_plot_inval_0.3 <- test_plot_tib_inval_0.3 %>% 
  select(alpha, coeff_G_Y) %>% 
  plot_template() +
  geom_point(colour = edin_bright_red_hex, alpha = 0.3) +
  aes(x = alpha, y = coeff_G_Y ) +
  scale_y_continuous(limits = c(-0.2, 0.2)) +
  scale_x_continuous(limits = c(-0.2, 0.2)) +
  labs(y = "Observed Gene-Outcome Coefficient",
       title = "30% of 25 \nInstruments Invalid",
       caption = ""
  ) +
  theme(axis.title.y = element_blank())

test_plot_inval_0.5 <- test_plot_tib_inval_0.5 %>% 
  select(alpha, coeff_G_Y) %>% 
  plot_template() +
  geom_point(colour = edin_bright_red_hex, alpha = 0.3) +
  aes(x = alpha, y = coeff_G_Y ) +
  scale_y_continuous(limits = c(-0.2, 0.2)) +
  scale_x_continuous(limits = c(-0.2, 0.2)) +
  labs(y = "Observed Gene-Outcome Coefficient",
       title = "50% of 25 \nInstruments Invalid",
       caption = "Pleiotropic effects range: -0.2 to 0.2") +
  theme(axis.title.y = element_blank())

plot_grid(test_plot_inval_0.1,
          test_plot_inval_0.3,
          test_plot_inval_0.5,
          ncol = 3,
          rel_widths = c(1.1, 1, 1))


```

\newpage
Similarly, with random error terms set to 0 (`rand_error = FALSE`) and no causal effect present (`causal_effect = FALSE`), gene-exposure coefficients estimated for each instrument should exactly match the actual values simulated, i.e. `coeff_G_X = gamma` for all instruments:

```{r test-plot-gamma-1, echo=FALSE, include = TRUE}

# Check observed gene-exposure coefficients for each instrument
# (coeff_G_X) approximate true values (gamma) when a causal effect 
# is present & a large number of participants are included 
#set.seed(1701)
sim_test_data_gamma_1 <- get_simulated_MR_data(n_participants = 100,
                                               n_instruments = 25,
                                               n_datasets = 1,
                                               prop_invalid = 0.1,
                                               causal_effect = FALSE,
                                               rand_error = FALSE,
                                               balanced_pleio = TRUE,
                                               InSIDE_satisfied = TRUE)


test_plot_tib_gamma_1 <- get_models(sim_test_data_gamma_1)[[1]] 

test_plot_tib_gamma_1 %>% 
  select(gamma, coeff_G_X) %>% 
  plot_template() +
  geom_point(colour = edin_bright_red_hex, alpha = 0.3) +
  aes(x = gamma, y = coeff_G_X ) +
  labs(y = "Observed Gene-Exposure Coefficient",
       title = "Actual and Estimated Gene-Exposure Coefficients Match")

```

\newpage
### Gene-Exposure Coefficient Versus Gene-Outcome Coefficient Plots
\leavevmode\newline For the next phase of testing, a function (`plot_GY_GX`) was written to plot the coefficients for gene-exposure versus gene-outcome as estimated using the previously created linear models:

```{r plot-GY-GX-fn, echo=TRUE, include = TRUE}

plot_GY_GX <- function(model_tib, 
                       plot_title = as.character(NA),
                       x_min = 0,                     # set x-axis limits
                       x_max = 0.1,
                       y_min = -0.05,                 # set x-axis limits
                       y_max = 0.06,
                       beta_x = 0.075,                # set beta-hat position
                       beta_y = 0.05,
                       hat_offset = 0.003
)
{
  
  model_tib %>% 
    mutate(Gradient = round(coefficients(lm(coeff_G_Y ~ 0 + coeff_G_X)[1], 5), 
                            digits = 2)) %>%
    plot_template() + # pre-formatted plot template - call to ggplot with UoE colours
    aes(x = coeff_G_X, y = coeff_G_Y) +
    geom_point(colour = edin_bright_red_hex, alpha = 0.3) +
    geom_abline(aes(intercept = 0, 
                    slope = Gradient),
                size = 1,
                colour = edin_uni_blue_hex) +
    geom_text(aes(label = paste0("\U03B2 = ", as.character(Gradient))), #beta
              x = beta_x, # labels with gradient (causal effect estimate)
              y = beta_y,
              colour = edin_uni_blue_hex, 
              hjust = 0, 
              data = . %>% slice_head()# prevent over-printing
    ) +
    #label = expression("True" ~ hat(beta)~ "= 0.25"),
    annotate("text",
             x = beta_x,      # add hat to beta
             y = beta_y + hat_offset,
             label = paste("\U02C6"),
             colour = edin_uni_blue_hex, 
             hjust = -0.4,
             vjust = 0.9
    ) +
    labs(title = plot_title,
         x = "Gene-Exposure Coefficient",
         y = "Gene-Outcome Coefficient") +
    xlim(x_min, x_max) +
    ylim(y_min, y_max)
  
}


```

\newpage
With random error terms set to 0 (`rand_error = FALSE`) and no causal effect present, a graph of gene-exposure coefficients versus gene-outcome coefficients should be a straight line through the origin with gradient = 0; causal effect of $\beta$ = 0.1  present (`beta_val = 0.1`, `causal_effect = TRUE`), the slope of a graph of gene-exposure coefficients versus gene-outcome coefficients from the same sample should be a straight line through the origin with gradient = 0.1:

```{r test-plot-causal, echo=FALSE, include = TRUE}

source(here::here("Script", "edin_fig_style.R"))
source(here::here("Script", "edin_uni_colours.R"))

# No causal effect present
#set.seed(1701)
sim_test_data_causal_0 <- get_simulated_MR_data(n_participants = 10000,
                                                n_instruments = 100,
                                                n_datasets = 1,
                                                prop_invalid = 0,
                                                causal_effect = FALSE,
                                                rand_error = FALSE)

test_plot_tib_causal_0 <- get_models(sim_test_data_causal_0)[[1]]

test_plot_causal_0 <- plot_GY_GX(test_plot_tib_causal_0, 
                                 plot_title = "No Causal Effect")

# Causal effect present
#set.seed(1701)
sim_test_data_causal_1 <- get_simulated_MR_data(n_participants = 10000,
                                                n_instruments = 100,
                                                n_datasets = 1,
                                                prop_invalid = 0, 
                                                beta_val = 0.1,
                                                causal_effect = TRUE,
                                                rand_error = FALSE,
                                                two_sample = FALSE)

test_plot_tib_causal_1 <- get_models(sim_test_data_causal_1)[[1]]

test_plot_causal_1 <- plot_GY_GX(test_plot_tib_causal_1, 
                                 plot_title = "Causal Effect Present")+
  theme(axis.title.y = element_blank())

plot_grid(test_plot_causal_0,
          test_plot_causal_1,
          ncol = 2,
          rel_widths = c(1.05, 1))



```


\newpage
### Random Errors
\leavevmode\newline Re-plotting the same graphs with non-zero random error terms (`rand_error = TRUE`) should produce similar graphs with Gaussian spread around lines passing through the origin with gradients of 0 and 0.1 for no causal effect and causal effect, respectively:

```{r test-plot-causal-errors, echo=FALSE, include = TRUE}


# Causal effect not present
#set.seed(1701)
sim_test_data_causal_0_errors <- get_simulated_MR_data(n_participants = 10000,
                                                       n_instruments = 25,
                                                       n_datasets = 1,
                                                       prop_invalid = 0,
                                                       causal_effect = FALSE,
                                                       rand_error = TRUE,
                                                       two_sample = FALSE)

test_plot_tib_causal_0_errors <- get_models(sim_test_data_causal_0_errors)[[1]]

test_plot_causal_0_errors <- plot_GY_GX(test_plot_tib_causal_0_errors, 
                                        plot_title = "No Causal Effect")

# Causal effect present
#set.seed(1701)
sim_test_data_causal_1_errors <- get_simulated_MR_data(n_participants = 10000,
                                                       n_instruments = 25,
                                                       n_datasets = 1,
                                                       prop_invalid = 0,
                                                       causal_effect = TRUE,
                                                       rand_error = TRUE,
                                                       two_sample = FALSE)

test_plot_tib_causal_1_errors <- get_models(sim_test_data_causal_1_errors)[[1]]

test_plot_causal_1_errors <-  plot_GY_GX(test_plot_tib_causal_1_errors, 
                                         plot_title = "Causal Effect Present") +
  theme(axis.title.y = element_blank())

plot_grid(test_plot_causal_0_errors,
          test_plot_causal_1_errors,
          ncol = 2,
          rel_widths = c(1.05, 1))
```

\newpage
### One versus Two Sample MR
\leavevmode\newline Where gene-exposure coefficients and gene-outcome coefficients are estimated from two separate samples rather than one (i.e. `two_sample = TRUE`, simulating 2 sample MR), even with random error terms set to zero, error will be introduced into causal effect estimation through random sampling of different combinations of effect alleles. However, where a causal effect is not present, the effect estimated will consistently be zero regardless of the combinations of alleles sampled, so random error should not be introduced:

```{r test-plot-causal-2SMR, echo=FALSE, cache=FALSE, include = TRUE}

source(here::here("Script", "edin_fig_style.R"))
source(here::here("Script", "edin_uni_colours.R"))

# Causal effect not present
#set.seed(1701)
sim_test_data_causal_0_2SMR <- get_simulated_MR_data(n_participants = 1000,
                                                     n_instruments = 25,
                                                     n_datasets = 1,
                                                     prop_invalid = 0,
                                                     causal_effect = FALSE,
                                                     rand_error = FALSE,
                                                     two_sample = TRUE)

test_plot_tib_causal_0_2SMR <- get_models(sim_test_data_causal_0_2SMR)[[1]]

test_plot_causal_0_2SMR <- plot_GY_GX(test_plot_tib_causal_0_2SMR, 
                                      plot_title = "No Causal Effect")

# Causal effect present
#set.seed(1701)
sim_test_data_causal_1_2SMR <- get_simulated_MR_data(n_participants = 1000,
                                                     n_instruments = 25,
                                                     n_datasets = 1,
                                                     prop_invalid = 0,
                                                     causal_effect = TRUE,
                                                     rand_error = FALSE,
                                                     two_sample = TRUE)

test_plot_tib_causal_1_2SMR <- get_models(sim_test_data_causal_1_2SMR)[[1]]

test_plot_causal_1_2SMR <- plot_GY_GX(test_plot_tib_causal_1_2SMR, 
                                      plot_title = "Causal Effect Present") +
  theme(axis.title.y = element_blank())

plot_grid(test_plot_causal_0_2SMR,
          test_plot_causal_1_2SMR,
          ncol = 2,
          rel_widths = c(1.05, 1))


```

\newpage
### Invalid Instruments 
\leavevmode\newline Where invalid instruments are present (i.e. `prop_invalid` $\ne$ `0`) and random error terms are set to 0, graphs of gene-exposure coefficients versus gene-outcome coefficients should be straight lines through the origin and all points representing valid instruments; the invalid instruments should appear as outliers to this line:

```{r test-plot-causal-inval, echo=FALSE, include = TRUE}

# Causal effect not present
#set.seed(1701)
sim_test_data_causal_0_inval <- get_simulated_MR_data(n_participants = 10000,
                                                      n_instruments = 20,
                                                      n_datasets = 1,
                                                      prop_invalid = 0.3,
                                                      causal_effect = FALSE,
                                                      rand_error = FALSE,
                                                      two_sample = FALSE)

test_plot_tib_causal_0_inval <- get_models(sim_test_data_causal_0_inval)[[1]]

test_plot_causal_0_inval <- plot_GY_GX(test_plot_tib_causal_0_inval, 
                                       plot_title = "No Causal Effect")

# Causal effect present
#set.seed(1701)
sim_test_data_causal_1_inval <- get_simulated_MR_data(n_participants = 10000,
                                                      n_instruments = 20,
                                                      n_datasets = 1,
                                                      prop_invalid = 0.3,
                                                      causal_effect = TRUE,
                                                      rand_error = FALSE,
                                                      two_sample = FALSE)

test_plot_tib_causal_1_inval <- get_models(sim_test_data_causal_1_inval)[[1]]

test_plot_causal_1_inval <- plot_GY_GX(test_plot_tib_causal_1_inval, 
                                       plot_title = "Causal Effect Present") +
  theme(axis.title.y = element_blank())

plot_grid(test_plot_causal_0_inval,
          test_plot_causal_1_inval,
          ncol = 2,
          rel_widths = c(1.05, 1))


```

\newpage
### Balanced Versus Directional Pleiotropy
\leavevmode\newline Replotting the above with unbalanced pleiotropy present (`balanced_pleio = FALSE`), the invalid instruments should all appear as outliers in the positive direction, i.e. steepening the line of best fit and leading to overestimation of the causal effect: 

```{r test-plot-causal-unbal, echo=FALSE, include = TRUE}


# Causal effect not present
#set.seed(1701)
sim_test_data_causal_0_unbal <- get_simulated_MR_data(n_participants = 10000,
                                                      n_instruments = 20,
                                                      n_datasets = 1,
                                                      prop_invalid = 0.2,
                                                      causal_effect = FALSE,
                                                      rand_error = FALSE, 
                                                      balanced_pleio = FALSE,
                                                      two_sample = FALSE)

test_plot_tib_causal_0_unbal <- get_models(sim_test_data_causal_0_unbal)[[1]]

test_plot_causal_0_unbal <- plot_GY_GX(test_plot_tib_causal_0_unbal, 
                                       plot_title = "No Causal Effect")

# Causal effect present
#set.seed(1701)
sim_test_data_causal_1_unbal <- get_simulated_MR_data(n_participants = 10000,
                                                      n_instruments = 20,
                                                      n_datasets = 1,
                                                      prop_invalid = 0.2,
                                                      causal_effect = TRUE,
                                                      rand_error = FALSE,
                                                      balanced_pleio = FALSE,
                                                      two_sample = FALSE)

test_plot_tib_causal_1_unbal <- get_models(sim_test_data_causal_1_unbal)[[1]]

test_plot_causal_1_unbal <- plot_GY_GX(test_plot_tib_causal_1_unbal, 
                                       plot_title = "Causal Effect Present") +
  theme(axis.title.y = element_blank())

plot_grid(test_plot_causal_0_unbal,
          test_plot_causal_1_unbal,
          ncol = 2,
          rel_widths = c(1.05, 1))


```
<!-- https://pmc.ncbi.nlm.nih.gov/articles/PMC4469799/ -->
<!-- https://mr-dictionary.mrcieu.ac.uk/term/inside/ -->

\newpage
### InSIDE Assumption and Phi
\leavevmode\newline The variable phi represents additional pleiotropic effects of each invalid instrument when the \acr{InSIDE} assumption is not satisfied. The \acr{InSIDE} assumption states that the gene-exposure association is not correlated with the pleiotropic path gene-outcome path of any invalid genetic instruments. This assumption can be violated if e.g.:

- several invalid genetic instruments influence the outcome via the same pleiotropic path

- several invalid genetic instruments are related to the same (unmeasured) confounders of the exposure:outcome relationship, aka correlated pleiotropy. 

As such, when the \acr{InSIDE} assumption is violated, even "strong" instruments (i.e. those with a strong gene-exposure relationship) may not allow accurate estimation of the true causal effect, as pleiotropic effects may scale with instrument strength. If pleiotropic effects are directional, \acr{InSIDE} assumption violation may lead to bias.

Bowden et al [@bowden_consistent_2016] modeled phi as the pleiotropic effects of unmeasured genetic confounders of the exposure:outcome relationship.  Phi adds additional error to causal effect estimation in scenarios with directional pleiotropic effects (`0 < alpha < 0.2`) and \acr{InSIDE} assumption violation. As such, switching `InSIDE_satisfied` from `TRUE` to `FALSE` should add scatter to the linear association expected when plotting alpha versus gene-outcome coefficients with random error terms set to zero:


```{r test-plot-phi, echo=FALSE, include = TRUE}

# Check violating InSIDE assumption results in distorted 
# estimation of pleiotropic effects
# N.B. cluster around alpha = 0 represents valid instruments with
# no pleiotropic effects
#set.seed(1701)
sim_test_data_phi_0 <- get_simulated_MR_data(n_participants = 100000,
                                             n_instruments = 100,
                                             n_datasets = 1,
                                             prop_invalid = 0.3,
                                             causal_effect = FALSE,
                                             rand_error = FALSE, 
                                             balanced_pleio = FALSE,
                                             InSIDE_satisfied = TRUE)


#set.seed(1701)
sim_test_data_phi_1 <- get_simulated_MR_data(n_participants = 100000,
                                             n_instruments = 100,
                                             n_datasets = 1,
                                             prop_invalid = 0.3,
                                             causal_effect = FALSE,
                                             rand_error = FALSE, 
                                             balanced_pleio = FALSE,
                                             InSIDE_satisfied = FALSE)



test_plot_tib_phi_0 <- get_models(sim_test_data_phi_0)[[1]]
test_plot_tib_phi_1 <- get_models(sim_test_data_phi_1)[[1]]

test_plot_phi_0 <- test_plot_tib_phi_0 %>%
  plot_template() +
  aes(x = alpha, y = coeff_G_Y) +
  geom_point(colour = edin_bright_red_hex, alpha = 0.3) +
  labs(title = "InSIDE Not Violated",
       y = "Gene-Outcome Coefficient")


test_plot_phi_1 <- test_plot_tib_phi_1 %>%
  plot_template() +
  aes(x = alpha, y = coeff_G_Y) +
  geom_point(colour = edin_bright_red_hex, alpha = 0.3) +
  labs(title = "InSIDE Violated",
       y = "Gene-Outcome Coefficient") +
  theme(axis.title.y = element_blank())


plot_grid(test_plot_phi_0,
          test_plot_phi_1,
          ncol = 2,
          rel_widths = c(1.05, 1))



```

\newpage
Setting `InSIDE_satisfied = TRUE` should mean `phi = 0`; `InSIDE_satisfied=FALSE` should result in `phi` $\propto$ gene-outcome coefficient, with scatter only in the positive direction of gene-outcome coefficients given the simulation only uses the `phi` term in Scenario 3 (which requires directional pleiotropy):


```{r test-plot-phi-2, echo=FALSE, include = TRUE}

# Check violating InSIDE assumption results in distorted 
# estimation of pleiotropic effects
# N.B. cluster around alpha = 0 represents valid instruments with
# no pleiotropic effects
#set.seed(1701)
sim_test_data_phi_0 <- get_simulated_MR_data(n_participants = 100000,
                                             n_instruments = 100,
                                             n_datasets = 1,
                                             prop_invalid = 0.3,
                                             causal_effect = FALSE,
                                             rand_error = FALSE, 
                                             balanced_pleio = FALSE,
                                             InSIDE_satisfied = TRUE)


#set.seed(1701)
sim_test_data_phi_1 <- get_simulated_MR_data(n_participants = 100000,
                                             n_instruments = 100,
                                             n_datasets = 1,
                                             prop_invalid = 0.3,
                                             causal_effect = FALSE,
                                             rand_error = FALSE, 
                                             balanced_pleio = FALSE,
                                             InSIDE_satisfied = FALSE)



test_plot_tib_phi_0 <- get_models(sim_test_data_phi_0)[[1]]
test_plot_tib_phi_1 <- get_models(sim_test_data_phi_1)[[1]]

test_plot_phi_0 <- test_plot_tib_phi_0 %>%
  plot_template() +
  aes(x = phi, y = coeff_G_Y) +
  geom_point(colour = edin_bright_red_hex, alpha = 0.3) +
  labs(title = "InSIDE Not Violated",
       y = "Gene-Outcome Coefficient")


test_plot_phi_1 <- test_plot_tib_phi_1 %>%
  plot_template() +
  aes(x = phi, y = coeff_G_Y) +
  geom_point(colour = edin_bright_red_hex, alpha = 0.3) +
  labs(title = "InSIDE Violated",
       y = "Gene-Outcome Coefficient") +
  theme(axis.title.y = element_blank())


plot_grid(test_plot_phi_0,
          test_plot_phi_1,
          ncol = 2,
          rel_widths = c(1.05, 1))

```

\newpage
## Summary Table {#appendix-sim-summ}

A function (`get_summary_MR_tib_row`) was written to take models generated from each simulated dataset, estimate causal effect using both weighted median and MR-Hevo methodologies, then output a summary formatted as per Tables 2 & 3 in Bowden et al [@bowden_consistent_2016]:



```{r summary-MR-tib-row-fn, echo=TRUE, include = TRUE}

# Load WME functions
library(TwoSampleMR)

# Load RStan - needed for MR-Hevo
library(rstan)


# Run local copy of MR-Hevo functions
# Not using full package due to conflicts with Windows
source(here::here("Script", "Hevo", "functions.mrhevo.R"))

# Standard set-up for RStan
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE, save_dso = TRUE)


# Compile model for MR-Hevo
mr.stanmodel <- stan_model(file= here::here("Script", 
                                            "Hevo", 
                                            "MRHevo_summarystats.stan"),
                           model_name="MRHevo.summarystats", 
                           verbose=FALSE,
                           save_dso = TRUE,
                           auto_write = TRUE)

get_summary_MR_tib_row <- function(model_list){
  
  
  # Create output tibble in same format as Table 2/3 from
  # Bowden et al
  output_tib_row <- tibble(N = as.integer(),
                           Prop_Invalid = as.double(),
                           F_stat = as.double(),
                           R2_stat = as.double(),
                           WME_Av = as.double(),
                           WME_SE = as.double(),
                           WME_Pos_Rate = as.double(),
                           Hevo_Av = as.double(),
                           Hevo_SE = as.double(),
                           Hevo_Pos_Rate = as.double())
  
  n_datasets <- length(model_list)
  
  # Create blank tibble to receive results of Weighted
  # Median Estimator function from MR-Base
  
  results_tib <-  tibble(WME_est = as.double(),
                         WME_se = as.double(),
                         WME_pval = as.double(),
                         WME_nsnp = as.integer(),
                         Hevo_est = as.double(),
                         Hevo_se = as.double(),
                         Hevo_sd = as.double(),
                         Hevo_est_lower_CI = as.double(),
                         Hevo_est_upper_CI = as.double(),
                         Hevo_causal_detected = as.logical()
  )
  
  
  # Run WME and MR-Hevo for each dataset 
  for(dataset in 1:n_datasets){
    
    # Stored as individual vectors for MR-Hevo/RStan - not
    # Tidyverse compatible
    coeff_G_X_vect <- model_list[[dataset]]$coeff_G_X
    coeff_G_Y_vect <- model_list[[dataset]]$coeff_G_Y
    coeff_G_X_SE_vect <- model_list[[dataset]]$coeff_G_X_SE
    coeff_G_Y_SE_vect <- model_list[[dataset]]$coeff_G_Y_SE
    prop_invalid <- min(model_list[[dataset]]$prop_invalid)
    F_stat <- min(model_list[[dataset]]$F_stat)
    R2_stat <- min(model_list[[dataset]]$R2_stat)
    n_instruments <- max(model_list[[dataset]]$Instrument)
    n_participants <- min(model_list[[dataset]]$n_participants)
    
    
    # N.B. MR-Hevo terminology vs WME paper/other code:
    # alpha = effects of instruments on exposure, i.e. coeff_G_X
    # beta = pleiotropic effects of instruments on outcome, i.e. alpha in WME
    # gamma = effects of instruments on outcome, i.e. coeff_G_Y
    # theta = causal effect X on Y, i.e. b
    
    # Results from weighted median estimator method
    WME_results <- mr_weighted_median(b_exp = coeff_G_X_vect,
                                      b_out = coeff_G_Y_vect,
                                      se_exp = coeff_G_X_SE_vect,
                                      se_out = coeff_G_Y_SE_vect,
                                      parameters = list(nboot = 1000))
    
    # Results from MR-Hevo method
    Hevo_results<- run_mrhevo.sstats(alpha_hat = coeff_G_X_vect,
                                     se.alpha_hat = coeff_G_X_SE_vect,
                                     gamma_hat = coeff_G_Y_vect,
                                     se.gamma_hat = coeff_G_Y_SE_vect) %>%
      summary()
    
    
    # Extract WME Results
    results_tib[dataset, ]$WME_est <- WME_results$b
    results_tib[dataset, ]$WME_se <- WME_results$se
    results_tib[dataset, ]$WME_pval <- WME_results$pval
    results_tib[dataset, ]$WME_nsnp <- WME_results$nsnp
    
    # Extract MR-Hevo Results
    results_tib[dataset, ]$Hevo_est <- Hevo_results$summary["theta","mean"]
    # Below used in error - actually Monte Carlo SE
    results_tib[dataset, ]$Hevo_se <- Hevo_results$summary["theta","se_mean"] 
    # Below should have been used as SE - SD of bootstrap distribution
    results_tib[dataset, ]$Hevo_sd <- Hevo_results$summary["theta","sd"] 
    results_tib[dataset, ]$Hevo_est_lower_CI <- Hevo_results$summary["theta","2.5%"]
    results_tib[dataset, ]$Hevo_est_upper_CI <- Hevo_results$summary["theta","97.5%"]
    
  }
  
  # Add causality Boolean to MR-Hevo
  results_tib <- results_tib %>%
    mutate(Hevo_est_causal_detected = (Hevo_est_lower_CI > 0  | Hevo_est_upper_CI < 0))
  
  
  output_tib_row <- results_tib %>% 
    summarise(N = n_participants,
              Prop_Invalid = prop_invalid,
              F_stat = mean(F_stat),
              R2_stat = mean(R2_stat),
              WME_Av = mean(WME_est),
              WME_SE = mean(WME_se),
              WME_Pos_Rate = length(WME_pval[WME_pval < 0.05]) / n_datasets,
              Hevo_Av = mean(Hevo_est),
              Hevo_SE = mean(Hevo_se),
              Hevo_Lower_CI = mean(Hevo_est_lower_CI),
              Hevo_Upper_CI = mean(Hevo_est_upper_CI),
              Hevo_Pos_Rate = sum(Hevo_est_causal_detected) / n_datasets
    ) %>% 
    mutate(across(where::here(is.double), round, 3))
  
  return(output_tib_row)
  
}



```

```{r load-functions-sneaky, echo = FALSE}

# test-summary-MR-tib-row-fn doesn't work without reloading functions here
# does work when all relevant code copy/pasted to test script - ?bugged
# Error code:
# Error in `h()`:
# ! error in evaluating the argument 'object' in selecting a method for function 'summary': could not find function "set.tau0"
# or sometimes:
# ! error in evaluating the argument 'object' in selecting a method for function 'summary': error in evaluating the argument 'object' in selecting a method for function 'sampling': object 'mr.stanmodel' not found

# Load function scripts
source(here::here("Script", "simulation_functions.R"))

# Run local copy of MR-Hevo functions
# Not using full package due to conflicts with Windows
source(here::here("Script", "Hevo", "functions.mrhevo.R"))

```

```{r test-summary-MR-tib-row-fn, echo=TRUE, include = TRUE}

test_tib_summ_MR_data <-  get_simulated_MR_data(n_participants = 10000,
                                                n_instruments = 25,
                                                n_datasets = 2,
                                                prop_invalid = 0.1,
                                                beta_val = 0.1,
                                                causal_effect = TRUE,
                                                rand_error = TRUE,
                                                two_sample = TRUE,
                                                balanced_pleio = TRUE,
                                                InSIDE_satisfied = TRUE)

test_tib_summ_MR_models <- get_models(test_tib_summ_MR_data)

test_tib_summ_MR_row <- get_summary_MR_tib_row(test_tib_summ_MR_models)

test_tib_summ_MR_row %>% 
  kable() %>% 
  kable_styling(latex_options="scale_down")

```

\newpage

# Appendix: Sensitivity Analyses {#appendix-sens}

```{r load-sens-results}

# --- Load results --- #
# 100 snp
## No Causal:
sens_no_causal_20k_100snp_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_20k_100snp_scen1_sim_summ_tib.rds"))
sens_no_causal_20k_100snp_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_20k_100snp_scen1_sim_summ_tib.rds"))

sens_no_causal_20k_100snp_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_20k_100snp_scen2_sim_summ_tib.rds"))
sens_no_causal_20k_100snp_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_20k_100snp_scen2_sim_summ_tib.rds"))

sens_no_causal_20k_100snp_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_20k_100snp_scen3_sim_summ_tib.rds"))
sens_no_causal_20k_100snp_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_20k_100snp_scen3_sim_summ_tib.rds"))


## Causal:
sens_causal_20k_100snp_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_20k_100snp_scen1_sim_summ_tib.rds"))
sens_causal_20k_100snp_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_20k_100snp_scen1_sim_summ_tib.rds"))

sens_causal_20k_100snp_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_20k_100snp_scen2_sim_summ_tib.rds"))
sens_causal_20k_100snp_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_20k_100snp_scen2_sim_summ_tib.rds"))

sens_causal_20k_100snp_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_20k_100snp_scen3_sim_summ_tib.rds"))
sens_causal_20k_100snp_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_20k_100snp_scen3_sim_summ_tib.rds"))


# --- Load results --- #
# 200k participants
## No Causal:
sens_no_causal_200k_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_200k_scen1_sim_summ_tib.rds"))
sens_no_causal_200k_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_200k_scen1_sim_summ_tib.rds"))

sens_no_causal_200k_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_200k_scen2_sim_summ_tib.rds"))
sens_no_causal_200k_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_200k_scen2_sim_summ_tib.rds"))

sens_no_causal_200k_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_200k_scen3_sim_summ_tib.rds"))
sens_no_causal_200k_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_no_causal_200k_scen3_sim_summ_tib.rds"))


## Causal:
sens_causal_200k_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_200k_scen1_sim_summ_tib.rds"))
sens_causal_200k_scen1_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_200k_scen1_sim_summ_tib.rds"))

sens_causal_200k_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_200k_scen2_sim_summ_tib.rds"))
sens_causal_200k_scen2_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_200k_scen2_sim_summ_tib.rds"))

sens_causal_200k_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_200k_scen3_sim_summ_tib.rds"))
sens_causal_200k_scen3_sim_summ_tib <- readRDS(file = here("Data", "Summary_Tables", "sens_causal_200k_scen3_sim_summ_tib.rds"))

```

## Simulation Study (Post-Hoc) {#appendix-sens-post-hoc}

### 100 Genetic Instruments {#sens-tibs-100-snp}
```{r sens-100-snp-sim-sum-tibs}

# --- No Causal --- #
# Scenario 1
sens_100snp_no_causal_scen1_sim_summ_tib <- bind_rows(sens_no_causal_20k_100snp_scen1_sim_summ_tib
) %>%
  mutate(Scenario = "Scenario 1: Balanced pleiotropy, InSIDE assumption satisfied")

# Scenario 2
sens_100snp_no_causal_scen2_sim_summ_tib <- bind_rows(sens_no_causal_20k_100snp_scen2_sim_summ_tib
) %>%
  mutate(Scenario = "Scenario 2: Directional pleiotropy, InSIDE assumption satisfied")

# Scenario 3
sens_100snp_no_causal_scen3_sim_summ_tib <- bind_rows(sens_no_causal_20k_100snp_scen3_sim_summ_tib
) %>%
  mutate(Scenario = "Scenario 3: Directional pleiotropy, InSIDE assumption not satisfied")


# Summary
sens_100snp_no_causal_sim_summ_tib <- bind_rows(sens_100snp_no_causal_scen1_sim_summ_tib,
                                                sens_100snp_no_causal_scen2_sim_summ_tib,
                                                sens_100snp_no_causal_scen3_sim_summ_tib
)%>% 
  mutate(WME_Lower_CI = WME_Av - 1.96 * WME_SE,
         WME_Upper_CI = WME_Av + 1.96 * WME_SE,
         Hevo_SE_Calc = round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3),
         Pos_Rate_Diff = Hevo_Pos_Rate - WME_Pos_Rate,
         Hevo_Better = Pos_Rate_Diff < 0)


# --- Causal --- #
# Scenario 1
sens_100snp_causal_scen1_sim_summ_tib <- bind_rows(sens_causal_20k_100snp_scen1_sim_summ_tib
) %>% 
  mutate(Scenario = "Scenario 1: Balanced pleiotropy, InSIDE assumption satisfied")

# Scenario 2
sens_100snp_causal_scen2_sim_summ_tib <- bind_rows(sens_causal_20k_100snp_scen2_sim_summ_tib
) %>% 
  mutate(Scenario = "Scenario 2: Directional pleiotropy, InSIDE assumption satisfied")

# Scenario 3
sens_100snp_causal_scen3_sim_summ_tib <- bind_rows(sens_causal_20k_100snp_scen3_sim_summ_tib
) %>% 
  mutate(Scenario = "Scenario 3: Directional pleiotropy, InSIDE assumption not satisfied")


# Summary
sens_100snp_causal_sim_summ_tib <- bind_rows(sens_100snp_causal_scen1_sim_summ_tib,
                                             sens_100snp_causal_scen2_sim_summ_tib,
                                             sens_100snp_causal_scen3_sim_summ_tib) %>% 
  mutate(WME_Lower_CI = WME_Av - 1.96 * WME_SE,
         WME_Upper_CI = WME_Av + 1.96 * WME_SE,
         Hevo_SE_Calc = round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3),
         Pos_Rate_Diff = Hevo_Pos_Rate - WME_Pos_Rate,
         Hevo_Better = Pos_Rate_Diff < 0)


```

```{r sens-100-snp-no-causal-sim-summ-display, echo=FALSE, warning=FALSE, include=TRUE, tab.id="sens-100-snp-no-causal-sim-summ-display", tab.cap="Summary of 100 simulated Mendelian randomisation studies per combination of scenario and parameters, all with null causal effect and using 20,000 participants with 100 genetic instruments", results='asis'}
#| ft.arraystretch = 1.3


library(flextable)
library(ftExtra)

# Display
sens_100snp_no_causal_sim_summ_display <- sens_100snp_no_causal_sim_summ_tib %>%
  # Change names for cleaner plotting
  mutate(Invalid = paste0((Prop_Invalid * 100), "%"),
         F = round(F_stat, 1),
         R2 = paste0(R2_stat *100, "%"),
         Weighted_Median_Mean_Estimate = WME_Av,
         Weighted_Median_Mean_SE = paste0("(", WME_SE, ")"),
         Weighted_Median_Lower_CI = round(WME_Av - 1.96 * WME_SE, 2),
         Weighted_Median_Upper_CI = round(WME_Av + 1.96 * WME_SE, 2),
         Weighted_Median_95_CI = paste0(Weighted_Median_Lower_CI, " to ", Weighted_Median_Upper_CI),
         Weighted_Median_Causal_Report_Rate = paste0((WME_Pos_Rate * 100), "%"),
         MR_Hevo_Mean_Estimate = Hevo_Av,
         #MR_Hevo_Mean_SE = paste0("(", round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3), ")"),
         MR_Hevo_Mean_SE = paste0("(", Hevo_SE_Calc, ")"),
         MR_Hevo_Lower_CI = round(Hevo_Lower_CI, 2),
         MR_Hevo_Upper_CI = round(Hevo_Upper_CI, 2),
         MR_Hevo_95_CI = paste0(round(Hevo_Lower_CI, 2), " to ", round(Hevo_Upper_CI, 2)),
         MR_Hevo_Causal_Report_Rate = paste0((Hevo_Pos_Rate * 100), "%")) %>%
  # Drop old names
  select(N,
         Invalid,
         F,
         R2,
         Weighted_Median_Mean_Estimate,
         Weighted_Median_Mean_SE,
         Weighted_Median_95_CI,
         Weighted_Median_Causal_Report_Rate,
         MR_Hevo_Mean_Estimate,
         MR_Hevo_Mean_SE,
         MR_Hevo_95_CI,
         MR_Hevo_Causal_Report_Rate,
         Scenario) %>%
  as_grouped_data(groups = c("Scenario")) %>%
  as_flextable(hide_grouplabel = TRUE, col_keys = c("N",
                                                    "Invalid",
                                                    "F",
                                                    "R2",
                                                    "Weighted_Median_Mean_Estimate",
                                                    "Weighted_Median_Mean_SE",
                                                    "Weighted_Median_95_CI", 
                                                    "Weighted_Median_Causal_Report_Rate",
                                                    "blank_col",
                                                    "MR_Hevo_Mean_Estimate",
                                                    "MR_Hevo_Mean_SE",
                                                    "MR_Hevo_95_CI", 
                                                    "MR_Hevo_Causal_Report_Rate",
                                                    "Scenario")) |>
  # To separate WME/MR-Hevo
  width(j = "blank_col", width = 0.2) |>
  empty_blanks() |>
  span_header() |>
  align(part = "all", align = "center") |>
  align(part = "body", j =c(5, 10),  align = "right") |>
  align(part = "body", j =c(6, 11),  align = "left") |>
  # Italicise N and F
  italic(part = "header", i = 1, j = c(1,3) ) |>
  # Fix name of invalid IVs
  flextable::compose(part = "header", i = 1:4, j = 2, value = as_paragraph("Invalid IVs")) |>
  # Fix name of 95% CIs
  flextable::compose(part = "header", i = 3, j = c(7, 12), value = as_paragraph("Mean")) |>
  flextable::compose(part = "header", i = 4, j = c(7, 12), value = as_paragraph("95% CI")) |>
  # Fix split headers
  flextable::compose(part = "header", i = 3, j = c(5,10), value = as_paragraph("Mean Estimate")) |>
  flextable::compose(part = "header", i = 4, j = c(5:6), value = as_paragraph("(Mean SE)")) |>
  flextable::compose(part = "header", i = 4, j = c(10:11), value = as_paragraph("(Mean SE*)")) |>
  #flextable::compose(part = "header", i = 4, j = c(5:6,10:11), value = as_paragraph("(Mean SE)")) |>
  merge_h(part = "header", i = 4) |>
  # Italicise/superscript R^2
  flextable::compose(part = "header", i = 1, j = 4, value = as_paragraph(as_i("R"), as_sup(as_i(as.character(2))))) |>
  
  hline(part = "header", i = 2, j = c(5:8, 10:13), border = officer::fp_border(color = "black", width = 1)) |>
  #footnote(i = c(1,4), j = c(2, 5), part = "header", value = as_paragraph(c("IV: Instrumental Variable", "SE: Standard Error")))
  # Fix dimensions
  autofit() |>
  #line_spacing(space = 0, part = "header") |>
  line_spacing(space = 1, part = "body") |>
  fit_to_width(max_width = 6.5) |>
  #height_all(height = 40, unit = "mm",part = "all") |>

  #Add footer
  flextable::add_footer_lines("CI: Confidence Interval, InSIDE: Instrument Strength Independent of Direct Effect, IV: Instumental Variable, SE: Standard Error, SE*: Estimated Standard Error. F and R\U00B2 statistics presented are the minimum values across all simulated datasets. \nNull Causal Effect (\U03B2 = 0)") |>
  flextable::fontsize(9, i = c(1:5), j = c(1:13), part = "header") |>
  flextable::fontsize(8, i = c(1:15), j = c(1:13), part = "body") |>
  flextable::fontsize(8, i = 1, j = 1, part = "footer")
# set_caption(caption = "Summary of 1000 Simulated Mendelian Randomisation Studies With Null Causal Effect (\U03B2 = 0)",
#             style = "Table Caption",
#             autonum = run_autonum(seq_id = "tab",
#                                   bkm = "no-causal-sim-summ-tib"))

sens_100snp_no_causal_sim_summ_display


```

\newpage


```{r sens-100-snp-causal-sim-summ-display, echo=FALSE, warning=FALSE, include=TRUE, tab.id="sens-100-snp-causal-sim-summ-display", tab.cap="Summary of 100 simulated Mendelian randomisation studies per combination of scenario and parameters, all with positive causal effect and using 20,000 participants with 100 genetic instruments", results='asis'}
#| ft.arraystretch = 1.3

library(flextable)
library(ftExtra)

# Display
sens_100snp_causal_sim_summ_display <- sens_100snp_causal_sim_summ_tib %>%
  # Change names for cleaner plotting
  mutate(Invalid = paste0((Prop_Invalid * 100), "%"),
         F = round(F_stat, 1),
         R2 = paste0(R2_stat *100, "%"),
         Weighted_Median_Mean_Estimate = WME_Av,
         Weighted_Median_Mean_SE = paste0("(", WME_SE, ")"),
         Weighted_Median_Lower_CI = round(WME_Av - 1.96 * WME_SE, 2),
         Weighted_Median_Upper_CI = round(WME_Av + 1.96 * WME_SE, 2),
         Weighted_Median_95_CI = paste0(Weighted_Median_Lower_CI, " to ", Weighted_Median_Upper_CI),
         Weighted_Median_Causal_Report_Rate = paste0((WME_Pos_Rate * 100), "%"),
         MR_Hevo_Mean_Estimate = Hevo_Av,
         #MR_Hevo_Mean_SE = paste0("(", round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3), ")"),
         MR_Hevo_Mean_SE = paste0("(", Hevo_SE_Calc, ")"),
         MR_Hevo_Lower_CI = round(Hevo_Lower_CI, 2),
         MR_Hevo_Upper_CI = round(Hevo_Upper_CI, 2),
         MR_Hevo_95_CI = paste0(round(Hevo_Lower_CI, 2), " to ", round(Hevo_Upper_CI, 2)),
         MR_Hevo_Causal_Report_Rate = paste0((Hevo_Pos_Rate * 100), "%")) %>%
  # Drop old names
  select(N,
         Invalid,
         F,
         R2,
         Weighted_Median_Mean_Estimate,
         Weighted_Median_Mean_SE,
         Weighted_Median_95_CI,
         Weighted_Median_Causal_Report_Rate,
         MR_Hevo_Mean_Estimate,
         MR_Hevo_Mean_SE,
         MR_Hevo_95_CI,
         MR_Hevo_Causal_Report_Rate,
         Scenario) %>%
  as_grouped_data(groups = c("Scenario")) %>%
  as_flextable(hide_grouplabel = TRUE, col_keys = c("N",
                                                    "Invalid",
                                                    "F",
                                                    "R2",
                                                    "Weighted_Median_Mean_Estimate",
                                                    "Weighted_Median_Mean_SE",
                                                    "Weighted_Median_95_CI", 
                                                    "Weighted_Median_Causal_Report_Rate",
                                                    "blank_col",
                                                    "MR_Hevo_Mean_Estimate",
                                                    "MR_Hevo_Mean_SE",
                                                    "MR_Hevo_95_CI", 
                                                    "MR_Hevo_Causal_Report_Rate",
                                                    "Scenario")) |>
  # To separate WME/MR-Hevo
  width(j = "blank_col", width = 0.2) |>
  empty_blanks() |>
  span_header() |>
  align(part = "all", align = "center") |>
  align(part = "body", j =c(5, 10),  align = "right") |>
  align(part = "body", j =c(6, 11),  align = "left") |>
  # Italicise N and F
  italic(part = "header", i = 1, j = c(1,3) ) |>
  # Fix name of invalid IVs
  flextable::compose(part = "header", i = 1:4, j = 2, value = as_paragraph("Invalid IVs")) |>
  # Fix name of 95% CIs
  flextable::compose(part = "header", i = 3, j = c(7, 12), value = as_paragraph("Mean")) |>
  flextable::compose(part = "header", i = 4, j = c(7, 12), value = as_paragraph("95% CI")) |>
  # Fix split headers
  flextable::compose(part = "header", i = 3, j = c(5,10), value = as_paragraph("Mean Estimate")) |>
  flextable::compose(part = "header", i = 4, j = c(5:6), value = as_paragraph("(Mean SE)")) |>
  flextable::compose(part = "header", i = 4, j = c(10:11), value = as_paragraph("(Mean SE*)")) |>
  #flextable::compose(part = "header", i = 4, j = c(5:6,10:11), value = as_paragraph("(Mean SE)")) |>
  merge_h(part = "header", i = 4) |>
  # Italicise/superscript R^2
  flextable::compose(part = "header", i = 1, j = 4, value = as_paragraph(as_i("R"), as_sup(as_i(as.character(2))))) |>
  
  hline(part = "header", i = 2, j = c(5:8, 10:13), border = officer::fp_border(color = "black", width = 1)) |>
  #footnote(i = c(1,4), j = c(2, 5), part = "header", value = as_paragraph(c("IV: Instrumental Variable", "SE: Standard Error")))
  # Fix dimensions
  autofit() |>
  #line_spacing(space = 0, part = "header") |>
  line_spacing(space = 1, part = "body") |>
  fit_to_width(max_width = 6.5) |>
  #height_all(height = 40, unit = "mm",part = "all") |>

  # Add footer
flextable::add_footer_lines("CI: Confidence Interval, InSIDE: Instrument Strength Independent of Direct Effect, IV: Instumental Variable, SE: Standard Error, SE*: Estimated Standard Error. F and R\U00B2 statistics presented are the minimum values across all simulated datasets. \nPositive Causal Effect (\U03B2 = 0.1)") |>
flextable::fontsize(9, i = c(1:5), j = c(1:13), part = "header") |>
flextable::fontsize(8, i = c(1:15), j = c(1:13), part = "body") |>
flextable::fontsize(8, i = 1, j = 1, part = "footer")
# set_caption(caption = "Summary of 1000 Simulated Mendelian Randomisation Studies With Null Causal Effect (\U03B2 = 0)",
#             style = "Table Caption",
#             autonum = run_autonum(seq_id = "tab",
#                                   bkm = "no-causal-sim-summ-tib"))

sens_100snp_causal_sim_summ_display


```

\newpage

### 200,000 Participants {#sens-tibs-200k}
```{r sens-200k-sim-sum-tibs}

# --- No Causal --- #
# Scenario 1
sens_200k_no_causal_scen1_sim_summ_tib <- bind_rows(sens_no_causal_200k_scen1_sim_summ_tib
) %>%
  mutate(Scenario = "Scenario 1: Balanced pleiotropy, InSIDE assumption satisfied")

# Scenario 2
sens_200k_no_causal_scen2_sim_summ_tib <- bind_rows(sens_no_causal_200k_scen2_sim_summ_tib
) %>%
  mutate(Scenario = "Scenario 2: Directional pleiotropy, InSIDE assumption satisfied")

# Scenario 3
sens_200k_no_causal_scen3_sim_summ_tib <- bind_rows(sens_no_causal_200k_scen3_sim_summ_tib
) %>%
  mutate(Scenario = "Scenario 3: Directional pleiotropy, InSIDE assumption not satisfied")


# Summary
sens_200k_no_causal_sim_summ_tib <- bind_rows(sens_200k_no_causal_scen1_sim_summ_tib,
                                              sens_200k_no_causal_scen2_sim_summ_tib,
                                              sens_200k_no_causal_scen3_sim_summ_tib
)%>% 
  mutate(WME_Lower_CI = WME_Av - 1.96 * WME_SE,
         WME_Upper_CI = WME_Av + 1.96 * WME_SE,
         Hevo_SE_Calc = round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3),
         Pos_Rate_Diff = Hevo_Pos_Rate - WME_Pos_Rate,
         Hevo_Better = Pos_Rate_Diff < 0)


# --- Causal --- #
# Scenario 1
sens_200k_causal_scen1_sim_summ_tib <- bind_rows(sens_causal_200k_scen1_sim_summ_tib
) %>% 
  mutate(Scenario = "Scenario 1: Balanced pleiotropy, InSIDE assumption satisfied")

# Scenario 2
sens_200k_causal_scen2_sim_summ_tib <- bind_rows(sens_causal_200k_scen2_sim_summ_tib
) %>% 
  mutate(Scenario = "Scenario 2: Directional pleiotropy, InSIDE assumption satisfied")

# Scenario 3
sens_200k_causal_scen3_sim_summ_tib <- bind_rows(sens_causal_200k_scen3_sim_summ_tib
) %>% 
  mutate(Scenario = "Scenario 3: Directional pleiotropy, InSIDE assumption not satisfied")


# Summary
sens_200k_causal_sim_summ_tib <- bind_rows(sens_200k_causal_scen1_sim_summ_tib,
                                             sens_200k_causal_scen2_sim_summ_tib,
                                             sens_200k_causal_scen3_sim_summ_tib) %>% 
  mutate(WME_Lower_CI = WME_Av - 1.96 * WME_SE,
         WME_Upper_CI = WME_Av + 1.96 * WME_SE,
         Hevo_SE_Calc = round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3),
         Pos_Rate_Diff = Hevo_Pos_Rate - WME_Pos_Rate,
         Hevo_Better = Pos_Rate_Diff < 0)


```

```{r sens-200k-no-causal-sim-summ-display, echo=FALSE, warning=FALSE, include=TRUE, tab.id="sens-200k-no-causal-sim-summ-display", tab.cap="Summary of 100 simulated Mendelian randomisation studies per combination of scenario and parameters, all with null causal effect and using 200,000 participants with 25 genetic instruments", results='asis'}
#| ft.arraystretch = 1.3


library(flextable)
library(ftExtra)

# Display
sens_200k_no_causal_sim_summ_display <- sens_200k_no_causal_sim_summ_tib %>%
  # Change names for cleaner plotting
  mutate(Invalid = paste0((Prop_Invalid * 100), "%"),
         F = round(F_stat, 1),
         R2 = paste0(R2_stat *100, "%"),
         Weighted_Median_Mean_Estimate = WME_Av,
         Weighted_Median_Mean_SE = paste0("(", WME_SE, ")"),
         Weighted_Median_Lower_CI = round(WME_Av - 1.96 * WME_SE, 2),
         Weighted_Median_Upper_CI = round(WME_Av + 1.96 * WME_SE, 2),
         Weighted_Median_95_CI = paste0(Weighted_Median_Lower_CI, " to ", Weighted_Median_Upper_CI),
         Weighted_Median_Causal_Report_Rate = paste0((WME_Pos_Rate * 100), "%"),
         MR_Hevo_Mean_Estimate = Hevo_Av,
         #MR_Hevo_Mean_SE = paste0("(", round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3), ")"),
         MR_Hevo_Mean_SE = paste0("(", Hevo_SE_Calc, ")"),
         MR_Hevo_Lower_CI = round(Hevo_Lower_CI, 2),
         MR_Hevo_Upper_CI = round(Hevo_Upper_CI, 2),
         MR_Hevo_95_CI = paste0(round(Hevo_Lower_CI, 2), " to ", round(Hevo_Upper_CI, 2)),
         MR_Hevo_Causal_Report_Rate = paste0((Hevo_Pos_Rate * 100), "%")) %>%
  # Drop old names
  select(N,
         Invalid,
         F,
         R2,
         Weighted_Median_Mean_Estimate,
         Weighted_Median_Mean_SE,
         Weighted_Median_95_CI,
         Weighted_Median_Causal_Report_Rate,
         MR_Hevo_Mean_Estimate,
         MR_Hevo_Mean_SE,
         MR_Hevo_95_CI,
         MR_Hevo_Causal_Report_Rate,
         Scenario) %>%
  as_grouped_data(groups = c("Scenario")) %>%
  as_flextable(hide_grouplabel = TRUE, col_keys = c("N",
                                                    "Invalid",
                                                    "F",
                                                    "R2",
                                                    "Weighted_Median_Mean_Estimate",
                                                    "Weighted_Median_Mean_SE",
                                                    "Weighted_Median_95_CI", 
                                                    "Weighted_Median_Causal_Report_Rate",
                                                    "blank_col",
                                                    "MR_Hevo_Mean_Estimate",
                                                    "MR_Hevo_Mean_SE",
                                                    "MR_Hevo_95_CI", 
                                                    "MR_Hevo_Causal_Report_Rate",
                                                    "Scenario")) |>
  # To separate WME/MR-Hevo
  width(j = "blank_col", width = 0.2) |>
  empty_blanks() |>
  span_header() |>
  align(part = "all", align = "center") |>
  align(part = "body", j =c(5, 10),  align = "right") |>
  align(part = "body", j =c(6, 11),  align = "left") |>
  # Italicise N and F
  italic(part = "header", i = 1, j = c(1,3) ) |>
  # Fix name of invalid IVs
  flextable::compose(part = "header", i = 1:4, j = 2, value = as_paragraph("Invalid IVs")) |>
  # Fix name of 95% CIs
  flextable::compose(part = "header", i = 3, j = c(7, 12), value = as_paragraph("Mean")) |>
  flextable::compose(part = "header", i = 4, j = c(7, 12), value = as_paragraph("95% CI")) |>
  # Fix split headers
  flextable::compose(part = "header", i = 3, j = c(5,10), value = as_paragraph("Mean Estimate")) |>
  flextable::compose(part = "header", i = 4, j = c(5:6), value = as_paragraph("(Mean SE)")) |>
  flextable::compose(part = "header", i = 4, j = c(10:11), value = as_paragraph("(Mean SE*)")) |>
  #flextable::compose(part = "header", i = 4, j = c(5:6,10:11), value = as_paragraph("(Mean SE)")) |>
  merge_h(part = "header", i = 4) |>
  # Italicise/superscript R^2
  flextable::compose(part = "header", i = 1, j = 4, value = as_paragraph(as_i("R"), as_sup(as_i(as.character(2))))) |>
  
  hline(part = "header", i = 2, j = c(5:8, 10:13), border = officer::fp_border(color = "black", width = 1)) |>
  #footnote(i = c(1,4), j = c(2, 5), part = "header", value = as_paragraph(c("IV: Instrumental Variable", "SE: Standard Error")))
  # Fix dimensions
  autofit() |>
  #line_spacing(space = 0, part = "header") |>
  line_spacing(space = 1, part = "body") |>
  fit_to_width(max_width = 6.5) |>
  #height_all(height = 40, unit = "mm",part = "all") |>

  # Add footer
  flextable::add_footer_lines("CI: Confidence Interval, InSIDE: Instrument Strength Independent of Direct Effect, IV: Instumental Variable, SE: Standard Error, SE*: Estimated Standard Error. F and R\U00B2 statistics presented are the minimum values across all simulated datasets. \nNull Causal Effect (\U03B2 = 0)") |>
  flextable::fontsize(9, i = c(1:5), j = c(1:13), part = "header") |>
  flextable::fontsize(8, i = c(1:15), j = c(1:13), part = "body") |>
  flextable::fontsize(8, i = 1, j = 1, part = "footer")
# set_caption(caption = "Summary of 1000 Simulated Mendelian Randomisation Studies With Null Causal Effect (\U03B2 = 0)",
#             style = "Table Caption",
#             autonum = run_autonum(seq_id = "tab",
#                                   bkm = "no-causal-sim-summ-tib"))

sens_200k_no_causal_sim_summ_display


```

\newpage

```{r sens-200k-causal-sim-summ-display, echo=FALSE, warning=FALSE, include=TRUE, tab.id="sens-200k-causal-sim-summ-display", tab.cap="Summary of 100 simulated Mendelian randomisation studies per combination of scenario and parameters, all with positive causal effect and using 200,000 participants with 25 genetic instruments", results='asis', cache=FALSE}
#| ft.arraystretch = 1.3

library(flextable)
library(ftExtra)

# Display
sens_200k_causal_sim_summ_display <- sens_200k_causal_sim_summ_tib %>%
  # Change names for cleaner plotting
  mutate(Invalid = paste0((Prop_Invalid * 100), "%"),
         F = round(F_stat, 1),
         R2 = paste0(R2_stat *100, "%"),
         Weighted_Median_Mean_Estimate = WME_Av,
         Weighted_Median_Mean_SE = paste0("(", WME_SE, ")"),
         Weighted_Median_Lower_CI = round(WME_Av - 1.96 * WME_SE, 2),
         Weighted_Median_Upper_CI = round(WME_Av + 1.96 * WME_SE, 2),
         Weighted_Median_95_CI = paste0(Weighted_Median_Lower_CI, " to ", Weighted_Median_Upper_CI),
         Weighted_Median_Causal_Report_Rate = paste0((WME_Pos_Rate * 100), "%"),
         MR_Hevo_Mean_Estimate = Hevo_Av,
         #MR_Hevo_Mean_SE = paste0("(", round((Hevo_Upper_CI - Hevo_Lower_CI)/3.92, 3), ")"),
         MR_Hevo_Mean_SE = paste0("(", Hevo_SE_Calc, ")"),
         MR_Hevo_Lower_CI = round(Hevo_Lower_CI, 2),
         MR_Hevo_Upper_CI = round(Hevo_Upper_CI, 2),
         MR_Hevo_95_CI = paste0(round(Hevo_Lower_CI, 2), " to ", round(Hevo_Upper_CI, 2)),
         MR_Hevo_Causal_Report_Rate = paste0((Hevo_Pos_Rate * 100), "%")) %>%
  # Drop old names
  select(N,
         Invalid,
         F,
         R2,
         Weighted_Median_Mean_Estimate,
         Weighted_Median_Mean_SE,
         Weighted_Median_95_CI,
         Weighted_Median_Causal_Report_Rate,
         MR_Hevo_Mean_Estimate,
         MR_Hevo_Mean_SE,
         MR_Hevo_95_CI,
         MR_Hevo_Causal_Report_Rate,
         Scenario) %>%
  as_grouped_data(groups = c("Scenario")) %>%
  as_flextable(hide_grouplabel = TRUE, col_keys = c("N",
                                                    "Invalid",
                                                    "F",
                                                    "R2",
                                                    "Weighted_Median_Mean_Estimate",
                                                    "Weighted_Median_Mean_SE",
                                                    "Weighted_Median_95_CI", 
                                                    "Weighted_Median_Causal_Report_Rate",
                                                    "blank_col",
                                                    "MR_Hevo_Mean_Estimate",
                                                    "MR_Hevo_Mean_SE",
                                                    "MR_Hevo_95_CI", 
                                                    "MR_Hevo_Causal_Report_Rate",
                                                    "Scenario")) |>
  # To separate WME/MR-Hevo
  width(j = "blank_col", width = 0.2) |>
  empty_blanks() |>
  span_header() |>
  align(part = "all", align = "center") |>
  align(part = "body", j =c(5, 10),  align = "right") |>
  align(part = "body", j =c(6, 11),  align = "left") |>
  # Italicise N and F
  italic(part = "header", i = 1, j = c(1,3) ) |>
  # Fix name of invalid IVs
  flextable::compose(part = "header", i = 1:4, j = 2, value = as_paragraph("Invalid IVs")) |>
  # Fix name of 95% CIs
  flextable::compose(part = "header", i = 3, j = c(7, 12), value = as_paragraph("Mean")) |>
  flextable::compose(part = "header", i = 4, j = c(7, 12), value = as_paragraph("95% CI")) |>
  # Fix split headers
  flextable::compose(part = "header", i = 3, j = c(5,10), value = as_paragraph("Mean Estimate")) |>
  flextable::compose(part = "header", i = 4, j = c(5:6), value = as_paragraph("(Mean SE)")) |>
  flextable::compose(part = "header", i = 4, j = c(10:11), value = as_paragraph("(Mean SE*)")) |>
  #flextable::compose(part = "header", i = 4, j = c(5:6,10:11), value = as_paragraph("(Mean SE)")) |>
  merge_h(part = "header", i = 4) |>
  # Italicise/superscript R^2
  flextable::compose(part = "header", i = 1, j = 4, value = as_paragraph(as_i("R"), as_sup(as_i(as.character(2))))) |>
  
  hline(part = "header", i = 2, j = c(5:8, 10:13), border = officer::fp_border(color = "black", width = 1)) |>
  #footnote(i = c(1,4), j = c(2, 5), part = "header", value = as_paragraph(c("IV: Instrumental Variable", "SE: Standard Error")))
  # Fix dimensions
  autofit() |>
  #line_spacing(space = 0, part = "header") |>
  line_spacing(space = 1, part = "body") |>
  fit_to_width(max_width = 6.5) |>
  #height_all(height = 40, unit = "mm",part = "all") |>

  # Add footer
  flextable::add_footer_lines("CI: Confidence Interval, InSIDE: Instrument Strength Independent of Direct Effect, IV: Instumental Variable, SE: Standard Error, SE*: Estimated Standard Error. F and R\U00B2 statistics presented are the minimum values across all simulated datasets. \nPositive Causal Effect (\U03B2 = 0.1)") |>
  flextable::fontsize(9, i = c(1:5), j = c(1:13), part = "header") |>
  flextable::fontsize(8, i = c(1:15), j = c(1:13), part = "body") |>
  flextable::fontsize(8, i = 1, j = 1, part = "footer")
# set_caption(caption = "Summary of 1000 Simulated Mendelian Randomisation Studies With Null Causal Effect (\U03B2 = 0)",
#             style = "Table Caption",
#             autonum = run_autonum(seq_id = "tab",
#                                   bkm = "no-causal-sim-summ-tib"))

sens_200k_causal_sim_summ_display


```


\newpage

\blandscape

## Re-Analysis Study {#appendix-sens-reanalysis}

```{r sens-citations-reanalysis-data-save, eval=FALSE}

sens_data_clift_smoking_2022_outlier <- read.csv(here("Data", "Citations_Datasets", "clift_smoking_2022.csv")) %>% 
  as_tibble() %>% 
  # Use Study_DOI as get_reanalysis function groups by this
  mutate(Study_DOI = "Outlier Included")


sens_data_xie_associations_2023_max <- read.csv(here("Data", "Citations_Datasets", "xie_associations_2023.csv")) %>% 
  as_tibble() %>% 
  mutate(
    Study_DOI = "NAs imputed - max values",
    # imputes missing as max
    across(starts_with("Coeff_"), ~str_replace_all(., pattern = "[Aa:Zz]", replacement = NA_character_)),
    across(starts_with("Coeff_"), ~as.double(.)),
    across(where(is.numeric), ~replace_na(., max(., na.rm = TRUE)))
  )

sens_data_xie_associations_2023_min <- read.csv(here("Data", "Citations_Datasets", "xie_associations_2023.csv")) %>% 
  as_tibble() %>% 
  mutate(
    Study_DOI = "NAs imputed - min values",
    # imputes missing as max
    across(starts_with("Coeff_"), ~str_replace_all(., pattern = "[Aa:Zz]", replacement = NA_character_)),
    across(starts_with("Coeff_"), ~as.double(.)),
    across(where(is.numeric), ~replace_na(., min(., na.rm = TRUE)))
  )


sens_citation_datasets_list <- list(sens_data_clift_smoking_2022_outlier,
                                    sens_data_xie_associations_2023_max,
                                    sens_data_xie_associations_2023_min)  

for(dataset in 1:length(sens_citation_datasets_list)){
  
  sens_citation_datasets_list[[dataset]] <- sens_citation_datasets_list[[dataset]] %>% 
    tibble() %>% 
    mutate(
      # replace all unicode dash variations with minus - to stop conversion to char
      # https://stackoverflow.com/questions/48923599/searching-for-all-variations-of-hyphens-and-dashes-in-regex
      across(starts_with("Coeff_"), 
             ~str_replace_all(.,
                              pattern = "[\u002D\u058A\u05BE\u1400\u1806\u2010-\u2015\u2E17\u2E1A\u2E3A\u2E3B\u2E40\u301C\u3030\u30A0\uFE31\uFE32\uFE58\uFE63\uFF0D]", 
                              # https://www.kaggle.com/discussions/questions-and-answers/54715
                              replacement = "\U002D")),
      # replace zeros for MR-Hevo
      across(starts_with("Coeff_"), ~replace(., . == 0, 10^-100)), 
      # remove square brackets from ref tags
      across(Study_Ref, ~str_replace_all(., "\\[|\\]", ""))
    )
    
}


# Combine
Sens_Citations_Instrument_Data <- bind_rows(sens_citation_datasets_list)

write.csv(Sens_Citations_Instrument_Data, here("Data", "Citations_Datasets", "Sens_Citations_Instrument_Data.csv"), append = FALSE)


```

```{r sens-citations-reanalysis-sum-tib, eval=FALSE}

Sens_Citations_Instrument_Data <- read.csv(here("Data", "Citations_Datasets", "Sens_Citations_Instrument_Data.csv"))

sens_citations_reanalysis_summ_tib <- Sens_Citations_Instrument_Data %>% 
  mutate(across(Coeff_G_X:Coeff_G_Y_SE, ~replace(., . == 0, 10^-100))) %>% 
  get_reanalysis_tib() 


write.csv(sens_citations_reanalysis_summ_tib, here("Data", "Citations_Datasets", "sens_citations_reanalysis_summ_tib.csv"),append = FALSE)

```
```{r sens-citations-reanalysis-sum-display, include = TRUE}
#| tab.id = "sens-citations-reanalysis-summ-display",
#| tab.cap = "Sensitivity re-analyses using inclusion of outliers and imputation of missing values as most extreme values from the respective dataset",
#| ft.arraystretch = 1.5

sens_citations_reanalysis_summ_tib <- read.csv(here("Data", "Citations_Datasets", "sens_citations_reanalysis_summ_tib.csv"))

sens_citations_reanalysis_summ_display <- sens_citations_reanalysis_summ_tib %>% 
  mutate(across(where(is.numeric), \(x) round(x, 3)), 
         Study_SNPs = WME_nsnp,
         Blank = NA,
         Weighted_Median_Beta = paste0(round(WME_est, 2), " (", round(WME_est_lower_CI, 2), "-", round(WME_est_upper_CI, 2), ")"),
         Weighted_Median_SE = WME_se,
         Weighted_Median_OR = paste0(round(WME_OR, 2), " (", round(WME_OR_lower_CI, 2), "-", round(WME_OR_upper_CI, 2), ")"),
         Weighted_Median_Causality = if_else(WME_est_causal_detected, "Yes", "No"),
         Blank_2 = NA,
         MR_Hevo_Beta = paste0(round(Hevo_est, 2), " (", round(Hevo_est_lower_CI, 2), "-", round(Hevo_est_upper_CI, 2), ")"),
         MR_Hevo_SE = round((Hevo_est_upper_CI - Hevo_est_lower_CI)/3.92, 3),
         MR_Hevo_OR = paste0(round(Hevo_OR, 2), " (", round(Hevo_OR_lower_CI, 2), "-", round(Hevo_OR_upper_CI, 2), ")"),
         MR_Hevo_Causality = if_else(Hevo_est_causal_detected, "Yes", "No")
         ) %>% 
  # Sort
  arrange(Study_Author) %>% 
  # Drop old names
  select(Study_Author,
         #Study_Ref,
         Study_DOI,
         Study_Exposure,
         Study_Outcome,
         Study_SNPs, 
         Blank,
         Weighted_Median_Beta,
         Weighted_Median_SE,
         Weighted_Median_OR,
         Weighted_Median_Causality,
         Blank_2,
         MR_Hevo_Beta,
         MR_Hevo_SE,
         MR_Hevo_OR,
         MR_Hevo_Causality) %>% 
    mutate(across(where(is.double), round, 3)) %>% 
  #as_grouped_data(groups = "Study_Author", expand_single = FALSE,) %>%
  flextable(#hide_grouplabel = TRUE, 
    col_keys = c("Study_Author", #"Study_Ref", 
                 "Study_DOI",
                 "Study_Exposure",
                 "Study_Outcome",
                 "Study_SNPs", 
                 "Blank", #5
                 "Weighted_Median_Beta", 
                 "Weighted_Median_SE",
                 "Weighted_Median_OR",
                 "Weighted_Median_Causality",
                 "Blank_2", #10
                 "MR_Hevo_Beta", 
                 "MR_Hevo_SE",
                 "MR_Hevo_OR",
                 "MR_Hevo_Causality")) |>
  # To separate Study Details/WME/MR-Hevo
  width(j = c(6, 11), width = 0.2) |>
  span_header() |>
  align(part = "all", align = "center") |>
  # Fix names 
  ## Blank cols - unsure why not working as above
  flextable::compose(part = "header", i = 1:3, j = c(6, 11), value = as_paragraph("")) |>
  ## Blank study top row
  flextable::compose(part = "header", i = 1, j = c(1), value = as_paragraph("")) |>
  empty_blanks() |>
  ## Re-analysis
  flextable::compose(part = "header", i = c(1:2), j = c(2), value = as_paragraph("Re-Analysis")) %>% 
  ## WME
  flextable::compose(part = "header", i = c(1:2), j = c(7:10), value = as_paragraph("Weighted Median")) %>% 
  merge_v(part = "header", j = c(6:9)) %>% 
  ## MR-Hevo
  flextable::compose(part = "header", i = c(1:2), j = c(12:15), value = as_paragraph("MR-Hevo")) %>% 
  merge_v(part = "header", j = c(11:14)) %>% 
  ## Causality
  width(j = c(6, 8, 11, 13), width = 20) |>
  flextable::compose(part = "header", i = 3, j = c(10, 15), value = as_paragraph("Causality\nReported")) |>
  ## SE*
  flextable::compose(part = "header", i = 3, j = c(12), value = as_paragraph("SE*")) |>
  ## Blanks
  empty_blanks() |>
  ## Beta
  flextable::compose(part = "header", i = 3, j = c(7, 12), value = as_paragraph("\U03B2")) |> #\U0302
  # Separating lines
  hline(part = "header", i = 2, j = c(7:10, 12:15), border = officer::fp_border(color = "black", width = 1)) |>
  hline(part = "body", i = c(1:3), j = c(1:15), border = officer::fp_border(color = "black", width = 0.2)) |>
  # Fix dimensions
  autofit() |>
  line_spacing(space = 1, part = "header") |>
  line_spacing(space = 1, part = "body") |>
  fit_to_width(max_width = 9) |>
  height_all(height = 0.6) |>
  #height_all(height = 40, unit = "mm",part = "all") |>
  # Add footer
  flextable::add_footer_lines("\U03B2 and OR presented as: estimate (95% CI).\n\U03B2: causal effect estimate, CI: Confidence Interval, OR: Odds Ratio, SE: Standard Error, SE*: Estimated Standard Error.\nNAFLD: non-alcoholic fatty liver disease, T2DM: type 2 diabetes mellitus") |>
  #footnote(i = c(1,4), j = c(2, 5), part = "header", value = as_paragraph(c("IV: Instrumental Variable", "SE: Standard Error")))
  flextable::fontsize(9, i = c(1:3), j = c(1:15), part = "header") |>
  flextable::fontsize(8, i = c(1:3), j = c(1:15), part = "header") |>
  flextable::fontsize(8, i = c(1:3), j = c(1:15), part = "body") |>
  flextable::fontsize(8, i = 1, j = 1, part = "footer")
  # reframe(N = N,
  #         WME_Av = mean(WME_est),
  #         WME_SE = mean(WME_se),
  #         Hevo_Av = mean(Hevo_est),
  #         Hevo_SE = mean(Hevo_se),
  #         Hevo_Est_Causal = Hevo_est_causal_detected
  # ) %>%

sens_citations_reanalysis_summ_display

```

\elandscape

\newpage

# Appendix: R Packages Used {#appendix-pkg}

## Package Citations

```{r package-citations, include = TRUE, echo = FALSE}

#nocite_references(cite_packages(output = "citekeys", out.dir = tempdir()))

grateful::cite_packages(output = "paragraph",
                        passive.voice = TRUE,
                        out.dir = here::here(),
                        omit = NULL,
                        include.RStudio = FALSE) 
#gt() %>% 
#fmt_markdown()

#kable() %>% 
#kable_styling() %>% 
#unclass() %>% 
#cat()
#str_replace_all(pattern = ",", "\n") #%>% 
#cat() %>% 
#return()
#tibble() %>%
#mutate(Citation = paste0("[", Citation, "]")) %>%
#knitr::kable()


```

## Session Information {#Session-Information}


```{r system-info, include = TRUE, echo = FALSE}

library(benchmarkme)

sys_details_full <- benchmarkme::get_sys_details()

sysname_release <- paste0(sys_details_full$sys_info, " ", sys_details_full$release)

sys_ram <- sys_details_full$ram
sys_cpu <- sys_details_full$cpu$model_name
sys_cores <- sys_details_full$cpu$no_of_cores

```

CPU: `r sys_cpu`, `r sys_cores` cores \newline
RAM: `r (sys_ram * 10^-9) %>% format(scientific = FALSE) %>% as.numeric() %>%  round(., 1)` GB

```{r session-info, include=TRUE, echo=FALSE}

platform <- devtools::session_info() %>% #str()
  .$platform

packages <- devtools::session_info() %>%
  .$packages %>%
  tibble() %>%
  filter(attached == TRUE) %>%
  select(-c(path,
            loadedpath,
            attached,
            is_base,
            md5ok,
            library))

package_col <- packages$package

# package_col %>%
#   map(citation) %>%
#   #print()
#   print(style = "BibTeX")
#   #print(style = "text")

platform

packages %>% 
  print(n = nrow(.))

```

\newpage

<!--chapter:end:9_Appendices.Rmd-->

